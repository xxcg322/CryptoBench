[
  {
    "id": "001",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ],
    "question": "Which of the following is NOT one of the main components of the Bitcoin system?\nA. Users with wallets containing keys\nB. Transactions propagated across the network\nC. Miners producing the consensus blockchain\nD. Central banks regulating the currency",
    "answer": "D"
  },
  {
    "id": "002",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ],
    "question": "What is the primary purpose of a 'change' output in a Bitcoin transaction?\nA. To pay transaction fees\nB. To return excess funds to the spender\nC. To send funds to multiple recipients\nD. To create a new Bitcoin address",
    "answer": "B"
  },
  {
    "id": "003",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ],
    "question": "How does the Bitcoin network primarily propagate new transactions?\nA. Through a central server\nB. Using email notifications\nC. Via gossiping in a peer-to-peer network\nD. By broadcasting on social media",
    "answer": "C"
  },
  {
    "id": "004",
    "categories": [
      "Bitcoin",
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the main purpose of the proof-of-work system in Bitcoin mining?\nA. To create new bitcoins\nB. To secure the network without a central authority\nC. To process transactions faster\nD. To reduce energy consumption",
    "answer": "B"
  },
  {
    "id": "005",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Why are six confirmations considered very secure for a Bitcoin transaction?\nA. It's an arbitrary number chosen by Satoshi Nakamoto\nB. It allows enough time for all nodes to sync\nC. It requires an immense amount of computation to reverse\nD. It's the maximum number of confirmations possible",
    "answer": "C"
  },
  {
    "id": "006",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following is NOT a purpose of the 'configure' script when compiling Bitcoin Core from source?\nA. Customize the build process\nB. Create build scripts specific to your system\nC. Download and install necessary dependencies\nD. Allow for feature selection",
    "answer": "C"
  },
  {
    "id": "007",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which configuration option in Bitcoin Core is used to maintain an index of all transactions?\nA. datadir\nB. txindex\nC. prune\nD. maxmempool",
    "answer": "B"
  },
  {
    "id": "008",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the primary method of authentication for Bitcoin Core's JSON-RPC interface?\nA. A cookie file with a random password\nB. Public key cryptography\nC. OAuth tokens\nD. Plain text username and password",
    "answer": "A"
  },
  {
    "id": "009",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which command is used to decode a raw Bitcoin transaction?\nA. getrawtransaction\nB. decodetx\nC. decoderawtransaction\nD. parsetransaction",
    "answer": "C"
  },
  {
    "id": "010",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the minimum amount of blockchain data (in MiB) that a pruned Bitcoin Core node typically keeps?\nA. 100 MiB\nB. 550 MiB\nC. 1000 MiB\nD. 2000 MiB",
    "answer": "B"
  },
  {
    "id": "011",
    "categories": [
      "Bitcoin",
      "Cryptography",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A Bitcoin exchange wants to support both compressed and uncompressed public keys. Which of the following is NOT a valid concern in implementing this support?\nA. Increased storage requirements\nB. Potential for key version mismatch\nC. Compatibility issues with newer protocol features\nD. Increased transaction fees for all users",
    "answer": "D"
  },
  {
    "id": "012",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "System Design",
      "Advanced"
    ],
    "question": "When designing a Bitcoin wallet to support multiple address types, which of the following approaches would be LEAST effective for future-proofing the wallet?\nA. Implementing a modular address parsing system\nB. Using an abstract 'Address' class with type-specific subclasses\nC. Hardcoding support for currently known address types\nD. Using a factory pattern for creating address objects",
    "answer": "C"
  },
  {
    "id": "013",
    "categories": [
      "Bitcoin",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "Which of the following would NOT help in preventing attacks exploiting the bech32 length extension vulnerability?\nA. Upgrading to use bech32m addresses\nB. Implementing a whitelist of known-good addresses\nC. Using longer bech32 addresses\nD. Adding a secondary verification step for withdrawals",
    "answer": "C"
  },
  {
    "id": "014",
    "categories": [
      "Bitcoin",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "In designing a secure Bitcoin storage system for a large institution, which of the following would likely provide the LEAST security benefit?\nA. Using a 3-of-5 multisignature address\nB. Implementing a timelock contract on transactions\nC. Storing all keys in a single, highly secure location\nD. Regularly rotating keys and addresses",
    "answer": "C"
  },
  {
    "id": "015",
    "categories": [
      "Bitcoin",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "In designing a multi-tiered key management system for a cryptocurrency exchange using BIP39 and BIP32, which of the following represents the BEST practice for maximum security?\nA. Use a single extended public key (xpub) for all operations\nB. Share the full 24-word recovery phrase among all employees\nC. Use hardened derivation for top-level paths and limit xpub access\nD. Generate a new master seed for each customer account",
    "answer": "C"
  },
  {
    "id": "016",
    "categories": [
      "Bitcoin",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "When implementing Shamir's Secret Sharing (SLIP39) with a BIP32 HD wallet structure for a large corporation's treasury operations, which of the following is NOT a key challenge in integrating with existing financial controls?\nA. Designing a key ceremony that can be audited without compromising security\nB. Creating interfaces between the HD wallet and current financial software\nC. Implementing a multi-signature scheme that aligns with existing approval processes\nD. Increasing the total number of bitcoins held by the corporation",
    "answer": "D"
  },
  {
    "id": "017",
    "categories": [
      "Bitcoin",
      "Privacy",
      "System Design",
      "Advanced"
    ],
    "question": "In a cryptocurrency wallet design that combines BIP39, BIP32, and BIP47 for maximum privacy, which of the following is a potential drawback?\nA. Inability to generate unique addresses for each transaction\nB. Lack of a recovery mechanism for the wallet\nC. Potential linking of transactions if payment codes are shared publicly\nD. Incompatibility with existing blockchain networks",
    "answer": "C"
  },
  {
    "id": "018",
    "categories": [
      "Bitcoin",
      "Cryptography",
      "System Design",
      "Advanced"
    ],
    "question": "In developing a quantum-resistant blockchain system that maintains compatibility with existing Bitcoin wallets, which of the following is a major trade-off?\nA. Reduced transaction speed for all users\nB. Increased transaction size due to additional signatures\nC. Inability to use existing Bitcoin addresses\nD. Requirement for all users to upgrade immediately",
    "answer": "B"
  },
  {
    "id": "019",
    "categories": [
      "Bitcoin",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A Bitcoin exchange has implemented a new transaction monitoring system to detect double-spending attempts. Which of the following scenarios would be the MOST challenging for this system to handle effectively?\nA. A transaction with a low fee being replaced by one with a higher fee (RBF)\nB. Two conflicting transactions seen in different order by different nodes due to network latency\nC. A transaction input script being modified without changing the transaction's overall structure (third-party malleability)\nD. A segwit transaction being replaced by a non-segwit version spending the same inputs",
    "answer": "B"
  },
  {
    "id": "020",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "System Design",
      "Advanced"
    ],
    "question": "In a new Bitcoin-based smart contract system designed for complex, multi-step transactions, which of the following would be the MOST difficult to implement within Bitcoin's current protocol limitations?\nA. A contract that requires three out of five signatures to release funds\nB. A transaction that can only be spent after a specific block height\nC. A contract that automatically executes based on the price of a stock reaching a certain value\nD. A series of pre-signed transactions that execute in a specific order over time",
    "answer": "C"
  },
  {
    "id": "021",
    "categories": [
      "Bitcoin",
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A proposed privacy-enhancing system for Bitcoin combines CoinJoin, Confidential Transactions, and Taproot. Which of the following would be the MOST significant challenge in implementing this system?\nA. Ensuring that the combined transaction size doesn't exceed Bitcoin's block size limit\nB. Maintaining compatibility with existing Bitcoin wallets and exchanges\nC. Preventing inflation bugs due to the use of cryptographic commitments for transaction amounts\nD. Achieving consensus among miners to adopt the necessary protocol changes",
    "answer": "D"
  },
  {
    "id": "022",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "In Bitcoin, what is the role of full nodes in the verification of authorization and authentication?\nA) They only verify authorization, not authentication.\nB) They verify both authorization and authentication, ensuring transaction validity.\nC) They serve as intermediaries between users and miners.\nD) They store the entire history of all transactions but do not perform verifications.",
    "answer": "B"
  },
  {
    "id": "023",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Why is Bitcoin’s Script language considered stateless, and how does this benefit the network?\nA) It maintains a log of previous executions to prevent double-spending.\nB) It allows complex computations and dynamic condition checking.\nC) It does not store any information between executions, ensuring predictable verification.\nD) It tracks transaction states across all full nodes to ensure consensus.",
    "answer": "C"
  },
  {
    "id": "024",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How do input and output scripts work together in legacy Bitcoin transactions?\nA) The output script defines spending conditions, while the input script provides the proof to satisfy those conditions.\nB) The input script defines spending conditions, and the output script authorizes the funds.\nC) Both input and output scripts define how miners validate the transaction.\nD) Input scripts define the transaction fees, and output scripts define the recipient.",
    "answer": "A"
  },
  {
    "id": "025",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is one security benefit of Bitcoin’s Script language being non-Turing complete?\nA) It allows for advanced smart contracts with dynamic features.\nB) It prevents vulnerabilities like infinite loops or overly complex logic.\nC) It enables the implementation of multi-chain smart contracts.\nD) It allows Bitcoin transactions to be faster by using parallel execution.",
    "answer": "B"
  },
  {
    "id": "026",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How does Bitcoin’s stateless verification model simplify transaction validation?\nA) It uses historical data to ensure transaction validity.\nB) It requires each node to store transaction history, simplifying the verification process.\nC) All necessary data for verifying a transaction is contained within the transaction itself.\nD) It utilizes a global state shared across the network for quick validation.",
    "answer": "C"
  },
  {
    "id": "027",
    "categories": [
      "Bitcoin",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ],
    "question": "How does Schnorr's ability to aggregate signatures benefit Bitcoin's transaction system?\nA) It allows public key recovery from the transaction data.\nB) It reduces the transaction size by combining multiple signatures into one.\nC) It increases the complexity of signature verification.\nD) It improves the transaction's resistance to tampering.",
    "answer": "B"
  },
  {
    "id": "028",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "How does the SIGHASH_SINGLE flag benefit multi-party transactions?\nA) It commits the signer to all inputs and outputs of the transaction.\nB) It allows each participant to sign only the specific output they are responsible for.\nC) It combines all signatures into a single one for the entire transaction.\nD) It allows transaction modification without invalidating signatures.",
    "answer": "B"
  },
  {
    "id": "029",
    "categories": [
      "Bitcoin",
      "Cryptography",
      "Privacy",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is a key privacy benefit of Schnorr signatures in multi-signature Bitcoin transactions?\nA) Schnorr signatures are more secure than ECDSA signatures.\nB) Schnorr signatures make multi-signature transactions indistinguishable from regular transactions.\nC) Schnorr signatures reveal the public keys used in multi-signature transactions.\nD) Schnorr signatures require fewer computational resources for signing.",
    "answer": "B"
  },
  {
    "id": "030",
    "categories": [
      "Bitcoin",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What does the Bitcoin signature verification algorithm use to ensure only the private key holder can sign a transaction?\nA) It uses the public key, message hash, and signature to verify the signer’s identity.\nB) It compares the signature to a list of approved addresses.\nC) It calculates the private key based on the transaction data.\nD) It relies on miners to validate the signature's authenticity.",
    "answer": "A"
  },
  {
    "id": "031",
    "categories": [
      "Bitcoin",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "How does the SIGHASH_ANYONECANPAY flag modify a transaction signature's behavior?\nA) It allows the signature to apply only to the signed input, enabling other inputs to be added.\nB) It requires all inputs and outputs to be signed by the same participant.\nC) It prevents any modification to the transaction after the signature is applied.\nD) It applies the signature to both the input and all outputs regardless of other inputs.",
    "answer": "A"
  },
  {
    "id": "032",
    "categories": [
      "Bitcoin",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In a future Bitcoin network where transaction fees are the primary miner incentive, which of the following scenarios is LEAST likely to occur as a result of RBF and transaction pinning?\nA. Increased fee volatility due to frequent fee bumping\nB. More complex block construction algorithms developed by miners\nC. A decrease in the overall security of the Bitcoin network\nD. Potential centralization pressure on smaller miners",
    "answer": "C"
  },
  {
    "id": "033",
    "categories": [
      "Bitcoin",
      "System Design",
      "Advanced"
    ],
    "question": "A Bitcoin wallet implements a fee management system combining RBF, CPFP, and CPFP carve-out. Which of the following is the MOST critical consideration for ensuring effective operation of this system?\nA. Automatically using the highest possible fee for all transactions\nB. Balancing automatic fee bumping with user control and transparency\nC. Always preferring CPFP over RBF for fee bumping\nD. Implementing CPFP carve-out for every transaction",
    "answer": "B"
  },
  {
    "id": "034",
    "categories": [
      "Bitcoin",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In a future where Bitcoin block rewards are minimal, which of the following potential evolutions of fee bumping mechanisms would MOST likely maintain both network security and usability?\nA. A dynamic RBF system with AI-driven fee estimation and standardized time-price options\nB. Elimination of all fee bumping in favor of a first-come, first-served transaction model\nC. A centralized fee market controlled by the largest mining pools\nD. Mandatory high fees for all transactions to ensure miner profitability",
    "answer": "A"
  },
  {
    "id": "035",
    "categories": [
      "Bitcoin",
      "System Design",
      "Advanced"
    ],
    "question": "For a Bitcoin wallet designed for high-frequency traders requiring 1-2 block confirmation times, which of the following proposed protocol-level features would LEAST effectively address the limitations of current fee bumping mechanisms?\nA. Enhanced RBF allowing replacement of multiple ancestor transactions simultaneously\nB. Implementation of a consensus-level 'express lane' for high-fee transactions\nC. Advanced package relay supporting complex transaction packages with internal dependencies\nD. Mandatory minimum fee rates for all transactions during peak network usage",
    "answer": "D"
  },
  {
    "id": "036",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How does compact block relay contribute to Bitcoin's network decentralization?\nA) By allowing only large miners to quickly propagate blocks\nB) By reducing the advantage of larger miners in block-finding races\nC) By increasing the bandwidth requirements for all nodes\nD) By encrypting block data to prevent eavesdropping",
    "answer": "B"
  },
  {
    "id": "037",
    "categories": [
      "Bitcoin",
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In the event of a large-scale network partition, what potential negative impact could private block relay networks have on Bitcoin's consensus?\nA) They could slow down block propagation across the entire network\nB) They might lead to more severe forks if the private networks themselves are partitioned\nC) They would prevent any blocks from being mined during the partition\nD) They would automatically resolve the partition without any issues",
    "answer": "B"
  },
  {
    "id": "038",
    "categories": [
      "Bitcoin",
      "Problem Solving",
      "Advanced"
    ],
    "question": "If multiple Bitcoin exchanges widely adopted a modified compact block relay system for detecting suspicious transactions, what potential impact might this have on the broader Bitcoin network?\nA) It would significantly reduce the overall number of Bitcoin transactions\nB) It could lead to increased network strain and affect mempool dynamics\nC) It would eliminate all privacy concerns in Bitcoin transactions\nD) It would force all Bitcoin users to use exchange-approved wallets",
    "answer": "B"
  },
  {
    "id": "039",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the primary factor that makes it increasingly difficult to alter a block deeper in the Bitcoin blockchain?\nA) The increased encryption of older blocks\nB) The need to recalculate proof-of-work for all subsequent blocks\nC) The larger size of older blocks\nD) The use of more complex hashing algorithms for older blocks",
    "answer": "B"
  },
  {
    "id": "040",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How do Merkle trees in Bitcoin's blockchain structure primarily benefit lightweight clients?\nA) By allowing them to mine new blocks more efficiently\nB) By providing them with a complete history of all transactions\nC) By enabling efficient verification of transaction inclusion with minimal data\nD) By eliminating the need for them to connect to full nodes",
    "answer": "C"
  },
  {
    "id": "041",
    "categories": [
      "Bitcoin",
      "System Design",
      "Knowledge",
      "Intermediate"
    ],
    "question": "In a Bitcoin wallet supporting both full block and Merkle proof verification, which method would be most suitable for a mobile device with limited resources?\nA) Merkle proof verification\nB) Full block verification\nC) Alternating between full block and Merkle proof verification\nD) Neither, mobile devices cannot perform transaction verification",
    "answer": "A"
  },
  {
    "id": "042",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of Bitcoin's test blockchains is most suitable for rapid development and testing of new scripts or protocol changes in a fully controlled environment?\nA) Mainnet\nB) Testnet\nC) Regtest\nD) Signet",
    "answer": "C"
  },
  {
    "id": "043",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Compared to a hypothetical blockchain where each block contains a hash of the entire previous block, Bitcoin's structure of hashing only the previous block's header offers which primary advantage?\nA) Improved efficiency and scalability\nB) Enhanced security\nC) Larger block sizes\nD) Faster transaction confirmation times",
    "answer": "A"
  },
  {
    "id": "044",
    "categories": [
      "Bitcoin",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following best describes a key difference between hard forks and soft forks in Bitcoin?\nA) Hard forks require all nodes to upgrade, while soft forks are backward compatible\nB) Soft forks can introduce any new feature, while hard forks are limited\nC) Hard forks are always intentional, while soft forks can happen accidentally\nD) Soft forks require 100% consensus, while hard forks only need 51% support",
    "answer": "A"
  },
  {
    "id": "045",
    "categories": [
      "Bitcoin",
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the primary purpose of the Proof of Work system in Bitcoin mining?\nA) To ensure fair distribution of newly minted bitcoins\nB) To make it computationally difficult and costly to add new blocks, securing the network\nC) To speed up transaction confirmation times\nD) To reduce energy consumption in the mining process",
    "answer": "B"
  },
  {
    "id": "046",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "In the context of a 51% attack on the Bitcoin network, which of the following is NOT a potential consequence?\nA) Double-spending recent transactions\nB) Censoring specific transactions from being confirmed\nC) Creating bitcoins out of thin air, exceeding the 21 million limit\nD) Preventing new transactions from gaining confirmations",
    "answer": "C"
  },
  {
    "id": "047",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Beginner"
    ],
    "question": "What is the primary benefit of mining pools for individual Bitcoin miners?\nA) Guaranteed block rewards every 10 minutes\nB) Ability to mine with less powerful hardware\nC) Reduced variance in payouts, providing more consistent income\nD) Complete control over which transactions are included in blocks",
    "answer": "C"
  },
  {
    "id": "048",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following activation methods for Bitcoin soft forks ensures activation by a specific time, regardless of miner signaling?\nA) BIP9\nB) BIP8\nC) Speedy Trial\nD) BIP34",
    "answer": "B"
  },
  {
    "id": "049",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following best describes a key difference between Bitcoin's security model and traditional centralized financial systems?\nA) Bitcoin requires users to share personal information for transactions\nB) Traditional systems are more resistant to large-scale data breaches\nC) Bitcoin transactions are irreversible and don't reveal private information\nD) Centralized systems give users more control over their funds",
    "answer": "C"
  },
  {
    "id": "050",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "In Bitcoin's security architecture, what serves as the 'root of trust'?\nA) The Bitcoin Core software\nB) The longest blockchain validated by consensus\nC) The user's private keys\nD) The mining hardware securing the network",
    "answer": "B"
  },
  {
    "id": "051",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following Bitcoin key storage methods offers the best protection against online threats?\nA) Software wallets on a personal computer\nB) Cloud-based encrypted storage\nC) Hardware signing devices\nD) Paper wallets (cold storage)",
    "answer": "D"
  },
  {
    "id": "052",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the primary advantage of using cold storage for Bitcoin?\nA) It allows for faster transactions\nB) It provides maximum security against online threats\nC) It's the most convenient method for daily use\nD) It automatically backs up your bitcoins",
    "answer": "B"
  },
  {
    "id": "053",
    "categories": [
      "Bitcoin",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "When creating a backup plan for Bitcoin wallets, what is a crucial consideration?\nA) Storing all backups in a single secure location\nB) Sharing your private keys with a trusted friend\nC) Creating multiple copies and storing them in different physical locations\nD) Using only digital backups for easy access",
    "answer": "C"
  },
  {
    "id": "054",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following best describes a key difference between colored coins and the Lightning Network as second-layer solutions for Bitcoin?\nA) Colored coins focus on asset representation, while Lightning Network focuses on payment scalability\nB) Colored coins operate entirely off-chain, while Lightning Network transactions are always on-chain\nC) Lightning Network can only handle bitcoin transactions, while colored coins can represent any asset\nD) Colored coins require specialized hardware, while Lightning Network works with standard Bitcoin nodes",
    "answer": "A"
  },
  {
    "id": "055",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "In the context of the Lightning Network, what is the primary purpose of Hash Time Lock Contracts (HTLCs)?\nA) To create new bitcoins within payment channels\nB) To enable trustless routing of payments across multiple channels\nC) To prevent the creation of new payment channels\nD) To increase transaction fees for miners",
    "answer": "B"
  },
  {
    "id": "056",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is NOT a potential benefit of widespread Lightning Network adoption?\nA) Increased transaction privacy\nB) Higher fees for on-chain transactions\nC) Enablement of micropayments\nD) Reduced on-chain congestion",
    "answer": "B"
  },
  {
    "id": "057",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the primary purpose of revocation keys in Lightning Network payment channels?\nA) To open new payment channels\nB) To increase the total capacity of the channel\nC) To prevent broadcasting of old channel states\nD) To encrypt communications between channel participants",
    "answer": "C"
  },
  {
    "id": "058",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is a key difference between the RGB and Taproot Assets protocols for implementing colored coins?\nA) RGB only works with Bitcoin, while Taproot Assets works with multiple blockchains\nB) RGB offers more flexibility for complex contracts, while Taproot Assets is more streamlined for asset transfer\nC) Taproot Assets can work with Lightning Network, but RGB cannot\nD) RGB requires specialized hardware, while Taproot Assets works with standard Bitcoin nodes",
    "answer": "B"
  },
  {
    "id": "059",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following best describes how the Lightning Network addresses Bitcoin's scalability issue?\nA) By increasing the Bitcoin block size\nB) By creating a second layer network for off-chain transactions\nC) By reducing the number of allowed Bitcoin transactions\nD) By implementing a new consensus algorithm for Bitcoin",
    "answer": "B"
  },
  {
    "id": "060",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "In the context of the Lightning Network, what is the primary purpose of Hashed Timelock Contracts (HTLCs)?\nA) To increase the block size of Bitcoin\nB) To enable trustless routing of payments across multiple channels\nC) To replace the proof-of-work consensus mechanism\nD) To eliminate the need for Bitcoin miners",
    "answer": "B"
  },
  {
    "id": "061",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is NOT a proposed mitigation strategy for forced expiration spam attacks in the Lightning Network?\nA) Allowing transaction replacement with higher sequence numbers\nB) Implementing a 'timestop' flag in blocks\nC) Increasing the Bitcoin block size\nD) Attaching high fees to transactions not redeemed via Exercise Settlement",
    "answer": "C"
  },
  {
    "id": "062",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the primary benefit of using Decrementing Timelocks in multi-hop payments on the Lightning Network?\nA) It increases the total transaction capacity of Bitcoin\nB) It allows for instant confirmation of on-chain transactions\nC) It ensures that intermediaries cannot steal funds during routing\nD) It eliminates the need for payment channels",
    "answer": "C"
  },
  {
    "id": "063",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which mechanism is used in the Lightning Network to prevent the broadcast of outdated channel states?\nA) Increasing the Bitcoin block size\nB) Using a proof-of-stake consensus mechanism\nC) Implementing Revocation Keys and Penalty Transactions\nD) Eliminating the use of Bitcoin transactions entirely",
    "answer": "C"
  },
  {
    "id": "064",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Privacy",
      "Knowledge",
      "Advanced"
    ],
    "question": "What technique does the Lightning Network use to preserve privacy during payment routing?\nA) Increasing transaction fees\nB) Onion routing\nC) Publishing all transaction details on the blockchain\nD) Requiring KYC for all network participants",
    "answer": "B"
  },
  {
    "id": "065",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Problem Solving",
      "Advanced"
    ],
    "question": "What potential long-term challenge could widespread adoption of the Lightning Network pose to Bitcoin's security model?\nA) Increased energy consumption for mining\nB) Reduced transaction fees for miners\nC) Higher barriers to entry for new users\nD) Slower confirmation times for on-chain transactions",
    "answer": "B"
  },
  {
    "id": "066",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "In a unilateral channel closure on the Lightning Network, what protects against the broadcast of an outdated channel state?\nA) Proof-of-stake consensus\nB) Increased mining difficulty\nC) Penalty mechanisms using revocation keys\nD) Automatic refunds to both parties",
    "answer": "C"
  },
  {
    "id": "067",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the primary advantage of using Channel Factories in the Lightning Network?\nA) They eliminate the need for Bitcoin altogether\nB) They allow creation of multiple payment channels from a single on-chain transaction\nC) They increase the block size of Bitcoin\nD) They remove the need for payment routing",
    "answer": "B"
  },
  {
    "id": "068",
    "categories": [
      "Bitcoin",
      "Layer 2 Solutions",
      "Privacy",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is a potential privacy vulnerability in the Lightning Network?\nA) All transactions being visible on the blockchain\nB) Channel graph analysis revealing network structure\nC) Miners being able to view all payment details\nD) Mandatory KYC for opening payment channels",
    "answer": "B"
  },
  {
    "id": "069",
    "question": "What is 'SegWit' (Segregated Witness) primarily designed to address in Bitcoin? A) Transaction malleability B) Block size limitation C) Mining centralization D) Wallet security",
    "answer": "A",
    "categories": [
      "Bitcoin",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "070",
    "categories": [
      "Blockchain Fundamental",
      "Consensus Mechanisms",
      "System Design",
      "Advanced"
    ],
    "question": "In a new consensus mechanism designed to solve the 'nothing at stake' problem while maintaining Bitcoin's UTXO model, which of the following would be the MOST critical vulnerability to address?\nA. Long-range attacks where validators can rewrite a significant portion of the blockchain\nB. Short-term forks due to network latency between validators\nC. Centralization of stake in the hands of a few large token holders\nD. Increased blockchain bloat due to more complex transaction structures",
    "answer": "A"
  },
  {
    "id": "071",
    "categories": [
      "Blockchain Fundamental",
      "Layer 2 Solutions",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "In the proposed Layer 2 scaling solution combining aspects of Lightning Network, Sidechains, and Zero-Knowledge proofs, which of the following would pose the GREATEST security risk?\nA. A bug in the zero-knowledge proof generation or verification system\nB. Network partitions between the main chain and the sidechain\nC. Users failing to come online to monitor for potential fraud\nD. Liquidity issues preventing large withdrawals from the sidechain",
    "answer": "A"
  },
  {
    "id": "072",
    "categories": [
      "Blockchain Fundamental",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which property of digital signatures ensures that a transaction cannot be altered after it is signed?\nA) Authorization\nB) Non-repudiation\nC) Integrity\nD) Flexibility",
    "answer": "C"
  },
  {
    "id": "073",
    "categories": [
      "Blockchain Fundamental",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ],
    "question": "In the Schnorr Identity Protocol, what does the verifier (Bob) use to ensure that only the prover (Alice) who knows the private key could have generated the signature?\nA) Bob checks Alice's public key against a database of valid keys.\nB) Bob computes the scalar values for the nonce and challenge, comparing the result.\nC) Bob reconstructs Alice's private key using the nonce.\nD) Bob multiplies the private key by the generator to verify the signature.",
    "answer": "B"
  },
  {
    "id": "074",
    "categories": [
      "Blockchain Fundamental",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is a key benefit of combining SIGHASH_ANYONECANPAY with other SIGHASH flags?\nA) It restricts the signature to specific outputs only.\nB) It allows multiple participants to add inputs and sign their own portion of the transaction.\nC) It increases the computational complexity of the signature.\nD) It ensures that only one input can be added to the transaction.",
    "answer": "B"
  },
  {
    "id": "075",
    "categories": [
      "Blockchain Fundamental",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ],
    "question": "In the simplified Schnorr Identity Protocol using integers, what is the main operation that ensures security?\nA) Multiplication is easy, but division is hard, preventing reverse engineering of the private key.\nB) Addition of the public key and nonce ensures the signature's validity.\nC) Using prime numbers ensures that the signature cannot be tampered with.\nD) Division of the public key by the nonce ensures privacy.",
    "answer": "A"
  },
  {
    "id": "076",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is a trade-off introduced by the use of Golomb-Rice Coded Sets (GCS) in compact block filters?\nA) Increased privacy at the cost of potentially higher bandwidth usage\nB) Reduced network latency at the expense of larger block sizes\nC) Improved transaction speed but with higher fees\nD) Enhanced security but with slower block validation",
    "answer": "A"
  },
  {
    "id": "077",
    "categories": [
      "Blockchain Fundamental",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a decentralized oracle network for providing real-world data to smart contracts. The system needs to ensure data accuracy, timeliness, and resistance to manipulation. Which combination of mechanisms would provide the highest level of security and reliability for this oracle network?\n\na) Use a single trusted data provider, implement instant data updates, store all data on-chain, and allow any user to submit data updates\nb) Implement a decentralized network of data providers, use a reputation system with slashing for inaccurate data, implement a challenge period for data disputes, and use a median value with outlier rejection\nc) Use a centralized API for data feeds, implement a time delay for all data updates, require KYC for all data providers, and use the first submitted value for each update\nd) Implement a random selection of data providers for each update, use the average of all submitted values, store data off-chain with hashes on-chain, and require manual verification for extreme values",
    "answer": "b"
  },
  {
    "id": "078",
    "categories": [
      "Blockchain Fundamental",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A developer is implementing a decentralized storage solution that combines on-chain incentives with off-chain storage. The system needs to ensure data availability, resist censorship, and provide economic incentives for storage providers. Which combination of techniques would best achieve these goals?\n\na) Use a centralized storage provider, implement a fixed fee structure for all uploads, store file hashes on-chain, and rely on the storage provider for all data retrievals\nb) Implement a proof-of-replication consensus mechanism, use erasure coding for data redundancy, implement a challenge-response protocol for data availability checks, and use a token-based incentive model with slashing for malicious behavior\nc) Use a distributed hash table for data storage, implement a flat pricing model for all data sizes, store full file contents on-chain, and use a lottery system for selecting storage providers\nd) Implement a proof-of-storage consensus, use a centralized indexer for file locations, store all metadata off-chain, and use a fixed set of trusted storage providers",
    "answer": "b"
  },
  {
    "id": "079",
    "categories": [
      "Blockchain Fundamental",
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a next-generation smart contract platform that aims to solve the blockchain trilemma (scalability, security, and decentralization) while providing advanced features for DeFi and Web3 applications. The platform needs to support the following features:\n\n1. High throughput and low latency transactions\n2. Strong security guarantees and formal verifiability\n3. Cross-chain interoperability and asset bridging\n4. Privacy-preserving smart contracts and transactions\n5. Quantum-resistant cryptography\n6. On-chain governance with efficient proposal execution\n7. Sustainable and energy-efficient consensus mechanism\n8. Advanced identity and reputation systems\n\nConsidering the complex requirements and the need for long-term sustainability, which combination of technologies, cryptographic primitives, and design choices would create the most robust, secure, and future-proof smart contract platform?\n\na) Use a sharded blockchain with a beacon chain for coordination, implement zk-STARKs for scalability and privacy, use lattice-based cryptography for quantum resistance, implement a hybrid PoS/PoW consensus mechanism, use threshold signatures for cross-chain communication, implement a layer-2 solution with optimistic rollups, use attribute-based encryption for identity management, and implement a futarchy-based governance system\nb) Implement a DAG-based structure with asynchronous Byzantine fault tolerance, use fully homomorphic encryption for private smart contracts, implement post-quantum digital signatures, use a pure Proof of Stake consensus with VDFs for randomness, implement a universal composability framework for cross-chain interactions, use zero-knowledge proofs for scalable state transitions, implement self-sovereign identity with verifiable credentials, and use liquid democracy for governance\nc) Use a multi-chain architecture with a hub-and-spoke model, implement zk-SNARKs with recursive composition for scalability, use multivariate cryptography for quantum resistance, implement a Proof of Authority consensus with rotating validators, use hash-locking for cross-chain atomic swaps, implement a sidechain for high-frequency transactions, use ring signatures for privacy-preserving transactions, and implement quadratic voting for governance\nd) Implement a hybrid blockchain/DAG structure with a probabilistic consensus mechanism, use a combination of zk-STARKs and bulletproofs for privacy and scalability, implement stateless clients with succinct state proofs, use supersingular isogeny-based cryptography for quantum resistance, implement a cross-chain communication protocol based on IBC (Inter-Blockchain Communication), use Boneh-Lynn-Shacham (BLS) signatures for efficient validator aggregation, implement a layer-2 solution with validity proofs, use zero-knowledge sets for revocation, and implement conviction voting with adaptive quorum biasing for governance",
    "answer": "d"
  },
  {
    "id": "080",
    "categories": [
      "Blockchain Fundamental",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In a decentralized reputation system, where users' reputations are stored on-chain, a vulnerability was found that allows malicious users to create multiple identities to artificially inflate their reputation scores. Additionally, users have been repeatedly submitting small updates to avoid detection by the rate limiter. What is the most critical measure to prevent manipulation and secure the system?\nA) Increase the rate limit for reputation updates\nB) Implement Sybil attack resistance and enforce stricter rate limiting controls\nC) Enable all users to verify their reputation updates manually\nD) Remove access controls for reputation changes to reduce centralization risks",
    "answer": "B"
  },
  {
    "id": "081",
    "categories": [
      "Blockchain Fundamental",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A blockchain project is experiencing a 'block stuffing' attack, where malicious actors fill entire blocks with their transactions, preventing time-sensitive operations from being processed in time. The project relies heavily on block gas limits for congestion control but has no alternative mechanism to handle such attacks. What is the most effective approach to mitigate this issue?\nA) Implement commit-reveal schemes for time-sensitive operations and avoid reliance on block gas limits\nB) Increase the block gas limit to allow more transactions to be processed\nC) Allow users to pay higher gas fees to prioritize their transactions\nD) Remove time-sensitive operations from the project to avoid congestion issues",
    "answer": "A"
  },
  {
    "id": "082",
    "question": "In a multi-agent scenario where several LLM-powered agents collaborate to complete a complex task, how can game theory be used to incentivize each agent to complete their part efficiently and prevent 'free-riding'?\nA. Implement a token reward system that penalizes agents who fail to complete their tasks\nB. Use a reputation system where agents with higher success rates get more complex tasks\nC. Introduce a contract where agents are paid equally regardless of their individual contributions\nD. Allow agents to vote on the distribution of rewards after task completion",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "083",
    "question": "In a scenario where an agent subcontracts a task to other agents, how can a chain of responsibility be established to ensure accountability for the outcome?\nA. Use a centralized task management system to monitor the progress of all agents\nB. Implement a blockchain ledger that records each agent’s responsibility for task completion\nC. Allow agents to report each other's progress in real-time\nD. Let the subcontractor bear full responsibility for the entire task",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "084",
    "question": "How can a multi-agent verification system prevent collusion or fraud between agents when confirming task completion?\nA. Use majority voting where agents collectively agree on task completion\nB. Introduce randomized audits from external agents to verify task results\nC. Implement a trust-based system where only trusted agents are assigned tasks\nD. Allow agents to monitor each other in real-time and report any fraudulent activities",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "085",
    "question": "LLM-powered agents rely on dynamic data from the real world. How can a real-time verification system be designed to ensure accuracy and timeliness of external inputs?\nA. Use smart contracts that allow for real-time updates from trusted data sources\nB. Allow agents to update each other’s data inputs manually\nC. Use a centralized server to control and validate all incoming data\nD. Implement decentralized oracles that verify and cross-check external data sources",
    "answer": "D",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "086",
    "question": "How can collaborative LLM-powered agents be incentivized to contribute their fair share to a shared task?\nA. Implement a reward-sharing system based on the amount of work done by each agent\nB. Allow agents to bid on tasks and compete for rewards\nC. Require agents to vote on the distribution of rewards after completing the task\nD. Use a fixed reward system where all agents are paid equally, regardless of their contributions",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "087",
    "question": "LLM-powered agents may receive multi-modal inputs (such as vision, language, and sensor data). How can a coordination system be designed to synchronize these inputs?\nA. Use centralized servers to manage and validate all inputs\nB. Implement decentralized data fusion algorithms that integrate multi-modal inputs in real-time\nC. Allow agents to independently process each data type and make decisions based on one input\nD. Use majority voting among agents to decide which input is most accurate",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "088",
    "question": "How can historical reputation systems ensure that LLM-powered agents can secure future high-value tasks based on previous performance?\nA. Use decentralized reputation systems that track agent performance across tasks\nB. Implement a token-based system where agents must bid for future tasks\nC. Allow agents to manually report their own task history for future job consideration\nD. Use human auditors to assess agent performance and decide future task assignments",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "089",
    "question": "How can LLM-powered agents incorporate self-supervision and feedback loops to improve task execution quality?\nA. Use decentralized feedback systems where other agents review and score task performance\nB. Implement real-time self-monitoring systems that detect and correct errors during execution\nC. Allow agents to manually review their own work after completing the task\nD. Use a centralized server to monitor all agents and provide feedback",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "090",
    "question": "In a task where multiple agents collaborate and supervise one another, how can game theory be applied to prevent collusion or fraudulent task reports?\nA. Introduce financial penalties for agents caught in collusion\nB. Use majority voting to ensure that all agents agree on task outcomes\nC. Implement reputation systems that reward honest behavior and punish collusion\nD. Allow agents to report fraudulent behavior anonymously",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "091",
    "question": "How can LLM-powered agents accurately predict task completion time based on historical data and complexity?\nA. Use machine learning algorithms to analyze historical data and make real-time predictions\nB. Allow agents to manually estimate task completion time\nC. Implement decentralized reputation systems where agents’ previous performance is reviewed\nD. Use a fixed time model where all tasks are assumed to take the same amount of time",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "092",
    "question": "In a blockchain using a Merkle tree with 8 leaf nodes, how many hashes need to be provided to prove that a specific transaction is included in the block? A) 2 B) 3 C) 4 D) 8",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "093",
    "question": "If a dApp uses Ceramic Network for decentralized data management and each user interaction creates a 1KB stream update, how many stream updates can be processed in a day if the network can handle 100 TPS? A) 864,000 B) 8,640,000 C) 86,400,000 D) 864,000,000",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "094",
    "question": "What is the primary use of 'Chainlink' in blockchain ecosystems? A) To provide decentralized oracle services B) To increase transaction speed C) To improve mining efficiency D) To create new tokens",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "095",
    "question": "In a particular blockchain, the probability of a block being orphaned increases as a logistic function of its size. If a 1MB block has a 0.1% chance of being orphaned, and the logistic growth rate is 2, what's the orphan risk of an 8MB block? A) 0.8% B) 1.6% C) 3.2% D) 6.4%",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "096",
    "question": "What does 'UTXO' stand for in blockchain technology? A) Unspent Transaction Output B) Unified Transaction X-ray Output C) Unverified Transaction X-chain Output D) Universal Transaction Xchange Operation",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "097",
    "question": "What is a 'node' in a blockchain network? A) A single transaction B) A block of transactions C) A computer running the blockchain software D) A cryptocurrency exchange",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "098",
    "question": "In a sharded blockchain with 64 shards, each shard produces a block every 6 seconds. The main chain, which processes cross-shard transactions, produces a block every 6 seconds as well. If a cross-shard transaction takes 3 main chain block confirmations to finalize and cross-shard transactions account for 20% of all transactions, what's the effective TPS of the network, assuming each shard can process 1000 TPS? A) 51,200 TPS B) 54,400 TPS C) 57,600 TPS D) 60,800 TPS",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "099",
    "question": "If a blockchain implements a state rent mechanism where users must pay to keep their account data stored, and the annual rent is set at 1% of the account balance, how much would a user with 1000 tokens need to pay per day to maintain their account (assuming tokens are indivisible)? A) 0.027 tokens B) 0.274 tokens C) 2.74 tokens D) Cannot be calculated with given information",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "100",
    "question": "What is the primary purpose of a 'private key' in cryptocurrency? A) To receive funds B) To view transaction history C) To sign transactions and prove ownership D) To mine new coins",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "101",
    "question": "If a blockchain has a block size limit of 1MB and an average transaction size of 250 bytes, what is the maximum number of transactions that can be included in a single block? A) 1,000 B) 2,000 C) 4,000 D) 8,000",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "102",
    "question": "In a particular blockchain, transactions are processed in parallel across multiple execution threads. The system uses a deterministic algorithm to assign transactions to threads based on the addresses involved. If there are 32 execution threads and 10,000 active addresses, what's the probability that a randomly chosen trio of addresses will all be assigned to different threads, assuming a uniform distribution? A) Approximately 90.82% B) Approximately 93% C) Approximately 96% D) Approximately 99%",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "103",
    "question": "In a sharded blockchain with 64 shards, each shard produces a block every 6 seconds. If cross-shard transactions take 3 confirmations on the destination shard and account for 10% of all transactions, what's the effective TPS of the network, assuming each shard can process 1000 TPS? A) 51,200 TPS B) 57,600 TPS C) 64,000 TPS D) 70,400 TPS",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "104",
    "question": "What is the main goal of 'sharding' in blockchain technology? A) To improve privacy B) To increase scalability C) To enhance security D) To reduce block time",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "105",
    "question": "What does 'decentralization' mean in the context of blockchain? A) No central authority controls the network B) All nodes are in one central location C) Only a few powerful nodes control the network D) The blockchain is spread across multiple countries",
    "answer": "A",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "106",
    "question": "In a sharded blockchain with 64 shards, each capable of 100 TPS, what is the theoretical maximum cross-shard transaction throughput, assuming each cross-shard transaction involves 2 shards and the cross-shard communication overhead is 20%? A) 6400 TPS B) 2560 TPS C) 1600 TPS D) 5120 TPS",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "107",
    "question": "A decentralized file storage network uses Proof of Replication, where storage providers must prove they are storing unique copies of data. If a provider wants to cheat by storing only one copy of a 1 GB file instead of the required 10 copies, approximately how much computational work (in GB) would they need to perform per challenge to avoid detection, assuming a secure hash function is used? A) 1 GB B) 5 GB C) 10 GB D) 100 GB",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "108",
    "question": "A new blockchain scaling solution called 'Elastic Sharding' is proposed. This solution allows the number of shards to dynamically change based on network load. When the network load exceeds a certain threshold, the number of shards increases; when the load decreases, shards merge. The number of shards N is related to the network load L by the equation: N = ceil(N_base * (L/L_base)^0.5), where N_base is the base number of shards and L_base is the base load. If N_base = 16 and L_base = 1000 TPS, and the current network load is 4000 TPS, how many shards should there be currently? A) 30 B) 31 C) 32 D) 33",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "109",
    "question": "What is a 'genesis block' in a blockchain? A) The most recent block B) The first block in the blockchain C) The largest block D) The block with the most transactions",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "110",
    "question": "What is a 'fork' in blockchain terminology? A) A type of cryptocurrency wallet B) A split in the blockchain resulting in two separate chains C) A method of encrypting transactions D) A way to merge two blockchains",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "111",
    "question": "If a dApp uses a sharded blockchain with 64 shards, each capable of processing 100 transactions per second, what is the theoretical maximum throughput of the entire network? A) 100 TPS B) 1,600 TPS C) 6,400 TPS D) 64,000 TPS",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "112",
    "question": "In a sharded blockchain with 64 shards, if each shard can process 100 transactions per second, what is the theoretical maximum throughput of the entire network? A) 100 tps B) 640 tps C) 6,400 tps D) 64,000 tps",
    "answer": "C",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "113",
    "question": "In a blockchain with an average block time of 10 minutes, approximately how many blocks are added in a 24-hour period? A) 72 B) 144 C) 288 D) 576",
    "answer": "B",
    "categories": [
      "Blockchain Fundamental",
      "Calculation",
      "Beginner"
    ]
  },
  {
    "id": "114",
    "categories": [
      "Consensus Mechanisms",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A developer is implementing a novel consensus mechanism for a sharded blockchain. The mechanism involves dynamic validator selection and cross-shard transactions. Which combination of techniques would best ensure the security, scalability, and liveness of this sharded blockchain system?\n\na) Use a fixed set of validators per shard, implement synchronous cross-shard communication, require full nodes for all participants, and use Proof of Work for consensus\nb) Implement a random beacon for validator selection, use asynchronous cross-shard transactions, store all shard data on the beacon chain, and use a single-secret leader election\nc) Use a VRF for validator assignment, implement optimistic cross-shard transactions with fraud proofs, use erasure coding for data availability, and implement a fisherman's challenge for invalid state transitions\nd) Use a deterministic rotation of validators, implement synchronous cross-shard transactions with atomic commits, store full state for all shards on each node, and use a BFT consensus algorithm",
    "answer": "c"
  },
  {
    "id": "115",
    "categories": [
      "Consensus Mechanisms",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a novel consensus mechanism for a highly scalable blockchain. The mechanism aims to achieve high throughput, low latency, and strong security guarantees. Consider the following design choices:\n\n1. Use of a directed acyclic graph (DAG) for transaction ordering\n2. Implementation of a probabilistic Byzantine fault-tolerant (BFT) protocol\n3. Use of a verifiable random function (VRF) for leader selection\n4. Implementation of a sharding mechanism for parallel transaction processing\n5. Use of zero-knowledge proofs for transaction validation\n6. Implementation of a reputation system for validator nodes\n\nWhich combination of these design choices would create the most robust and secure consensus mechanism, and why?\n\na) 1, 2, 3 - This combination provides efficient transaction ordering, Byzantine fault tolerance, and secure leader selection\nb) 2, 4, 6 - This setup offers Byzantine fault tolerance, scalability through sharding, and incentivized good behavior of validators\nc) 1, 3, 5 - This model combines efficient transaction ordering, secure leader selection, and privacy-preserving transaction validation\nd) 2, 3, 4, 6 - This combination provides Byzantine fault tolerance, secure and fair leader selection, scalability, and long-term stability through reputation management",
    "answer": "d"
  },
  {
    "id": "116",
    "question": "Which consensus mechanism is Bitcoin primarily known for using? A) Proof of Stake B) Proof of Work C) Delegated Proof of Stake D) Practical Byzantine Fault Tolerance",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "117",
    "question": "In a proof-of-stake blockchain using the Algorand consensus protocol, if there are 1 million token holders and each block requires a committee of 1000 validators, what is the probability that a token holder with 0.1% of the total stake will be selected for the committee for a specific block? A) 0.1% B) 1% C) 63.2% D) 99.9%",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "118",
    "question": "In a sharded blockchain with 64 shards, if an attacker controls 25% of the total network stake, what is the probability that they can control a majority (>50%) of validators in a specific shard, assuming random and uniform validator assignment? A) 0.1% B) 1% C) 5% D) 25%",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "119",
    "question": "What is a '51% attack' in the context of blockchain mining? A) When 51% of miners agree on a change B) When a single entity controls more than half of the network's mining power C) When 51% of transactions are rejected D) When the blockchain is split into 51 chains",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "120",
    "question": "In a federated blockchain with 100 nodes, if the Byzantine Fault Tolerance threshold is set at 1/3, how many malicious nodes can the network withstand before consensus becomes impossible? A) 33 B) 34 C) 66 D) 67",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "121",
    "question": "If a blockchain network has a hashrate of 100 EH/s (Exahashes per second) and a single ASIC miner produces 100 TH/s (Terahashes per second), how many such miners would be needed to control 51% of the network's hashrate? A) 510,000 B) 5,100,000 C) 51,000 D) 510",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "122",
    "question": "If a blockchain uses a consensus mechanism where the probability of being selected as a block producer is proportional to the logarithm of the stake, how much more stake does a validator need to double their chances of selection? A) 2 times more B) 4 times more C) 8 times more D) 16 times more",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "123",
    "question": "If a Proof of History blockchain can generate 400,000 sequential hashes per second, and it takes 1 million hashes to create a new block, what's the theoretical maximum number of blocks that can be created per minute? A) 6 B) 12 C) 24 D) 48",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "124",
    "question": "If a Proof of Space blockchain requires miners to plot 100GB to have a 0.1% chance of winning a block, approximately how much total storage is dedicated to the network if there are 10,000 active miners? A) 100TB B) 1PB C) 10PB D) 100PB",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "125",
    "question": "In a sharded blockchain with 512 shards, each shard has 200 validators. The network implements a 'rotational validation' mechanism where validators are reassigned to different shards every epoch. If an attacker controls 12% of the total validator set, what's the probability they will control a majority in at least one shard in a given epoch? A) Less than 1% B) Approximately 5% C) Approximately 10% D) More than 15%",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "126",
    "question": "What is the purpose of 'mining' in proof-of-work blockchains? A) To create new cryptocurrencies B) To validate and add new transactions to the blockchain C) To encrypt transactions D) To store transaction data",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "127",
    "question": "In a blockchain using a Verifiable Random Function (VRF) for leader election, if the VRF output is 256 bits and the target threshold is 2^240, what is the probability of a validator being selected as the leader for a given slot? A) 1/65536 B) 1/16 C) 1/256 D) 1/4096",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "128",
    "question": "If a Proof of Stake blockchain has 1 million staked tokens and aims for 10,000 blocks per day, what is the expected number of blocks a validator with 1000 staked tokens will produce in a year? A) 365 B) 3,650 C) 36,500 D) 365,000",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "129",
    "question": "In a Proof of Stake system, if a validator has staked 5% of the total staked tokens, what is the probability that they will be chosen to validate the next block? A) 5% B) 10% C) 20% D) 50%",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "130",
    "question": "A cryptocurrency uses a proof-of-work system where miners must find a nonce such that H(block_header || nonce) < target, where H is a hash function. If the target is decreased by a factor of 16, approximately how much more computational effort is required on average? A) 4 times B) 8 times C) 16 times D) 256 times",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "131",
    "question": "What is the primary purpose of a consensus mechanism in blockchain? A) To encrypt data B) To agree on the state of the blockchain C) To mine new coins D) To process transactions faster",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "132",
    "question": "A new consensus mechanism proposes to use a VDF (Verifiable Delay Function) for leader election, where the leader is the validator who computes the VDF output closest to a target value. If the VDF takes 10 seconds to compute and 0.1 seconds to verify, and network propagation takes 0.5 seconds on average, what's the optimal block time to ensure that >99% of honest nodes can verify all VDF outputs before the next block? A) 11.1 seconds B) 15.1 seconds C) 18.6 seconds D) 21.1 seconds",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "133",
    "question": "In a particular blockchain, validators are required to stake both the native token and a basket of other cryptocurrencies. The weight of each validator is determined by a geometric mean of these stakes. If a validator has 100 native tokens and crypto assets worth 10,000 native tokens, what stake of each would maximize their weight? A) 100 native tokens and 10,000 in crypto B) 1,000 native tokens and 1,000 in crypto C) 3,162 native tokens and 3,162 in crypto D) 5,050 native tokens and 5,050 in crypto",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "134",
    "question": "In a proof-of-stake blockchain using the Algorand consensus protocol, if there are 1 million token holders and each block requires a committee of 1000 validators, what is the expected number of blocks a token holder with 0.1% of the total stake will validate in a year (assuming 30-second block times)? A) 105 B) 1,051 C) 10,512 D) 105,120",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "135",
    "question": "A blockchain uses a consensus mechanism where validators are selected based on a combination of their stake and their historical uptime. If a validator has 1% of the total stake and 99.9% uptime, while the average validator has 0.1% stake and 99% uptime, how much more likely is this validator to be selected compared to the average? A) 10 times B) 11 times C) 100 times D) 110 times",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "136",
    "question": "In a blockchain using a Delegated Proof of Stake (DPoS) consensus with 21 active validators, if a super-representative (validator) fails to produce a block when it's their turn, what is typically the minimum number of missed blocks before they are automatically disqualified? A) 1 block B) 3 blocks C) 21 blocks D) 63 blocks",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "137",
    "question": "In a Proof of Authority network with 100 authorities, if each authority has a 1% chance of being compromised, what's the probability that at least 51 authorities remain uncompromised? A) 99.99% B) 99.43% C) 96.82% D) 91.13%",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "138",
    "question": "A new consensus mechanism proposes to use a combination of Verifiable Delay Functions (VDFs) and Verifiable Random Functions (VRFs) for leader election. VDF output determines eligibility, while VRF output determines priority among eligible validators. What could be a potential advantage of this approach? A) Improved resistance to adaptive adversaries B) Reduced block time variance C) Lower hardware requirements for validation D) Increased throughput",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "139",
    "question": "In a particular blockchain using a BFT consensus mechanism, the probability of a round failing to reach consensus is p. If the blockchain requires f+1 consecutive successful rounds to finalize a block, where f is the maximum number of Byzantine nodes, what is the expected number of rounds needed to finalize a block? A) (1-p)^(-f-1) B) (1-p)^(f+1) C) (1-p^(f+1))^(-1) D) p^(-f-1)",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "140",
    "question": "If a blockchain implements a consensus mechanism where nodes must solve a computational puzzle and find a solution within a certain range to propose a block, and the difficulty is adjusted so that a solution is found every 10 seconds on average, what's the probability that no solution is found within 1 minute? A) 0.25% B) 2% C) 20% D) 50%",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "141",
    "question": "If a blockchain uses a consensus mechanism where the probability of being selected as a block producer is proportional to the cube root of the stake, how much more stake does a validator need to increase their chances of selection by 8 times? A) 64 times more B) 512 times more C) 729 times more D) 1000 times more",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "142",
    "question": "What is 'Delegated Proof of Stake' (DPoS)? A) A variant of PoS where token holders vote for block producers B) A type of PoW mining C) A consensus mechanism that doesn't use staking D) A method for delegating mining power",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "143",
    "question": "Which consensus mechanism does Bitcoin primarily use? A) Proof of Stake B) Proof of Work C) Delegated Proof of Stake D) Proof of Authority",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "144",
    "question": "In a particular blockchain network, blocks are produced every 10 seconds on average. The network implements a difficulty adjustment algorithm that changes the difficulty every 100 blocks based on the time taken for those 100 blocks. If a major mining pool controlling 30% of the network hashrate goes offline, approximately how long will it take for the block time to return to 10 seconds? A) 16.67 minutes B) 23.81 minutes C) 33.33 minutes D) 47.62 minutes",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "145",
    "question": "In a hybrid consensus mechanism that combines Proof of Work and Proof of Stake, if 60% of block production is controlled by PoS validators and 40% by PoW miners, what percentage of the total stake would an attacker need to control to have a 51% influence on the network (assuming they control no hash power)? A) 30.6% B) 51% C) 60% D) 85%",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "146",
    "question": "What is 'Proof of Authority' (PoA) consensus? A) A mechanism where authority figures validate transactions B) A variant of PoW where miners prove their authority C) A consensus mechanism based on identity as a stake D) A system where the oldest network participants have authority",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "147",
    "question": "What is 'mining difficulty' in Proof of Work? A) The complexity of mining equipment B) The cost of mining C) A measure of how hard it is to find a new block D) The difficulty of writing mining software",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "148",
    "question": "In a Proof of Stake system, if the expected return is 5% per year and there's a 1% chance of being slashed 30% of the stake for a violation, what's the minimum return needed to offset this risk? A) 5.3% B) 5.6% C) 6.0% D) 6.3%",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "149",
    "question": "What is 'Delegated Proof of Stake' (DPoS) designed to improve? A) Network security B) Transaction privacy C) Governance and scalability D) Smart contract functionality",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "150",
    "question": "If a blockchain uses a Verifiable Random Function (VRF) for leader selection where each validator's probability of being chosen is proportional to their stake, and there are 100 validators with equal stake, what's the probability that a specific validator is chosen for 3 out of 10 consecutive blocks? A) 0.03% B) 0.3% C) 3% D) 30%",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "151",
    "question": "A blockchain implements a 'difficulty bomb' that doubles the mining difficulty every 100,000 blocks. If the current average block time is 15 seconds and the bomb has just been activated, approximately how long will it take for the average block time to reach 1 minute, assuming no changes in hash rate? A) 17.4 days B) 34.7 days C) 69.4 days D) 138.9 days",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "152",
    "question": "A cryptocurrency uses a proof-of-stake consensus mechanism where the probability of being chosen to produce the next block is proportional to the amount of currency held. What potential issue does this create compared to proof-of-work? A) 51% attacks become more expensive B) The rich get richer, leading to centralization C) Block production becomes slower D) Transaction fees increase",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "153",
    "question": "In a Proof of Work blockchain with a current hash rate of 100 EH/s, approximately how many hashes must a miner with 1% of the network's hash rate compute to have a 63.2% chance of mining a block? A) 6.93 x 10^20 B) 6.93 x 10^18 C) 6.93 x 10^16 D) 6.93 x 10^14",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "154",
    "question": "In a Delegated Proof of Stake system, if there are 100 delegate candidates and 1 million token holders, and each token holder can vote for up to 30 candidates, what's the maximum number of votes a single candidate could receive? A) 1 million B) 30 million C) 33.33 million D) 100 million",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "155",
    "question": "In a blockchain using Avalanche consensus, each node samples K other nodes during each round of voting. If there are N nodes in the network and the threshold for consensus is α, what's the probability that a single malicious node can influence the outcome of a vote, assuming it's selected in the sample? A) (K/N)^α B) 1 - (1-K/N)^α C) K/(αN) D) α/(KN)",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "156",
    "question": "In a Proof of Capacity consensus where the chance of mining a block is proportional to the amount of storage pledged, if a miner with 10TB of storage mines on average 1 block per day, approximately how much storage would be needed to mine 10 blocks per day? A) 50TB B) 100TB C) 200TB D) 1PB",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "157",
    "question": "In a blockchain network using Proof of Stake, if a validator has 10% of the total staked tokens and the network has a 5% annual inflation rate, what is the validator's expected annual return before considering operating costs and assuming perfect performance? A) 5% B) 10% C) 0.5% D) 15%",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "158",
    "question": "In a blockchain using Proof of Elapsed Time (PoET), if the average wait time is set to 5 minutes and there are 1000 nodes, what's the probability that a specific node will win the right to create the next block? A) 0.1% B) 0.2% C) 0.5% D) 1%",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "159",
    "question": "In a Delegated Proof of Stake system with 21 active block producers, what percentage of producers need to be compromised to potentially halt the network? A) 34% B) 51% C) 67% D) 100%",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "160",
    "question": "If a Proof of Work blockchain's difficulty adjustment aims for a 10-minute block time and the actual average over the last 2016 blocks was 8 minutes, what will be the approximate percentage change in difficulty? A) 20% decrease B) 20% increase C) 25% increase D) 25% decrease",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "161",
    "question": "A new consensus mechanism proposes to use a VDF (Verifiable Delay Function) for leader election. If the VDF takes 5 seconds to compute and 0.1 seconds to verify, and network propagation takes 0.5 seconds on average, what's the optimal block time to ensure that >99% of honest nodes can verify the leader election before the next block? A) 5.6 seconds B) 6.1 seconds C) 6.6 seconds D) 7.1 seconds",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "162",
    "question": "A new consensus mechanism proposes to use a combination of Proof of Stake and Proof of Work, where PoS is used for validator selection and PoW for block production. What could be a potential issue with this hybrid approach? A) Increased energy consumption B) Reduced transaction throughput C) Potential centralization due to high hardware requirements D) Incompatibility between PoS and PoW incentive structures",
    "answer": "D",
    "categories": [
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "163",
    "question": "In a Proof of Importance system, if a node's importance score is calculated as (stake * 20%) + (transaction volume * 30%) + (net transfer volume * 50%), what's the importance score of a node with 1000 tokens staked, 5000 tokens transacted, and a net transfer of 2000 tokens? A) 2300 B) 2700 C) 3100 D) 3500",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "164",
    "question": "In a proof-of-work blockchain, if the current mining difficulty is such that it takes an average of 1 million hashes to find a valid block, and a miner can perform 10,000 hashes per second, what is the probability that the miner will find a valid block within 1 minute? A) 0.45 B) 0.55 C) 0.63 D) 0.78",
    "answer": "A",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "165",
    "question": "A new consensus mechanism proposes to use a combination of Proof of Stake and Proof of History, where validators must produce a sequential proof of history and stake tokens. If generating a proof of history takes 0.2 seconds and verifying it takes 0.02 seconds, what's the maximum number of validators the network can support while maintaining a 2-second block time, assuming network latency is 0.1 seconds? A) 84 validators B) 85 validators C) 86 validators D) 87 validators",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "166",
    "question": "What is the purpose of a 'nonce' in Proof of Work mining? A) To sign transactions B) To encrypt the block data C) To adjust the block's hash to meet the difficulty target D) To verify the miner's identity",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "167",
    "question": "If a blockchain implements a 'difficulty bomb' that doubles the mining difficulty every 100,000 blocks, starting from block 5,000,000, at which block number will the difficulty be 32 times the original? A) 5,300,000 B) 5,400,000 C) 5,500,000 D) 5,600,000",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "168",
    "question": "A blockchain uses a Verifiable Delay Function (VDF) that takes 5 minutes to compute on specialized hardware. If an attacker gains access to hardware that can compute the VDF 10 times faster, how does this affect the security of the network? A) It has no effect on security B) It allows the attacker to predict future random numbers C) It enables the attacker to produce blocks faster D) It makes the attacker's transactions confirm quicker",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "169",
    "question": "What is a 'validator' in Proof of Stake systems? A) A miner B) A node that verifies transactions and creates new blocks C) A smart contract auditor D) A blockchain explorer",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "170",
    "question": "If a blockchain implements a 'slashing' mechanism in its proof-of-stake protocol, where validators lose 30% of their stake for double signing, how much total stake would be lost if 5 validators, each with 1000 coins staked, were caught double signing? A) 300 coins B) 1000 coins C) 1500 coins D) 5000 coins",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "171",
    "question": "In a proof-of-work blockchain, if the current hash rate is 100 EH/s and a new ASIC miner is released that is twice as efficient as current models, what percentage of the current miners need to upgrade to the new hardware to increase the network's hash rate to 150 EH/s? A) 25% B) 33% C) 50% D) 75%",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "172",
    "question": "What is 'Proof of Authority' (PoA) consensus primarily used for? A) Public blockchains B) Private or consortium blockchains C) DeFi platforms D) NFT marketplaces",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "173",
    "question": "If a Proof of Stake blockchain requires validators to have a minimum of 32 tokens staked and has a maximum of 256 validators per committee, what's the theoretical maximum number of unique validators the network can support with 1 million total tokens? A) 7,812 B) 15,625 C) 31,250 D) 62,500",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "174",
    "question": "In a Proof of Reputation system where reputation scores range from 0 to 100, if the probability of being selected as a block producer is proportional to the square of the reputation score, how many times more likely is a node with a score of 90 to be selected compared to a node with a score of 30? A) 3 times B) 6 times C) 9 times D) 81 times",
    "answer": "C",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "175",
    "question": "A proof-of-stake blockchain implements a slashing mechanism where validators lose 3% of their stake for downtime and 10% for equivocation. If a validator with 1000 tokens staked experiences 5 downtime incidents and 1 equivocation in a month, how many tokens will they have left? A) 750 tokens B) 765 tokens C) 825 tokens D) 850 tokens",
    "answer": "B",
    "categories": [
      "Consensus Mechanisms",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "176",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ],
    "question": "In elliptic curve cryptography used in Bitcoin, what is the result of adding a point P to its inverse -P on the curve?\nA. 2P\nB. The point at infinity\nC. The original point P\nD. A new point with x-coordinate 0",
    "answer": "B"
  },
  {
    "id": "177",
    "categories": [
      "Cryptography",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In a secure multi-party computation (MPC) system, participants collaborate to compute a result without revealing their private inputs. Recently, some participants have colluded to influence the computation’s outcome, leading to biased results. Furthermore, incomplete computations have not been handled properly, stalling the process for other participants. What should be the main focus to secure this system?\nA) Use random timeouts for critical operations to ensure fairness\nB) Allow participants to resubmit their inputs in case of an incomplete computation\nC) Implement protection against collusion attacks and ensure proper error handling for incomplete computations\nD) Use a majority-based voting system to resolve any disputes among participants",
    "answer": "C"
  },
  {
    "id": "178",
    "question": "Which of the following is NOT a property of a cryptographically secure hash function? A) Preimage resistance B) Second preimage resistance C) Collision resistance D) Reversibility",
    "answer": "D",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "179",
    "question": "A cryptosystem uses a 256-bit key. Assuming a brute-force attack can test 1 billion keys per second, approximately how long would it take to exhaust the entire keyspace? A) About 1 year B) About 100 years C) About 1 million years D) About 1 billion years",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "180",
    "question": "In a Schnorr signature scheme over a group of prime order q, how many random bits are typically needed to generate the nonce for each signature? A) log q B) q C) 2q D) q^2",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "181",
    "question": "A new symmetric encryption scheme claims to be quantum-resistant because it uses a 512-bit key. Which of the following statements is most accurate? A) The scheme is definitely quantum-resistant due to the large key size B) The scheme might be broken by Shor's algorithm C) The scheme provides 256 bits of security against quantum attacks D) The scheme needs to be at least 1024 bits to be quantum-resistant",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "182",
    "question": "A post-quantum key exchange protocol based on the learning with errors (LWE) problem uses matrices of dimension n x n over a field with q elements. If n = 1024 and q ≈ 2^30, approximately how many bits are needed to represent the public key? A) 2^20 bits B) 2^30 bits C) 2^40 bits D) 2^50 bits",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "183",
    "question": "In a multi-party computation protocol, n parties want to compute a function of their inputs without revealing the inputs to each other. What is the minimum number of honest parties required to ensure security if up to t parties can be malicious, assuming t < n/2? A) t+1 B) n-t C) n/2 D) n-1",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "184",
    "question": "What is the primary goal of threshold cryptography? A) To increase the encryption speed B) To distribute trust among multiple parties C) To reduce the key size D) To improve resistance against side-channel attacks",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "185",
    "question": "In the context of elliptic curve cryptography, what does the term 'base point' refer to? A) The starting point for key generation B) The point at infinity on the curve C) The lowest point on the curve D) The point with the smallest x-coordinate",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "186",
    "question": "What is the primary goal of a zero-knowledge proof? A) To prove knowledge of information without revealing the information itself B) To encrypt data with zero overhead C) To generate truly random numbers D) To create unbreakable ciphers",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "187",
    "question": "In elliptic curve cryptography, what does the term 'cofactor' refer to? A) The number of points on the curve B) The size of the underlying field C) The ratio between the curve order and the largest prime factor of the order D) The degree of the curve equation",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "188",
    "question": "Which of the following best describes the concept of 'semantic security' in encryption? A) The ciphertext reveals no information about the plaintext except its length B) The encryption key is semantically correct C) The plaintext has a well-defined semantic structure D) The encryption algorithm understands the meaning of the plaintext",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "189",
    "question": "In a Feistel network with 16 rounds, how many times is the round function applied to each half of the data? A) 8 times B) 16 times C) 24 times D) 32 times",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "190",
    "question": "In a homomorphic encryption scheme, if E(m1) * E(m2) = E(m1 + m2), what type of homomorphism is this? A) Additive B) Multiplicative C) Mixed D) Exponential",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "191",
    "question": "In a blind signature scheme, what property allows the signer to sign a message without seeing its content? A) Homomorphism B) Commutativity C) Associativity D) Distributivity",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "192",
    "question": "What is the main principle behind the 'Kerckhoffs's principle' in cryptography? A) The encryption algorithm should be kept secret B) The key should be as long as the plaintext C) The security of the system should rely solely on the secrecy of the key D) Multiple layers of encryption increase security exponentially",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "193",
    "question": "In a multi-party computation protocol for n parties, what is the communication complexity (in rounds) of the BGW protocol for computing any function securely against t < n/3 malicious adversaries? A) Constant B) Logarithmic in n C) Linear in n D) Quadratic in n",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "194",
    "question": "What is the main difference between a block cipher and a stream cipher? A) Block ciphers are faster B) Stream ciphers use larger keys C) Block ciphers encrypt fixed-size blocks of data D) Stream ciphers are more secure",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "195",
    "question": "Which of the following is a characteristic of a cryptographically secure pseudo-random number generator (CSPRNG)? A) It always produces the same sequence of numbers B) It is computationally indistinguishable from a true random sequence C) It is faster than other types of random number generators D) It produces only prime numbers",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "196",
    "question": "A zero-knowledge proof system has a proving time of 5 seconds, verification time of 0.1 seconds, and proof size of 1 KB. If you need to prove the correctness of 1 million operations, what would be more efficient: generating one large proof for all operations, or 1000 proofs for 1000 operations each? Consider both total time and proof size. A) One large proof B) 1000 smaller proofs C) Both are equally efficient D) It depends on the parallel processing capabilities",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "197",
    "question": "A new lightweight block cipher for IoT devices uses a 64-bit block size and a 128-bit key. Approximately how many blocks need to be encrypted before a collision is expected due to the birthday paradox? A) 2^16 B) 2^32 C) 2^64 D) 2^128",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "198",
    "question": "A cryptosystem uses the Chinese Remainder Theorem for decryption. If p = 17 and q = 23, what is the multiplicative inverse of p modulo q? A) 5 B) 7 C) 13 D) 19",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "199",
    "question": "Which of the following best describes the concept of 'forward secrecy' in cryptographic protocols? A) The ability to decrypt future messages B) Protection of past communications even if the long-term key is compromised C) The use of quantum-resistant algorithms D) The prevention of replay attacks",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "200",
    "question": "What is the primary purpose of the Secure Remote Password (SRP) protocol? A) To establish a shared encryption key B) To authenticate a user without sending the password over the network C) To generate one-time passwords D) To encrypt passwords for storage",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "201",
    "question": "Which of the following best describes a 'chosen-ciphertext attack'? A) An attacker can choose the plaintext to be encrypted B) An attacker can decrypt arbitrary ciphertexts C) An attacker can choose ciphertexts and obtain their decryptions D) An attacker can modify the encryption key",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "202",
    "question": "Which of the following best describes the concept of 'indistinguishability obfuscation' in cryptography? A) A technique to make ciphertext indistinguishable from random data B) A method to obfuscate encryption keys C) A theoretical construct for creating unintelligible yet functional programs D) A way to hide the structure of cryptographic algorithms",
    "answer": "C",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "203",
    "question": "In the context of elliptic curve cryptography, what does the term 'scalar multiplication' refer to? A) Multiplying two points on the curve B) Multiplying a point on the curve by an integer C) Multiplying the coordinates of a point D) Multiplying the curve parameters",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "204",
    "question": "In the context of post-quantum cryptography, what is the main principle behind lattice-based cryptography? A) Using high-dimensional mathematical lattices B) Implementing quantum algorithms C) Relying on the hardness of factoring large numbers D) Using elliptic curves over finite fields",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "205",
    "question": "In a secret sharing scheme with threshold t, how many shares are needed to uniquely determine a polynomial of degree t-1? A) t-1 B) t C) t+1 D) 2t-1",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "206",
    "question": "A post-quantum digital signature scheme has public keys of size 1.5 KB, private keys of size 2.5 KB, and signatures of size 2 KB. For an application that needs to verify 1 million signatures per day, approximately how much storage is needed just for the signatures over a year? A) 730 GB B) 365 GB C) 1.5 TB D) 2 TB",
    "answer": "A",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "207",
    "question": "In the context of symmetric encryption, what does the term 'confusion' refer to? A) The complexity of the key schedule B) The relationship between the key and the ciphertext C) The mixing of operations from different algebraic groups D) The diffusion of plaintext bits in the ciphertext",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "208",
    "question": "If a blockchain uses a Schnorr signature scheme for multi-signature transactions, and 100 participants need to sign a transaction, approximately how much space would be saved compared to using individual signatures (assuming each Schnorr signature is 64 bytes and a public key is 32 bytes)? A) 3,168 bytes B) 6,336 bytes C) 9,504 bytes D) 12,672 bytes",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "209",
    "question": "In a zk-SNARK system, if the trusted setup procedure requires at least 100 participants to ensure security, and each participant has a 1% chance of being compromised, what is the probability that the setup remains secure? A) 36.6% B) 63.4% C) 90.4% D) 99.0%",
    "answer": "B",
    "categories": [
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "210",
    "categories": [
      "DAO & Governance",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A DAO is implementing a novel governance system that combines token voting, reputation scores, and quadratic voting. The team is concerned about potential centralization, manipulation, and long-term sustainability. Consider the following design choices:\n\n1. Implement time-locked voting with a decay function\n2. Use a commit-reveal scheme for vote submission\n3. Require stake-weighted quorum for proposal passage\n4. Implement delegate voting with on-chain tracking\n5. Use an off-chain solution for vote counting\n6. Implement a challenge period for executed proposals\n\nWhich combination of these choices would best address the concerns while maintaining decentralization and security?\n\na) 1, 2, 4, 6\nb) 2, 3, 4, 5\nc) 1, 3, 4, 6\nd) 2, 3, 5, 6",
    "answer": "A"
  },
  {
    "id": "211",
    "categories": [
      "DAO & Governance",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a governance system for a major DeFi protocol that aims to balance decentralization, security, and efficiency. The system needs to handle proposal submissions, voting, and execution. Consider the following requirements:\n\n1. Resist governance attacks and vote buying\n2. Ensure informed voting and prevent last-minute large token holder influence\n3. Allow for emergency actions in case of critical vulnerabilities\n4. Provide transparency and auditability of the entire process\n\nWhich combination of mechanisms would best fulfill these requirements while maintaining the protocol's decentralized nature?\n\na) Implement quadratic voting, require token lock-up during voting periods, use a multi-sig wallet for emergency actions, and store all voting data on-chain\nb) Use delegated voting with decay, implement a time-locked voting period with increasing voting power, require code submission with proposals, and use a DAO-controlled pause function\nc) Implement stake-weighted voting, use off-chain voting with on-chain execution, require KYC for large token holders, and give admin keys to a trusted third party\nd) Use one-token-one-vote system, implement instant vote execution, allow for vote changes until the last moment, and use a centralized backup system for emergencies",
    "answer": "B"
  },
  {
    "id": "212",
    "categories": [
      "DAO & Governance",
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a privacy-preserving voting system for DAOs using zero-knowledge proofs. The system needs to ensure vote secrecy, prevent double-voting, and allow for transparent tallying. Which combination of cryptographic techniques and contract design would best achieve these goals?\n\na) Use zk-SNARKs for vote casting, implement a merkle tree for voter registration, use homomorphic encryption for vote aggregation, and implement a verifiable random function for voter anonymity\nb) Use ring signatures for voting, implement a centralized vote counting mechanism, store all votes on-chain in plaintext, and use a trusted setup ceremony for parameter generation\nc) Use blind signatures for voter authentication, implement a commit-reveal scheme for voting, use a centralized mixer for anonymity, and publish all zero-knowledge proofs on-chain\nd) Use fully homomorphic encryption for the entire voting process, implement a centralized key generation ceremony, store all encrypted votes off-chain, and use a multi-party computation protocol for vote tallying",
    "answer": "A"
  },
  {
    "id": "213",
    "categories": [
      "DAO & Governance",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a governance system for a major DeFi protocol that aims to balance decentralization, security, and efficiency. The system needs to handle proposal submissions, voting, and execution. Consider the following code snippet for the vote execution function:\n\n```solidity\nfunction executeProposal(uint256 proposalId) external {\n    Proposal storage proposal = proposals[proposalId];\n    require(block.timestamp > proposal.votingEnds, \"Voting period not ended\");\n    require(!proposal.executed, \"Proposal already executed\");\n    \n    if (proposal.forVotes > proposal.againstVotes) {\n        proposal.executed = true;\n        (bool success, ) = proposal.target.call(proposal.data);\n        require(success, \"Proposal execution failed\");\n    } else {\n        revert(\"Proposal rejected\");\n    }\n}\n```\n\nWhich combination of additional mechanisms and modifications would best enhance the security, fairness, and resistance to governance attacks for this system?\n\na) Implement a time lock for proposal execution, use quadratic voting, add a quorum requirement, and implement a vote delegation system with decay\nb) Use an off-chain voting mechanism with on-chain execution, implement a reputation-based voting power system, add a challenge period for executed proposals, and use a multi-sig wallet for emergency actions\nc) Implement a futarchy-based decision market, use token-locked voting with a vesting period, add a minimum proposal threshold, and implement a ragequit mechanism for minority protection\nd) Use a holographic consensus mechanism, implement a conviction voting system, add a continuous proposal submission and execution model, and use proxy contracts for upgradeable governance logic",
    "answer": "A"
  },
  {
    "id": "214",
    "categories": [
      "DAO & Governance",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In a token-curated registry (TCR) that allows users to stake tokens and vote on whether projects should be included in a curated list, it was discovered that vote-buying activities have become rampant, and there is a lack of dispute resolution for controversial listings. Furthermore, voters who stake significant amounts of tokens seem to wield disproportionate influence, compromising the integrity of the list. What is the most important step to secure the system?\nA) Allow unlimited voting power to users who stake large amounts of tokens\nB) Implement a challenge-response mechanism for disputed listings and introduce protections against vote-buying attacks\nC) Reduce the amount of tokens required for voting to increase participation\nD) Remove all restrictions on voting to allow market forces to determine the final list",
    "answer": "B"
  },
  {
    "id": "215",
    "question": "In a decentralized protocol with millions of users, how can you balance the influence of small token holders against large investors, while ensuring efficient decision-making in a high-stakes environment?\nA. Implement a quadratic voting system that increases the cost of additional votes for large holders\nB. Use a simple majority voting system, where each token represents one vote\nC. Establish a rotating governance committee of randomly selected token holders\nD. Introduce a veto power for large token holders to override community decisions",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "216",
    "question": "Modular smart contracts allow for flexible upgrades but also introduce risks during the transition. What is the best approach to ensure security during upgrades in a decentralized financial protocol?\nA. Allow only the core development team to perform upgrades without governance input\nB. Implement time-locked upgrades, allowing stakeholders to review proposed changes before they are activated\nC. Automatically roll out upgrades without any governance process to avoid delays\nD. Introduce an upgrade committee with full control over upgrade decisions, bypassing token holder voting",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "217",
    "question": "How can a decentralized protocol ensure that governance tokens are distributed fairly and reflect the contributions of different types of participants, such as developers, liquidity providers, and traders?\nA. Distribute tokens equally to all users regardless of their activity\nB. Implement participation-based rewards that distribute tokens based on contributions like liquidity provision or development efforts\nC. Use an airdrop to randomly distribute governance tokens to a subset of users\nD. Limit token distribution to early investors to maintain a stable governance base",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "218",
    "question": "In a decentralized financial protocol, frequent upgrades are necessary but can introduce vulnerabilities. Which governance approach ensures rapid iteration while minimizing the risk of new attack vectors?\nA. Only allow emergency upgrades to be voted on by governance token holders\nB. Introduce a staged upgrade process that requires extensive testing on testnets and multi-signature governance approval before implementation\nC. Perform all upgrades directly on the mainnet without a testing phase to save time\nD. Implement a one-time security audit process for all future upgrades, ensuring trust in all updates",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "219",
    "question": "Decentralized governance can slow innovation due to high coordination costs. What governance model can foster technical innovation without sacrificing inclusiveness?\nA. Introduce a core dev team with permanent decision-making authority over all upgrades\nB. Adopt a hybrid model where technical upgrades are fast-tracked by a smaller technical committee, while broader governance decisions are open to the community\nC. Allow only token holders with a minimum balance to participate in governance to ensure efficiency\nD. Limit voting to quarterly intervals to reduce decision-making complexity",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "220",
    "question": "When upgrading a decentralized trading protocol, how can the protocol minimize disruption to liquidity and maintain user confidence during significant changes?\nA. Allow the protocol to shut down for maintenance during the upgrade\nB. Implement a phased rollout where the old and new versions run in parallel for a transition period\nC. Announce the upgrade but immediately force all users to switch to the new version\nD. Encourage traders to withdraw liquidity before the upgrade to minimize risk",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "221",
    "question": "What mechanism can a protocol use to manage token velocity and ensure that governance tokens remain valuable as governance instruments, rather than becoming speculative assets?\nA. Allow unrestricted trading of governance tokens to maximize liquidity\nB. Implement a staking mechanism where tokens must be locked for a set period to participate in governance\nC. Allow token holders to vote without holding their tokens, preventing them from becoming speculative\nD. Use governance tokens exclusively for voting with no associated financial value",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "222",
    "question": "If a critical vulnerability is found in a decentralized protocol’s smart contracts, how can the protocol design an emergency governance process that balances speed and decentralization?\nA. Allow a pre-selected group of community members to freeze the contract immediately, with no community oversight\nB. Introduce an emergency committee with temporary authority to patch the contract, subject to a community vote afterward\nC. Require a full governance vote before making any changes to the contract, even in emergencies\nD. Automate the governance process so that smart contracts can self-upgrade in case of a vulnerability",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "223",
    "question": "Low voter turnout in decentralized governance can result in a few large token holders dominating decision-making. What mechanism can a protocol implement to increase voter turnout and prevent centralization of governance?\nA. Reward voters with a portion of transaction fees or staking rewards for participating in governance\nB. Automatically redistribute governance tokens from inactive voters to active participants\nC. Disallow small token holders from voting to reduce noise and inefficiency\nD. Cap the voting power of large token holders to equalize the influence of all voters",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "224",
    "question": "As decentralized protocols expand across multiple blockchains, governance becomes more complex. How can a protocol ensure that governance decisions made on one chain are enforced across other chains?\nA. Implement weighted voting where votes from different blockchains are counted separately and only the dominant chain decides\nB. Use cross-chain communication protocols, such as decentralized bridges, to synchronize governance actions across chains\nC. Require each chain to have an independent governance process without cross-chain enforcement\nD. Elect a central governance authority to make decisions on behalf of all blockchains involved",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "225",
    "question": "Many real-world transactions, such as legal obligations or physical asset management, are too complex to be fully automated with smart contracts. How can DAOs balance the need for off-chain processing of complex transactions while maintaining decentralization and autonomy?\nA. Use centralized entities to handle complex off-chain processes\nB. Implement decentralized arbitration mechanisms that operate off-chain but are governed by on-chain rules\nC. Reduce DAO scope to only include simple, fully automatable tasks\nD. Bypass off-chain processes altogether and rely entirely on smart contracts for governance",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "226",
    "question": "Smart contracts struggle with ambiguity and edge cases in real-world scenarios. What mechanism can DAOs use to address the limitations of smart contracts when dealing with complex real-world operations?\nA. Off-chain arbitration mechanisms where human intervention is allowed when smart contracts fail\nB. Rely solely on fully automated smart contracts, even if they cannot handle all edge cases\nC. Require all participants to manually intervene in each smart contract execution\nD. Ignore real-world complexity and use simple on-chain rules for all governance decisions",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "227",
    "question": "In cases where off-chain processes are necessary for DAO operations, how can a DAO ensure that these off-chain activities don’t compromise decentralization?\nA. Assign all off-chain responsibilities to a centralized third-party service\nB. Use decentralized oracles and multi-party verification to ensure transparency and fairness in off-chain processes\nC. Avoid off-chain operations entirely and limit the scope of the DAO\nD. Automate off-chain tasks by converting them to smart contracts",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "228",
    "question": "Real-world assets cannot be fully managed on-chain by DAOs. What approach can DAOs take to bridge the gap between real-world assets and on-chain governance?\nA. Use tokenization to represent real-world assets on-chain while employing decentralized custodians to manage them off-chain\nB. Only manage virtual assets to avoid the complexities of real-world asset management\nC. Centralize all real-world asset management under one trusted authority\nD. Require all physical assets to be converted into digital form before they can be managed by the DAO",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "229",
    "question": "How can DAOs interact with traditional centralized systems (such as legal frameworks) while maintaining decentralization and autonomy?\nA. Establish centralized entities to manage legal compliance on behalf of the DAO\nB. Create hybrid models such as DAO LLCs to combine decentralized governance with legal structures\nC. Avoid any interaction with legal frameworks to maintain full decentralization\nD. Assign legal responsibilities to the most active members of the DAO",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "230",
    "question": "Off-chain processes in a DAO can create information asymmetry, leading to potential governance manipulation. What mechanism can DAOs use to reduce information asymmetry and ensure fairness in off-chain decision-making?\nA. Centralize information flow to a single entity responsible for reporting\nB. Implement decentralized oracle systems and public reporting platforms to provide real-time, verifiable data\nC. Allow only the DAO’s core members to access key off-chain data\nD. Keep off-chain decision-making hidden from the public to prevent over-disclosure",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "231",
    "question": "Real-world decision-making often involves subjective judgment, while smart contracts operate purely on objective rules. How can DAOs incorporate subjective decision-making without undermining the trust and objectivity of on-chain governance?\nA. Allow a trusted centralized authority to make subjective decisions on behalf of the DAO\nB. Implement decentralized arbitration mechanisms or governance committees that handle subjective cases with transparent, on-chain records\nC. Ban all subjective decisions from the DAO’s governance process to maintain objectivity\nD. Use only manual processes to handle subjective decisions without any connection to on-chain governance",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "232",
    "question": "In DAOs, real-world operations still require human intervention for complex or unpredictable events. How can DAOs balance automation with human oversight to ensure effective governance?\nA. Use fully automated governance without any human involvement, regardless of complexity\nB. Implement tiered governance where routine tasks are automated, and complex decisions are escalated to elected human decision-makers\nC. Allow only core team members to manually intervene in case of emergencies\nD. Delegate all decision-making to off-chain arbitrators with no link to on-chain governance",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "233",
    "question": "Unpredictable real-world events, such as natural disasters or regulatory changes, cannot be encoded in smart contracts. How can DAOs design flexible governance mechanisms to handle such events while maintaining on-chain integrity?\nA. Establish emergency powers for elected representatives, with post-event community review\nB. Rely on centralized decision-making bodies to respond to emergencies\nC. Ignore all unpredictable events and rely entirely on pre-defined smart contract rules\nD. Require the entire community to vote on every emergency decision in real time",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "234",
    "question": "Due to the complexity of real-world operations, off-chain processes often lack the transparency of on-chain transactions. How can DAOs ensure that off-chain operations remain transparent and accountable to the governance process?\nA. Trust centralized third parties to provide reports on off-chain activities\nB. Use decentralized oracles to link off-chain actions to on-chain outcomes and publish audit trails on-chain\nC. Allow only select members to have visibility into off-chain operations\nD. Keep off-chain processes private to maintain operational flexibility",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "235",
    "question": "In a DAO, how can you design a mechanism to ensure the trustworthiness and accuracy of external data inputs? Given that off-chain data often comes from third-party providers, how can you balance the trade-off between decentralization and efficiency in oracle networks?\nA. Use a multi-oracle system where data is validated by a majority\nB. Implement a reputation-based scoring system to prioritize trusted oracles\nC. Allow token holders to vote on the validity of off-chain data inputs\nD. Require pre-approved oracles to provide all critical data inputs to minimize errors",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "236",
    "question": "Real-world events are often ambiguous and uncertain, while smart contracts operate on precise, predefined rules. How would you design a DAO to handle ambiguous or uncertain inputs without compromising automation and decentralization?\nA. Implement an arbitration mechanism where trusted community members decide on ambiguous inputs\nB. Allow smart contracts to pause and request human intervention when ambiguity is detected\nC. Utilize oracles that provide probabilistic data to accommodate uncertain inputs\nD. Introduce a fallback mechanism where unresolved inputs are ignored by the system",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "237",
    "question": "In highly automated DAOs, when should you rely on algorithmic rules versus human intervention? How would you design a hybrid governance model to balance automation and human decision-making?\nA. Human intervention should only be allowed in emergency situations where automated systems fail\nB. Allow token holders to periodically vote on key governance decisions, with algorithms handling day-to-day operations\nC. Introduce an elected committee that has the authority to override automated decisions when necessary\nD. Fully rely on automated rules, but provide an audit system for human review",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "238",
    "question": "When a DAO relies on off-chain inputs, how would you design a decentralized verification model to ensure data authenticity and integrity?\nA. Implement a staking system where oracles must stake tokens and are penalized for providing false data\nB. Use a centralized oracle provider that ensures data reliability\nC. Allow participants to submit data and validate it through a majority consensus vote\nD. Automatically accept the first oracle to provide data to avoid delays",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "239",
    "question": "For complex business scenarios involving multi-dimensional inputs, how can a smart contract architecture be designed to adapt to changing real-world needs?\nA. Use modular smart contracts that allow for incremental upgrades through decentralized governance\nB. Implement a static contract system that minimizes external dependencies\nC. Require off-chain consensus for contract changes to be approved\nD. Automatically upgrade contracts based on external oracle data",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "240",
    "question": "How can you design an incentive system to ensure that participants in a decentralized oracle network are motivated to provide accurate data without being influenced by manipulation?\nA. Require oracles to post a bond that can be slashed in case of false data\nB. Use a reputation system that tracks oracle accuracy and rewards consistent performance\nC. Allow only oracles with a certain amount of staked tokens to provide data\nD. Distribute equal rewards to all oracles, regardless of data accuracy",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "241",
    "question": "When a DAO involves real-world actions, how can you design a mechanism to ensure on-chain events and off-chain execution remain synchronized?\nA. Use multi-signature verification to confirm that off-chain actions have been completed before on-chain execution\nB. Allow smart contracts to release funds based on pre-set time delays without verifying off-chain events\nC. Require participants to manually verify each off-chain action through governance votes\nD. Automatically synchronize off-chain actions with on-chain data using real-time IoT sensors",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "242",
    "question": "Smart contracts lack the ability to perceive and adapt to external environments. What technologies could enhance a DAO's ability to sense and respond to real-world conditions?\nA. Introduce decentralized oracle networks that provide real-time data from multiple sources\nB. Use AI to automatically adjust smart contract logic based on external changes\nC. Implement Internet of Things (IoT) devices that feed physical data directly into smart contracts\nD. Allow human administrators to manually input real-world data into smart contracts",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "243",
    "question": "When managing real-world assets, legal and regulatory frameworks may conflict with smart contract execution. How would you design a DAO mechanism that complies with local laws while managing real-world assets?\nA. Use hybrid legal-DAO models where a legal entity oversees compliance while the DAO manages governance\nB. Avoid managing real-world assets altogether to prevent legal conflicts\nC. Implement a centralized control system within the DAO for handling legal compliance\nD. Allow local regulators to directly control relevant smart contracts",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "244",
    "question": "Oracles provide off-chain data to DAOs, but if an oracle provides faulty or fraudulent data, it could severely impact operations. How would you design an emergency response mechanism to quickly recover from oracle failures?\nA. Implement time-delayed transactions to allow for human review before finalizing decisions based on oracle data\nB. Automatically reverse any transaction triggered by an oracle once faulty data is detected\nC. Use a fallback oracle system that switches to a backup oracle in case of failure\nD. Require all transactions to be manually reviewed by the community before approval",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "245",
    "question": "Real-world complexity and variability require a DAO's governance model to have dynamic adjustment capabilities, yet smart contracts are typically static. How can a DAO governance mechanism be designed to automatically adjust rules in response to external changes while ensuring transparency and decentralization?\nA. Implement AI-based governance that monitors external conditions and adjusts smart contract rules automatically\nB. Introduce a hybrid model where key changes are made by a trusted committee while minor changes are automated\nC. Allow token holders to vote periodically on governance rule updates to accommodate external changes\nD. Utilize a modular contract architecture that allows incremental upgrades through decentralized proposals",
    "answer": "D",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "246",
    "question": "Oracles provide off-chain data to DAOs, but ensuring consensus among multiple oracles is challenging. How can you design a decentralized consensus mechanism to achieve agreement based on multiple oracle inputs while preventing collusion or malicious behavior?\nA. Use a reputation system where oracles with higher accuracy rates have more influence\nB. Implement a multi-signature oracle system where a majority of oracles must agree on data\nC. Allow token holders to manually verify oracle inputs through voting\nD. Introduce financial penalties for oracles that provide incorrect data",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "247",
    "question": "In complex DAOs, conflicts may arise between human decisions and automated smart contract rules. How would you resolve conflicts when human decisions contradict automated contract execution while maintaining DAO integrity?\nA. Allow human decisions to override automated contracts under specific conditions\nB. Implement a multi-tier governance structure where conflicting decisions are escalated to a higher authority\nC. Create a fail-safe mechanism that temporarily halts contract execution until conflicts are resolved\nD. Ensure automated contracts always take precedence to avoid human bias",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "248",
    "question": "In a highly automated DAO, if a critical algorithm or process fails, it could have severe consequences for the system. How would you design checks and balances to ensure control over critical decisions and prevent algorithms from 'overreaching' their authority?\nA. Use smart contract kill-switches activated by a decentralized governance vote\nB. Implement an external audit system that regularly evaluates smart contract behavior\nC. Allow core developers to manually intervene in case of emergency\nD. Introduce multi-tiered decision-making where critical algorithms must be approved by human oversight before execution",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "249",
    "question": "DAOs rely on oracles to ensure trustworthy off-chain data inputs. How can you verify the trustworthiness of oracles while maintaining decentralization?\nA. Implement a decentralized reputation system that ranks oracles based on historical accuracy\nB. Allow only pre-approved oracles to provide data, ensuring reliability\nC. Use zero-knowledge proofs to verify the source of oracle data without compromising privacy\nD. Require oracles to stake tokens that can be slashed in case of inaccurate data",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "250",
    "question": "How can a blockchain-based governance system ensure that real-world tasks performed by LLM-powered agents align with on-chain decisions?\nA. Allow token holders to vote on task completion before rewards are distributed\nB. Implement smart contracts that automatically enforce task criteria based on blockchain governance rules\nC. Use a third-party audit system to verify alignment with on-chain governance\nD. Allow agents to self-report task completion based on trust",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "251",
    "question": "In a quadratic funding round with a matching pool of 10,000 DAI, if projects A, B, and C receive 100, 200, and 300 DAI in individual contributions respectively, how much matching funds does project B receive? A) 2,500 DAI B) 3,333 DAI C) 4,000 DAI D) 5,000 DAI",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "252",
    "question": "In a DAO using conviction voting, if the decay rate is 10% per day and a user with 1000 tokens stops supporting a proposal after 5 days, what will their conviction be after 2 more days (assuming initial conviction is token balance)? A) Approximately 655 B) Approximately 729 C) Approximately 810 D) Approximately 900",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "253",
    "question": "If a blockchain implements a quadratic voting mechanism for governance where each additional vote costs twice as much as the previous one, how many total tokens would a user need to cast 5 votes on a single proposal? A) 15 tokens B) 25 tokens C) 35 tokens D) 55 tokens",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "254",
    "question": "A DAO uses a quadratic funding model for internal project funding. If projects A, B, and C receive individual contributions of 100, 200, and 300 tokens respectively, and there's a matching pool of 1000 tokens, how many matching tokens does project B receive? A) 250 B) 333 C) 400 D) 500",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "255",
    "question": "What is 'holographic consensus' in DAO governance? A) A 3D visualization of voting results B) A consensus mechanism using holographic technology C) A system where a small group can pass proposals if there's low opposition D) A method for creating consensus among different DAOs",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "256",
    "question": "A DAO implements a 'rage quit' feature allowing members to exit with their share of assets if they disagree with a proposal. If the DAO has total assets of 10,000 ETH and 1,000,000 governance tokens, how much ETH can a member with 50,000 tokens withdraw? A) 100 ETH B) 250 ETH C) 500 ETH D) 1000 ETH",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "257",
    "question": "If a Proof of Stake blockchain uses a quadratic voting mechanism for governance where each additional vote costs twice as much as the previous one, how many total tokens would a user need to cast 5 votes on a single proposal? A) 15 tokens B) 25 tokens C) 35 tokens D) 55 tokens",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "258",
    "question": "A DAO implements a governance model where voting power is (tokens staked) * (1 + log(staking time in days)). If Alice stakes 1000 tokens for 30 days and Bob stakes 2000 tokens for 10 days, who has more voting power? A) Alice B) Bob C) They have equal voting power D) Need more information",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "259",
    "question": "In a governance mining scheme, if 1000 governance tokens are distributed daily based on liquidity provided, and Alice provides 15% of the total liquidity for half a day, how many governance tokens will she receive? A) 75 B) 100 C) 150 D) 300",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "260",
    "question": "In a DAO with 1 million total tokens, if a governance attack requires 51% of tokens, and an attacker can borrow 400,000 tokens via flash loan but needs to pay 0.1% fee, how many tokens must they already own to succeed? A) 110,000 B) 210,000 C) 310,000 D) 410,000",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "261",
    "question": "A DAO uses a reputation-based voting system where reputation is earned through participation and decays by 1% per week. If a user earns 1000 reputation points and doesn't participate for 6 months, approximately how much reputation will they have left? A) 760 B) 784 C) 807 D) 940",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "262",
    "question": "A DeFi protocol implements a novel governance mechanism where voting power v decays exponentially over time t according to the formula v = v0 * e^(-λt), where λ is the decay constant. If voting power decreases by 10% every 30 days, what's the value of λ? A) 0.0035 B) 0.0070 C) 0.0105 D) 0.0140",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "263",
    "question": "If a governance proposal requires a quorum of 4% of the total token supply and 66% approval to pass, in a DAO with 1 million tokens, what's the minimum number of 'Yes' votes needed for the proposal to succeed? A) 26,400 B) 40,000 C) 66,000 D) 264,000",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "264",
    "question": "In a dApp using Aragon for DAO management, if creating a new DAO costs 0.2 ETH and 1% of users create a DAO, how much ETH would be spent on DAO creation for a dApp with 500,000 users? A) 500 ETH B) 1,000 ETH C) 1,500 ETH D) 2,000 ETH",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "265",
    "question": "In a DAO using delegated voting, if Alice delegates to Bob, Bob delegates to Charlie, and Charlie delegates to Dave, but Dave is inactive during a vote, whose voting power is used? A) Alice's B) Bob's C) Charlie's D) No one's",
    "answer": "D",
    "categories": [
      "DAO & Governance",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "266",
    "question": "If a governance attack requires 51% of tokens, and an attacker can borrow 1 million tokens via flash loan but needs to pay 0.1% fee, how much must they already own to succeed if the total supply is 10 million tokens? A) 4 million B) 4.1 million C) 4.9 million D) 5.1 million",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "267",
    "question": "A DAO implements a governance model where voting power is calculated as (tokens held) ^ 0.5 * (lock time in years + 1). If Alice locks 10,000 tokens for 2 years and Bob locks 40,000 tokens for 1 year, who has more voting power? A) Alice B) Bob C) They have equal voting power D) Need more information",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "268",
    "question": "A DAO implements a governance model where voting power is calculated as (tokens held) * (1 + 0.1 * years of membership). If the DAO is 3 years old and a new member joins with the same number of tokens as a founding member, what percentage of the founding member's voting power does the new member have? A) 75% B) 77% C) 80% D) 83%",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "269",
    "question": "In a liquid democracy model, if Alice delegates her 100 votes to Bob, and Bob delegates his total voting power (including Alice's delegation) to Charlie, how many votes can Charlie cast assuming he had 50 votes originally? A) 150 B) 200 C) 250 D) 300",
    "answer": "C",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "270",
    "question": "In a futarchy model, if a prediction market shows a 70% chance of a proposal increasing token price and a 60% chance of it improving protocol security, but the community values security twice as much as price, should the proposal be implemented? A) Yes B) No C) Need more information D) It's a tie",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "271",
    "question": "A DAO uses a voting system where each voter must stake tokens, and tokens are burned if the voter ends up on the losing side of a vote. If a proposal has 100,000 tokens voted in favor and 50,000 against, and 10% of tokens on the losing side are burned, how many tokens are burned? A) 5,000 B) 10,000 C) 15,000 D) 20,000",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "272",
    "question": "A DAO implements a governance model where voting power is the cube root of tokens held. If there are 1000 token holders each with 1 token, and one whale with 1 million tokens, what percentage of the total voting power does the whale control? A) 9.09% B) 50% C) 90% D) 99%",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "273",
    "question": "A DAO implements a governance attack prevention mechanism where the voting power is the square root of tokens held. If an attacker acquires 51% of the total token supply, what percentage of the voting power do they control? A) 51% B) Approximately 71.4% C) 75% D) 100%",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "274",
    "question": "A DAO implements a governance model where voting power decays over time unless the user participates in votes. If voting power halves every month of inactivity, and a user with 1000 voting power doesn't vote for 3 months, what will their voting power be? A) 125 B) 250 C) 500 D) 750",
    "answer": "A",
    "categories": [
      "DAO & Governance",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "275",
    "question": "What is 'conviction voting' in DAOs? A) Voting based on one's strong beliefs B) A voting system where voting power increases over time C) Voting that requires a conviction record check D) A system to convict malicious voters",
    "answer": "B",
    "categories": [
      "DAO & Governance",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "276",
    "categories": [
      "Dapps",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "An NFT marketplace allows users to buy and sell unique digital assets. However, several front-running attacks have been reported where malicious actors exploit the platform's lack of transaction ordering protection, buying NFTs just before legitimate users and reselling them at a higher price. Additionally, the marketplace lacks a proper dispute resolution mechanism for failed trades. What should the developer prioritize to secure the marketplace?\nA) Implement an escrow mechanism for secure trading and protect against front-running attacks\nB) Allow users to verify trades before completion to reduce failed transactions\nC) Disable all automated trading functions to reduce front-running\nD) Remove the marketplace’s dependency on Ethereum to avoid gas fee issues",
    "answer": "A"
  },
  {
    "id": "277",
    "question": "If a dApp implements lazy loading and reduces initial load time from 5 seconds to 2 seconds, and research shows that every 1 second delay in page load results in a 7% reduction in conversions, what percentage increase in conversions can be expected? A) 14% B) 21% C) 28% D) 35%",
    "answer": "B",
    "categories": [
      "Dapps",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "278",
    "question": "In a dApp using Textile for decentralized data management, if the average user generates 1MB of data per day and the dApp has 100,000 active users, how much new data would need to be stored and replicated across the network each month (assuming 30-day months)? A) 3 TB B) 30 TB C) 300 TB D) 3000 TB",
    "answer": "A",
    "categories": [
      "Dapps",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "279",
    "question": "A decentralized social media platform implements a new 'Attention Mining' mechanism. Users 'mine' by reading, creating, and interacting with content, but the system dynamically adjusts mining difficulty to prevent spam. Difficulty is related to content quality (scored by AI), user reputation, and interaction authenticity (determined by behavior analysis). If the platform has 1 million daily active users, with an average of 100,000 pieces of content created daily, and AI determines that 30% of the content is high-quality while 20% of interactions are deemed inauthentic, what percentage of the daily token distribution should be allocated to attention mining to maximize genuine engagement? A) 15% B) 25% C) 35% D) 45%",
    "answer": "C",
    "categories": [
      "Dapps",
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "280",
    "question": "If a dApp implements a progressive disclosure UX pattern and reduces the number of visible options from 20 to 5, and research shows that each additional option increases decision time by 0.5 seconds, how much time is saved per user interaction? A) 2.5 seconds B) 5 seconds C) 7.5 seconds D) 10 seconds",
    "answer": "C",
    "categories": [
      "Dapps",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "281",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are conducting a threat model for a new DeFi protocol that combines an AMM, lending platform, and yield farming. The protocol interacts with multiple external oracles and allows for complex multi-step transactions. Which of the following approaches would be most effective in identifying and prioritizing security risks?\n\na) Conduct a code audit, implement unit tests, and deploy to a testnet for user testing\nb) Use formal verification, implement fuzzing tests, and conduct a third-party security audit\nc) Create a data flow diagram, identify trust boundaries, analyze the attack surface for each component, develop attack trees for critical functions, and prioritize risks based on impact and likelihood\nd) Implement role-based access control, use SafeMath for all calculations, and add events for all state changes",
    "answer": "c"
  },
  {
    "id": "282",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A DeFi protocol relies on multiple on-chain oracles for price feeds in a critical liquidation function. The team wants to ensure the security and reliability of these price feeds while optimizing for gas efficiency. Consider the following code snippet:\n\n```solidity\nfunction liquidate(address account) external {\n    uint256 price = getPrice();\n    if (isUndercollateralized(account, price)) {\n        _liquidate(account, price);\n    }\n}\n\nfunction getPrice() internal returns (uint256) {\n    uint256[] memory prices = new uint256[](oracles.length);\n    for (uint i = 0; i < oracles.length; i++) {\n        prices[i] = oracles[i].getPrice();\n    }\n    return median(prices);\n}\n```\n\nWhich combination of techniques would provide the strongest protection against oracle manipulation and failures while maintaining gas efficiency?\n\na) Implement a circuit breaker for large price movements, use a Chainlink oracle as a fallback, and cache prices for a set period\nb) Use a weighted median with confidence intervals, implement a TWAP mechanism, and allow for dynamic oracle weights based on historical accuracy\nc) Implement a challenge period for liquidations, use a commit-reveal scheme for oracle updates, and require multi-sig approval for oracle additions/removals\nd) Use zk-SNARKs for price aggregation, implement a reputation system for oracles, and use a bonding curve for oracle stake requirements",
    "answer": "b"
  },
  {
    "id": "283",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a complex smart contract system for a decentralized derivatives platform. The system involves multiple contracts handling collateral management, order matching, and settlement. You need to ensure proper identification and security of trust boundaries. Consider the following system components:\n\n1. Collateral Manager\n2. Order Book\n3. Matching Engine\n4. Settlement Engine\n5. Liquidation Module\n6. Oracle Interface\n\nWhich approach would be most effective in securing the trust boundaries between these components?\n\na) Implement a central registry contract, use delegate calls for all inter-contract interactions, and make all state variables public\nb) Use the same access control mechanism for all contracts, make all functions public, and rely on external calls for inter-contract communication\nc) Create a detailed system diagram, identify data flows, implement specific access controls and validation at each trust boundary, use a proxy pattern for upgradability, and employ event logging for cross-boundary actions\nd) Combine all functionality into a single monolithic contract, avoid external calls, and implement role-based access control",
    "answer": "c"
  },
  {
    "id": "284",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A popular DeFi protocol is experiencing sophisticated gas griefing attacks that exploit complex interactions between multiple contracts. The attackers are using flash loans to manipulate gas prices and block specific transactions. Given the following constraints:\n\n1. The protocol must remain fully on-chain\n2. User experience should not be significantly impacted\n3. The solution should be cost-effective for regular users\n4. The protocol's core functionality cannot be altered\n\nWhich combination of measures would be most effective in mitigating these attacks while satisfying the given constraints?\n\na) Implement a fixed gas price for all transactions, use off-chain computation for complex operations, and limit the number of daily transactions\nb) Use gas tokens for all transactions, implement gas price oracles, and require users to stake tokens before interacting with the protocol\nc) Optimize gas usage in critical functions, implement batch processing with dynamic sorting based on gas price, use a commit-reveal scheme for sensitive operations, and implement a priority queue system with time-weighted gas price averaging\nd) Move all operations to a layer 2 solution, use zk-rollups for transaction verification, and implement gas subsidies for users",
    "answer": "c"
  },
  {
    "id": "285",
    "categories": [
      "DeFi",
      "Tokenomics",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a new DeFi platform with a complex tokenomics model including staking, yield farming, and governance. The team wants to ensure long-term sustainability, security, and resistance to economic attacks. Consider the following mechanisms:\n\n1. Bonding curve for token issuance\n2. Vesting periods for rewards\n3. Quadratic voting for governance\n4. Dynamic reward rates based on total value locked (TVL)\n5. Algorithmic stabilization mechanism\n6. Liquidity mining with time-weighted rewards\n7. Governance-controlled parameter adjustments\n8. Cross-chain bridging and liquidity provision\n\nWhich combination of these mechanisms would create the most robust and secure tokenomics model, and why?\n\na) 1, 2, 3, 6 - This combination provides controlled token issuance, aligns long-term incentives, prevents governance attacks, and incentivizes sustained liquidity provision\nb) 2, 4, 5, 7 - This setup offers flexibility in reward distribution, maintains price stability, and allows for community-driven adjustments to the system\nc) 3, 4, 6, 8 - This model focuses on fair governance, dynamic rewards, and cross-chain interoperability, which may lead to rapid growth but potential instability\nd) 1, 3, 5, 7 - This combination emphasizes controlled issuance, fair governance, price stability, and community control, but may lack in liquidity incentives",
    "answer": "a"
  },
  {
    "id": "286",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized exchange (DEX) is facing sophisticated front-running attacks that exploit subtle timing issues and mempool visibility. The development team wants to implement a solution that minimizes these attacks while maintaining high liquidity and low slippage. Consider the following code snippet for the trade execution function:\n\n```solidity\nfunction executeTrade(uint256 amount, uint256 minReturn, uint256 nonce) external {\n    require(nonce > lastNonce[msg.sender], \"Invalid nonce\");\n    lastNonce[msg.sender] = nonce;\n    uint256 return = performSwap(amount);\n    require(return >= minReturn, \"Slippage too high\");\n    token.transfer(msg.sender, return);\n}\n```\n\nWhich combination of modifications and additional mechanisms would be most effective in mitigating front-running while maintaining the DEX's performance?\n\na) Implement a commit-reveal scheme with a minimum time delay, use batch auctions for trade execution, and add a reputation system for traders\nb) Use a constant product market maker model, implement infinite slippage protection, and execute all trades at the end of each block\nc) Implement an off-chain order book with on-chain settlement, use zk-SNARKs for trade verification, and implement a front-running detection algorithm\nd) Add a small random delay to each transaction, implement a fee-based priority system, and use a time-weighted average price (TWAP) for trade execution",
    "answer": "a"
  },
  {
    "id": "287",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A DeFi protocol implements a complex system of interconnected smart contracts for lending, borrowing, and yield farming. During a security audit, the following vulnerability is discovered in the reward distribution mechanism:\n\n```solidity\nfunction distributeRewards() public {\n    uint256 totalRewards = address(this).balance;\n    for (uint256 i = 0; i < users.length; i++) {\n        uint256 userReward = (totalRewards * userShares[users[i]]) / totalShares;\n        (bool success, ) = users[i].call{value: userReward}(\"\");\n        require(success, \"Reward transfer failed\");\n    }\n}\n```\n\nWhich combination of vulnerabilities and potential attacks is this code most susceptible to, and what would be the most effective way to mitigate them?\n\na) Reentrancy and integer division rounding; Use the pull-over-push pattern and SafeMath library\nb) Gas limitation and front-running; Implement batch processing and a commit-reveal scheme\nc) Reentrancy and gas griefing; Use the checks-effects-interactions pattern and implement a gas limit per iteration\nd) Integer overflow and unchecked return values; Use SafeMath and require statements for each transfer",
    "answer": "c"
  },
  {
    "id": "288",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A decentralized exchange (DEX) is implementing a new automated market maker (AMM) model with concentrated liquidity. The core swap function is as follows:\n\n```solidity\nfunction swap(uint256 amountIn, uint256 minAmountOut, address recipient) external {\n    (uint256 reserveA, uint256 reserveB) = getReserves();\n    uint256 amountOut = getAmountOut(amountIn, reserveA, reserveB);\n    require(amountOut >= minAmountOut, \"Insufficient output amount\");\n    \n    tokenA.transferFrom(msg.sender, address(this), amountIn);\n    tokenB.transfer(recipient, amountOut);\n    \n    updateReserves(reserveA + amountIn, reserveB - amountOut);\n    emit Swap(msg.sender, amountIn, amountOut, recipient);\n}\n```\n\nWhich of the following combinations of additional mechanisms and modifications would provide the highest level of security and efficiency for this AMM?\n\na) Implement a price oracle, use SafeMath for calculations, and add reentrancy protection\nb) Use inline assembly for efficiency, implement a flash loan feature, and add a timelock for large trades\nc) Implement JIT (Just-In-Time) liquidity, use formal verification for core functions, and add slippage protection based on price impact\nd) Use optimistic updates, implement meta-transactions for gas-less swaps, and add a fee-on-transfer token support",
    "answer": "c"
  },
  {
    "id": "289",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A yield farming protocol is experiencing frequent economic attacks that exploit the reward distribution mechanism. The current implementation uses the following formula to calculate user rewards:\n\n```solidity\nfunction calculateRewards(address user) public view returns (uint256) {\n    uint256 userStake = stakes[user];\n    uint256 totalStake = getTotalStake();\n    uint256 timeSinceLastHarvest = block.timestamp - lastHarvestTime[user];\n    \n    return (userStake * rewardRate * timeSinceLastHarvest) / totalStake;\n}\n```\n\nWhich combination of modifications and additional mechanisms would best protect against economic exploits while maintaining fair reward distribution?\n\na) Implement a vesting period for rewards, use a moving average for totalStake, and add an anti-whale mechanism\nb) Use an exponential decay function for rewards, implement a lockup period for stakes, and add a dynamic reward rate based on TVL\nc) Implement a square root formula for reward calculation, use a checkpoint system for balances, and add a cooldown period between harvests\nd) Use a bonding curve for reward rate, implement a slashing mechanism for early withdrawals, and add a governance-controlled reward boost feature",
    "answer": "c"
  },
  {
    "id": "290",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A smart contract system is being developed for a decentralized insurance platform. The system needs to handle policy creation, premium payments, claim submissions, and payouts. Consider the following security challenges:\n\n1. Ensuring the integrity and confidentiality of policyholder data\n2. Preventing fraudulent claims\n3. Managing the liquidity of the insurance pool\n4. Handling regulatory compliance and KYC requirements\n\nWhich combination of techniques and design choices would best address these challenges while maintaining the decentralized nature of the platform?\n\na) Use zero-knowledge proofs for policyholder verification, implement a reputation system for claim assessors, use a dynamic premium calculation based on pool liquidity, and store KYC data off-chain with on-chain hashes\nb) Implement a centralized KYC process, use a multi-sig wallet for claim approvals, store all policyholder data on-chain, and use a stable coin for the insurance pool\nc) Use federated learning for fraud detection, implement a liquidity mining program for the insurance pool, store encrypted policyholder data on IPFS, and use oracles for regulatory compliance checks\nd) Implement a DAO for governance decisions, use a bonding curve for premium calculations, store all data on-chain in plain text, and require manual verification for all claims",
    "answer": "a"
  },
  {
    "id": "291",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A decentralized derivatives platform is implementing a new margin trading system with cross-margining capabilities. Part of the liquidation function is implemented. Which combination of additional mechanisms and modifications would best enhance the security and fairness of this liquidation system?\n\na) Implement a dutch auction for liquidations, use a decentralized price oracle network, add a partial liquidation mechanism, and implement a dynamic liquidation threshold based on market volatility\nb) Use a centralized liquidation bot, implement instant liquidations without price checks, store all position data off-chain, and allow only whitelisted addresses to perform liquidations\nc) Implement a fixed liquidation penalty, use the last traded price for liquidations, add a first-come-first-serve liquidation mechanism, and allow borrowing of liquidation funds\nd) Use a gradual liquidation process, implement a single trusted price feed, add a fixed cooldown period between liquidations, and require manual approval for all liquidations",
    "answer": "a"
  },
  {
    "id": "292",
    "categories": [
      "DeFi",
      "Tokenomics",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A DeFi protocol is implementing a complex liquidity mining program with multiple pools and reward distribution mechanisms. The team wants to ensure fair distribution, prevent gaming of the system, and maintain long-term sustainability. Which combination of features and mechanisms would best achieve these goals?\n\na) Use a fixed reward rate for all pools, distribute rewards instantly, allow unlimited deposits, and use a first-come-first-serve model for reward allocation\nb) Implement dynamic reward rates based on TVL, use a vesting period for rewards, cap the total rewards per user, and use a snapshot mechanism for reward calculations\nc) Use a linear reward distribution model, allow reward claiming at any time, implement no lockup period for deposits, and use the last-minute balance for reward calculations\nd) Implement quadratic voting for reward allocation, use time-weighted liquidity for calculations, implement a cooldown period between deposits and reward claiming, and use a decay function for long-term emissions",
    "answer": "d"
  },
  {
    "id": "293",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A smart contract developer is designing a decentralized exchange (DEX) with an order book model instead of an AMM. The system needs to handle limit orders, market orders, and ensure fair order execution. Which combination of techniques would provide the best balance of security, efficiency, and resistance to front-running?\n\na) Use a centralized order matching engine, implement KYC for all traders, store order books off-chain, and use a trusted timestamp service for order prioritization\nb) Implement a frequent batch auction mechanism, use commit-reveal schemes for order submission, implement a verifiable delay function (VDF) for order sequencing, and use zero-knowledge proofs for order matching\nc) Use a first-come-first-serve model for order execution, store all orders on-chain, implement instant order matching, and allow miners to prioritize transactions\nd) Implement a second-price auction for each trade, use a centralized sequencer for order submission, store encrypted orders on-chain, and use a random number generator for tie-breaking",
    "answer": "b"
  },
  {
    "id": "294",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A DeFi protocol implements a complex system of interconnected smart contracts for lending, borrowing, and yield farming. The following vulnerability is discovered in the reward distribution mechanism:\n\n```solidity\nfunction distributeRewards() public {\n    uint256 totalRewards = address(this).balance;\n    for (uint256 i = 0; i < users.length; i++) {\n        uint256 userReward = (totalRewards * userShares[users[i]]) / totalShares;\n        (bool success, ) = users[i].call{value: userReward}(\"\");\n        require(success, \"Reward transfer failed\");\n    }\n}\n```\n\nConsidering the potential vulnerabilities, which combination of fixes and design changes would provide the highest level of security while maintaining gas efficiency?\n\na) Use the pull-over-push pattern for reward distribution, implement reentrancy guards, use SafeMath for calculations, and add events for reward claims\nb) Implement batch processing with a maximum gas limit per batch, use transfer instead of call, add a mutex lock, and store user balances for later claiming\nc) Use a merkle tree for reward distribution, implement reentrancy guards, use assembly for gas optimization, and add a time delay between reward calculations and distributions\nd) Implement an iterative distribution model with checkpoints, use OpenZeppelin's ReentrancyGuard, safely handle integer division, and emit detailed events for each step of the distribution process",
    "answer": "d"
  },
  {
    "id": "295",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "You are auditing a new DeFi protocol that combines an AMM, lending platform, and yield farming. The protocol interacts with multiple external oracles and allows for complex multi-step transactions. During your analysis, you discover the following code in a critical function:\n\n```solidity\nfunction executeTrade(address tokenIn, address tokenOut, uint256 amount) external {\n    require(oracles[tokenIn].getPrice() > 0, \"Invalid price\");\n    require(oracles[tokenOut].getPrice() > 0, \"Invalid price\");\n    \n    uint256 expectedOutput = (amount * oracles[tokenIn].getPrice()) / oracles[tokenOut].getPrice();\n    \n    tokenIn.transferFrom(msg.sender, address(this), amount);\n    tokenOut.transfer(msg.sender, expectedOutput);\n    \n    emit TradeExecuted(msg.sender, tokenIn, tokenOut, amount, expectedOutput);\n}\n```\n\nWhich combination of vulnerabilities and potential attacks is this code most susceptible to, and what would be the most comprehensive way to mitigate them?\n\na) Oracle manipulation and reentrancy; Use a decentralized oracle network with time-weighted average prices, implement reentrancy guards, and add slippage protection\nb) Front-running and integer overflow; Implement a commit-reveal scheme, use SafeMath, and add a maximum slippage parameter\nc) Oracle manipulation, reentrancy, and precision loss; Use a composite oracle with median price selection, implement the checks-effects-interactions pattern, and use high-precision fixed-point arithmetic\nd) Insufficient input validation and centralization risks; Implement strict input validation, use a multi-signature wallet for protocol upgrades, and add emergency pause functionality",
    "answer": "c"
  },
  {
    "id": "296",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "You are auditing a complex DeFi protocol that implements a novel automated market maker (AMM) model with concentrated liquidity and flash loan capabilities. The core swap function contains the following code:\n\n```solidity\nfunction swap(uint256 amountIn, uint256 minAmountOut, address recipient) external {\n    (uint256 reserveA, uint256 reserveB) = getReserves();\n    uint256 amountOut = getAmountOut(amountIn, reserveA, reserveB);\n    require(amountOut >= minAmountOut, \"Insufficient output amount\");\n    \n    tokenA.transferFrom(msg.sender, address(this), amountIn);\n    tokenB.transfer(recipient, amountOut);\n    \n    updateReserves(reserveA + amountIn, reserveB - amountOut);\n    emit Swap(msg.sender, amountIn, amountOut, recipient);\n}\n\nfunction flashLoan(uint256 amount, address recipient, bytes calldata data) external {\n    uint256 fee = amount * 9 / 10000;\n    tokenA.transfer(recipient, amount);\n    IFlashLoanReceiver(recipient).executeOperation(amount, fee, data);\n    tokenA.transferFrom(recipient, address(this), amount + fee);\n}\n```\n\nWhich combination of vulnerabilities and potential attacks is this code most susceptible to, and what would be the most comprehensive way to mitigate them?\n\na) Reentrancy and price manipulation; Implement reentrancy guards, use a price oracle with TWAP, and add slippage protection\nb) Front-running and flash loan attacks; Use a commit-reveal scheme for trades, implement a virtual reserve system, and add a minimum time delay between flash loans\nc) Precision loss and sandwich attacks; Use fixed-point arithmetic, implement an integrated price impact calculation, and add a maximum allowed slippage parameter\nd) Reentrancy, price manipulation, and flash loan attacks; Implement the checks-effects-interactions pattern, use a composite price oracle with outlier rejection, add dynamic fees based on price impact, and implement a per-block flash loan limit",
    "answer": "d"
  },
  {
    "id": "297",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a decentralized derivatives platform with support for complex financial instruments, including options, futures, and synthetic assets. The platform needs to ensure proper risk management, accurate price discovery, and resistance to market manipulation. Consider the following code snippet for a simplified option contract:\n\n```solidity\ncontract Option {\n    address public underlying;\n    uint256 public strikePrice;\n    uint256 public expiration;\n    bool public isCall;\n    \n    function exercise() external {\n        require(block.timestamp <= expiration, \"Option expired\");\n        uint256 currentPrice = getPrice(underlying);\n        \n        if (isCall) {\n            require(currentPrice > strikePrice, \"Out of money\");\n            uint256 profit = currentPrice - strikePrice;\n            underlying.transfer(msg.sender, profit);\n        } else {\n            require(currentPrice < strikePrice, \"Out of money\");\n            uint256 profit = strikePrice - currentPrice;\n            msg.sender.transfer(profit);\n        }\n    }\n    \n    function getPrice(address asset) internal returns (uint256) {\n        // Price oracle call\n    }\n}\n```\n\nWhich combination of additional mechanisms and modifications would best enhance the security, accuracy, and manipulation resistance of this derivatives platform?\n\na) Implement a decentralized oracle network with TWAP, use a virtual AMM for price discovery, add a dynamic margin system with auto-liquidation, and implement circuit breakers for extreme market conditions\nb) Use a centralized price feed, implement KYC for all users, require full collateralization for all positions, and use a fixed fee structure for all trades\nc) Implement an on-chain options pricing model, use a commit-reveal scheme for exercise requests, add a challenge period for settlements, and use a reputation system for liquidity providers\nd) Use a hybrid oracle system combining off-chain price feeds with on-chain validation, implement a two-step exercise process with timelock, add a dynamic fee structure based on market volatility, and use a backstop liquidity protocol for settlement assurance",
    "answer": "d"
  },
  {
    "id": "298",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "You are auditing a complex DeFi protocol that combines lending, borrowing, and yield farming with cross-chain interactions. The protocol uses a novel tokenomics model and employs multiple oracles for price feeds. During your analysis, you discover the following vulnerabilities:\n\n1. A potential reentrancy attack vector in the lending function\n2. Possible precision loss in interest rate calculations\n3. Centralization risks in the governance module\n4. Potential front-running opportunities in the yield farming rewards distribution\n5. Inconsistent handling of decimals across different token standards\n\nConsidering the complexity of the protocol and the interconnected nature of its components, which combination of fixes and design changes would provide the most comprehensive security improvement while maintaining the protocol's functionality and efficiency?\n\na) Implement reentrancy guards, use fixed-point arithmetic for interest calculations, transition to a multi-sig wallet for governance, implement a virtual balance system for reward distribution, and normalize all token decimals to 18\nb) Use the checks-effects-interactions pattern, implement a dynamic interest rate model with safety checks, transition to a decentralized autonomous organization (DAO) for governance, use a commit-reveal scheme for reward claims, and implement adapter contracts for different token standards\nc) Implement a proxy upgrade pattern with timelock, use a formal verification tool for core functions, implement quadratic voting for governance, use a merkle tree for efficient reward distribution, and implement a universal token wrapper for consistent decimal handling\nd) Use OpenZeppelin's ReentrancyGuard, implement a compound interest model with high-precision libraries, use a timelocked executor for governance actions, implement batch processing for reward distribution with maximum slippage checks, and use a decimal-agnostic internal accounting system",
    "answer": "B"
  },
  {
    "id": "299",
    "categories": [
      "DeFi",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a decentralized exchange (DEX) that aims to solve the issues of front-running and miner extractable value (MEV) while maintaining high liquidity and low slippage. The DEX needs to support both limit and market orders, as well as complex trading strategies. Consider the following code snippet for the core trading function:\n\n```solidity\nfunction executeTrade(bytes32 orderHash, uint256 amount, uint256 price) external {\n    Order memory order = orders[orderHash];\n    require(order.status == OrderStatus.Active, \"Invalid order\");\n    require(msg.sender == order.trader, \"Unauthorized\");\n    \n    uint256 executionPrice = getCurrentPrice(order.tokenPair);\n    require(executionPrice <= price, \"Price slippage\");\n    \n    uint256 fillAmount = min(amount, order.remainingAmount);\n    uint256 cost = fillAmount * executionPrice;\n    \n    order.tokenSell.transferFrom(order.trader, address(this), fillAmount);\n    order.tokenBuy.transfer(order.trader, cost);\n    \n    order.remainingAmount -= fillAmount;\n    if (order.remainingAmount == 0) {\n        order.status = OrderStatus.Filled;\n    }\n    \n    emit TradeExecuted(orderHash, fillAmount, executionPrice);\n}\n```\n\nWhich combination of additional mechanisms and modifications would best mitigate front-running and MEV while ensuring efficient and fair trade execution?\n\na) Implement a frequent batch auction mechanism, use commit-reveal schemes for order submission, implement a verifiable delay function (VDF) for order sequencing, and use zero-knowledge proofs for order matching\nb) Use a hybrid on-chain/off-chain order book, implement a front-running resistant order type, use a decentralized sequencer network for transaction ordering, and implement a dynamic fee model that disincentivizes MEV\nc) Implement a constant function market maker (CFMM) model, use meta-transactions for gasless trading, implement a time-weighted average price (TWAP) for execution, and use a layer-2 solution for scalability\nd) Use an intent-based trading system with off-chain solvers, implement a universal limit order protocol, use a decentralized oracle network for price feeds, and implement a challenge period for trade settlements",
    "answer": "A"
  },
  {
    "id": "300",
    "categories": [
      "DeFi",
      "Interoperability",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a decentralized lending protocol with cross-chain capabilities. The protocol aims to optimize capital efficiency, minimize liquidation risks, and provide seamless cross-chain borrowing and lending. Consider the following challenges:\n\n1. Ensuring consistent interest rate models across different chains\n2. Mitigating oracle manipulation risks for cross-chain asset prices\n3. Handling different block confirmation times for cross-chain transactions\n4. Preventing attacks that exploit differences in liquidity across chains\n5. Ensuring efficient liquidations for cross-chain collateralized positions\n\nWhich combination of techniques and design choices would best address these challenges while maintaining the security and efficiency of the lending protocol?\n\na) Implement a unified interest rate model using a virtual pool, use a decentralized oracle network with cross-chain verification, implement an optimistic rollup for fast cross-chain transactions, use a liquidity balancing mechanism with incentives, and implement a decentralized liquidator network with stake-based participation\nb) Use chain-specific interest rate models, implement a trusted oracle network for price feeds, use hash time-locked contracts (HTLCs) for cross-chain transactions, implement strict liquidity caps per chain, and use a centralized liquidation bot for efficiency\nc) Implement a dynamic interest rate model with cross-chain governance, use a hybrid oracle system with on-chain and off-chain components, implement a two-way peg mechanism for cross-chain asset transfers, use a virtual lending pool for liquidity management, and implement a liquidation auction mechanism with cross-chain bidding\nd) Use a fixed interest rate model across all chains, implement a price feed system based on centralized exchanges, use atomic swaps for cross-chain transactions, implement independent liquidity pools for each chain, and use a permissioned set of liquidators",
    "answer": "a"
  },
  {
    "id": "301",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are auditing a complex smart contract system for a decentralized insurance platform. The platform offers various insurance products, including crypto asset coverage, smart contract failure insurance, and yield farming protection. During your analysis, you discover the following code snippet in a core function:\n\n```solidity\nfunction processClaim(uint256 claimId) external {\n    Claim storage claim = claims[claimId];\n    require(claim.status == ClaimStatus.Submitted, \"Invalid claim status\");\n    \n    uint256 coverageAmount = policies[claim.policyId].coverageAmount;\n    uint256 payoutAmount = calculatePayout(claim);\n    \n    if (payoutAmount > 0) {\n        claim.status = ClaimStatus.Approved;\n        token.transfer(claim.beneficiary, payoutAmount);\n    } else {\n        claim.status = ClaimStatus.Rejected;\n    }\n    \n    emit ClaimProcessed(claimId, claim.status, payoutAmount);\n}\n\nfunction calculatePayout(Claim memory claim) internal view returns (uint256) {\n    // Complex payout calculation logic\n}\n```\n\nConsidering the potential vulnerabilities and the critical nature of insurance claim processing, which combination of security measures and design improvements would provide the most robust protection against attacks and errors?\n\na) Implement a multi-signature approval process for claims, use a decentralized oracle network for external data verification, implement a timelock for large payouts, and use formal verification for the payout calculation logic\nb) Use a centralized claims adjuster, implement KYC for all policyholders, store all claim data off-chain, and use a fixed payout amount for all claims\nc) Implement a challenge period for claim approvals, use a reputation system for claim assessors, implement a dynamic premium adjustment mechanism based on claim history, and use zero-knowledge proofs for privacy-preserving claim verification\nd) Use a prediction market for claim resolution, implement automatic claim processing based on smart contract events, store all policy and claim data on-chain, and use a random number generator for payout calculations",
    "answer": "a"
  },
  {
    "id": "302",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "You are auditing a complex DeFi protocol that implements a novel automated market maker (AMM) model with concentrated liquidity, flash loans, and cross-chain asset bridging. During your analysis, you discover the following code snippet in a critical function:\n\n```solidity\nfunction executeSwap(SwapParams memory params) external returns (uint256) {\n    (uint256 reserveIn, uint256 reserveOut) = getReserves(params.tokenIn, params.tokenOut);\n    uint256 amountOut = computeAmountOut(params.amountIn, reserveIn, reserveOut);\n    require(amountOut >= params.minAmountOut, \"Insufficient output\");\n\n    if (params.useFlashLoan) {\n        IFlashLoanReceiver(msg.sender).executeOperation(params.tokenOut, amountOut, params.data);\n        require(IERC20(params.tokenOut).transferFrom(msg.sender, address(this), amountOut), \"Repay failed\");\n    } else {\n        require(IERC20(params.tokenIn).transferFrom(msg.sender, address(this), params.amountIn), \"Transfer failed\");\n        require(IERC20(params.tokenOut).transfer(params.recipient, amountOut), \"Transfer failed\");\n    }\n\n    updateReserves(params.tokenIn, params.tokenOut, reserveIn + params.amountIn, reserveOut - amountOut);\n    emit Swap(msg.sender, params.tokenIn, params.tokenOut, params.amountIn, amountOut);\n    return amountOut;\n}\n\nfunction bridgeAsset(address token, uint256 amount, uint256 destChainId) external {\n    require(IERC20(token).transferFrom(msg.sender, address(this), amount), \"Transfer failed\");\n    bytes memory data = abi.encode(msg.sender, amount);\n    IBridge(bridgeAddress).initiateTransfer(token, amount, destChainId, data);\n    emit AssetBridgeInitiated(msg.sender, token, amount, destChainId);\n}\n```\n\nConsidering the complexity of the protocol and the potential for cross-function and cross-chain interactions, which combination of vulnerabilities and attack vectors is this code most susceptible to, and what would be the most comprehensive way to mitigate them?\n\na) Reentrancy, oracle manipulation, and bridge security; Implement reentrancy guards, use a decentralized oracle network with time-weighted average prices, and add a timelock for bridge operations\nb) Front-running, flash loan attacks, and precision loss; Use a commit-reveal scheme for trades, implement a virtual reserve system, and use fixed-point arithmetic for calculations\nc) Reentrancy, price manipulation, flash loan attacks, and cross-chain security issues; Implement the checks-effects-interactions pattern, use a composite price oracle with circuit breakers, add dynamic fees based on price impact, implement a per-block flash loan limit, and use a decentralized multi-party computation protocol for cross-chain asset transfers\nd) Insufficient input validation, centralization risks, and liquidity imbalances; Implement strict input validation, use a multi-signature wallet for protocol upgrades, and add dynamic liquidity rebalancing across pools",
    "answer": "c"
  },
  {
    "id": "303",
    "categories": [
      "DeFi",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "You are auditing a complex DeFi ecosystem that includes a decentralized exchange, lending protocol, yield aggregator, and cross-chain bridge. The system uses a novel tokenomics model with rebasing mechanics and employs multiple oracles for price feeds and risk assessment. During your analysis, you discover the following vulnerabilities and design issues:\n\n1. Potential reentrancy vulnerabilities in the lending and flash loan functions\n2. Inconsistent slippage protection across different trading pairs\n3. Centralization risks in the governance module and oracle management\n4. Possible precision loss in interest rate and yield calculations\n5. Inefficient gas usage in batch operations and state updates\n6. Potential front-running opportunities in the cross-chain bridging process\n7. Lack of proper access control in some administrative functions\n8. Incomplete event emissions for critical state changes\n\nConsidering the interconnected nature of the ecosystem components and the complexity of the tokenomics model, which combination of fixes, design changes, and additional security measures would provide the most comprehensive improvement to the system's overall security, efficiency, and decentralization?\n\na) Implement reentrancy guards and use the checks-effects-interactions pattern, standardize slippage protection using a dynamic model, transition to a multi-sig wallet for critical functions, use high-precision fixed-point libraries for calculations, optimize gas usage through storage packing and batch updates, implement a commit-reveal scheme for cross-chain transactions, use role-based access control for all functions, and add comprehensive event logging\nb) Use formal verification for core functions, implement quadratic voting for governance, use a decentralized oracle network with reputation system, implement an optimistic rollup layer for scalability, use zk-SNARKs for privacy-preserving transactions, implement a virtual balance system for efficient state management, use a federated peg for the cross-chain bridge, and implement a bug bounty program\nc) Implement the Universal Upgradeable Proxy Standard (UUPS) with timelock, use a hybrid on-chain/off-chain order book, implement a two-step ownership transfer process, use Chainlink's decentralized oracle network, implement meta-transactions for gas efficiency, use threshold signatures for cross-chain validations, implement circuit breakers for anomaly detection, and use formal verification for the tokenomics model\nd) Implement a comprehensive security module that includes reentrancy guards, access control, and circuit breakers; use a decentralized oracle network with cryptographic proofs for data integrity; implement a zk-rollup layer for scalability with fraud proofs; use a combination of on-chain governance with delegation and off-chain dispute resolution; implement cross-function and cross-contract invariants with formal verification; use a hybrid commit-chain model for the bridge with fast withdrawals; implement a dynamic fee model based on system utilization; and use advanced cryptographic techniques like verifiable delay functions (VDFs) for randomness in rebasing",
    "answer": "d"
  },
  {
    "id": "304",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized derivatives trading platform recently experienced significant market manipulation during periods of extreme volatility. Automated liquidations were triggered based on inaccurate price feeds from an external oracle, leading to unfair liquidations of user positions. Additionally, some critical functions lacked appropriate margin checks, leading to partial failures in trade execution. What is the most important step the developer should take to secure this platform?\nA) Use safe math for all calculations to avoid arithmetic errors\nB) Implement secure price oracles with fallback mechanisms and proper margin checks for trades\nC) Disable external price oracles and rely on internal pricing mechanisms\nD) Allow users to manually verify all price feeds before triggering liquidations",
    "answer": "B"
  },
  {
    "id": "305",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A stablecoin is designed to maintain a 1:1 peg with a fiat currency. The system relies on collateralized assets and external price oracles to adjust the supply and demand. However, in times of market stress, price oracles have provided inaccurate data, causing the stablecoin to lose its peg. Additionally, the system lacks a mechanism for users to contest incorrect price feeds. What is the most crucial step to prevent such incidents in the future?\nA) Implement a gradual adjustment mechanism for stability and secure price oracles with fallback mechanisms\nB) Allow users to directly update the price oracle to ensure accuracy\nC) Remove the need for collateralization to simplify the system\nD) Let the market correct price deviations without intervention",
    "answer": "A"
  },
  {
    "id": "306",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized automated market maker (AMM) allows users to swap tokens based on a constant product formula. However, recent extreme market volatility has led to significant slippage and users have started experiencing large, unexpected losses during trades. Additionally, the AMM pool is vulnerable to front-running attacks, where bots manipulate trade orders. What is the most crucial step to secure the AMM?\nA) Implement flash loan attacks mitigation techniques\nB) Use formal verification for core swap logic and introduce slippage protection mechanisms\nC) Allow users to manually verify swap outcomes to prevent losses\nD) Rely solely on the constant product formula without any additional protections",
    "answer": "B"
  },
  {
    "id": "307",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized yield farming protocol rewards users who provide liquidity with governance tokens. Recently, a flash loan attack was executed to manipulate the system’s reward distribution mechanism, resulting in an unfairly high yield for the attacker. The protocol also lacks timelock mechanisms for critical parameter changes, allowing attackers to exploit newly introduced bugs. What is the most important step to secure the yield farming protocol?\nA) Implement slippage protection to reduce the impact of flash loans\nB) Use timelock mechanisms for critical parameter changes and protect against flash loan attacks\nC) Allow users to vote on how rewards are distributed\nD) Rely solely on a higher staking threshold to discourage attacks",
    "answer": "B"
  },
  {
    "id": "308",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "In a decentralized options trading platform, a price oracle failure caused incorrect settlement of options contracts, leading to large-scale liquidations. Additionally, the platform lacked circuit breakers for extreme market conditions, causing cascading failures. Some traders exploited these failures to profit from the inaccurate pricing. What is the most crucial security enhancement for this platform?\nA) Implement proper error handling for expired options\nB) Introduce circuit breakers for extreme market conditions and secure price oracles\nC) Allow users to manually review the settlement process before liquidation\nD) Remove the need for price oracles and rely on traders for market prices",
    "answer": "B"
  },
  {
    "id": "309",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized prediction market allows users to bet on future events using a smart contract. However, a flaw in the secure oracle integration caused incorrect outcomes to be determined, resulting in unfair market resolutions. Some users have started front-running bets, placing predictions right before the outcome is revealed. What is the most important step to secure the prediction market?\nA) Use slippage protection to prevent large bets before outcomes\nB) Implement a challenge period for outcome determination and protection against front-running\nC) Remove all oracles to avoid reliance on external data\nD) Allow users to dispute outcomes manually through an external committee",
    "answer": "B"
  },
  {
    "id": "310",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A liquidity mining contract rewards users for providing liquidity to decentralized finance (DeFi) pools. Recently, the contract was exploited through a flash loan, allowing an attacker to manipulate the token distribution mechanism. Additionally, there were no vesting or lock-up periods, enabling the attacker to immediately sell the rewards. What is the most critical security measure to prevent future attacks?\nA) Implement access controls for admin functions to secure the protocol\nB) Introduce vesting or lock-up periods and protect against flash loan attacks\nC) Allow only verified users to participate in liquidity mining\nD) Remove the reward distribution feature to prevent further exploitation",
    "answer": "B"
  },
  {
    "id": "311",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized lending aggregator platform allows users to borrow and lend assets across multiple DeFi protocols. However, a vulnerability in the validation mechanism for external protocols allowed an attacker to manipulate the aggregator's funds. Additionally, there were no exposure limits for new protocols, leading to significant losses when the aggregator integrated with an untested protocol. What is the most critical step to secure the aggregator?\nA) Implement proper validation for external protocols and introduce exposure limits for new protocols\nB) Allow users to manually verify external protocols before integration\nC) Remove the lending functionality to prevent future losses\nD) Increase the required collateral for borrowing to reduce risks",
    "answer": "A"
  },
  {
    "id": "312",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized lending platform offers flash loans, allowing users to borrow assets as long as they return the loan within the same transaction. Recently, an attacker executed a reentrancy attack during a flash loan, leading to significant losses. Additionally, there were no limits on loan amounts, allowing the attacker to borrow large sums. What is the most important step to secure the platform?\nA) Ensure all borrowed assets are returned in the same transaction and implement reentrancy protection\nB) Allow users to borrow small amounts only to minimize losses\nC) Remove flash loans entirely to avoid further exploits\nD) Use a centralized authority to monitor loan transactions",
    "answer": "A"
  },
  {
    "id": "313",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A token swap platform allows users to exchange tokens with built-in slippage protection. However, during periods of low liquidity, users have been experiencing failed swaps due to insufficient slippage tolerance, and some trades were front-run by bots exploiting the low liquidity conditions. Additionally, users are unable to adjust slippage tolerance dynamically based on market conditions. What is the most critical security measure to improve the platform?\nA) Implement dynamic slippage tolerance based on liquidity and introduce front-running protection\nB) Allow users to adjust slippage tolerance manually for each swap\nC) Remove the slippage protection feature to simplify trades\nD) Allow only large liquidity providers to participate in token swaps",
    "answer": "A"
  },
  {
    "id": "314",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized finance (DeFi) protocol has been repeatedly targeted by 'sandwich' attacks, where bots place large orders before and after a user's transaction, manipulating token prices to their advantage. The protocol lacks slippage protection and does not implement any mechanisms to prevent front-running. What is the most important measure to mitigate sandwich attacks?\nA) Implement slippage protection mechanisms and use front-running resistant designs, such as batch auctions\nB) Allow users to execute trades manually to avoid bots\nC) Remove the token swap feature to prevent manipulation\nD) Disable price feeds to avoid price manipulation",
    "answer": "A"
  },
  {
    "id": "315",
    "question": "In a Uniswap-style AMM, if a liquidity pool contains 1000 TokenA and 5000 TokenB, what would be the price of TokenA in terms of TokenB? A) 0.2 TokenB B) 5 TokenB C) 0.5 TokenB D) 2 TokenB",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "316",
    "question": "In a perpetual futures market with 10x leverage, if the funding rate is +0.01% per 8 hours and a trader holds a $100,000 long position for 24 hours, how much do they pay in funding? A) $3 B) $30 C) $300 D) $3000",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "317",
    "question": "If a DeFi protocol offers leveraged yield farming with a maximum leverage of 5x, and the base APY is 20%, what's the maximum APY a user could theoretically achieve, assuming they pay 5% interest on borrowed funds and ignoring compounding? A) 80% B) 100% C) 120% D) 140%",
    "answer": "A",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "318",
    "question": "An innovative DeFi protocol proposes a 'Fractional Reserve Lending' model, where the reserve ratio of the pool dynamically adjusts based on current utilization. The reserve ratio R is related to the utilization U by the equation: R = 1 / (1 + e^((U-0.5)/0.1)) * 0.4 + 0.1. If the current pool size is 10 million tokens and 6 million tokens are lent out, what is the approximate maximum amount that can still be borrowed? A) About 800,000 tokens B) About 1 million tokens C) About 1.2 million tokens D) About 1.4 million tokens",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "319",
    "question": "If a liquidity provider adds 10 ETH and 20,000 DAI to a Uniswap pool when the total pool consists of 100 ETH and 200,000 DAI, what percentage of the pool does the provider own? A) 5% B) 10% C) 15% D) 20%",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "320",
    "question": "If a flash loan attack manipulates the price of an asset in a lending protocol from $100 to $150, causing $1 million of liquidations, and the attacker can capture 10% of the liquidation value, what's the minimum size of flash loan needed to break even, assuming a 0.1% flash loan fee? A) $1 million B) $10 million C) $100 million D) $1 billion",
    "answer": "B",
    "categories": [
      "DeFi",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "321",
    "question": "A DeFi protocol introduces a new concept of 'dynamic liquidity pools' where the pool's composition changes based on market conditions. The pool uses an algorithm that adjusts weights based on the relative volatility of assets. How might this affect impermanent loss compared to static-weight pools? A) Consistently lower impermanent loss B) Higher impermanent loss during high volatility C) Unpredictable impermanent loss patterns D) No significant effect on impermanent loss",
    "answer": "C",
    "categories": [
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "322",
    "question": "In a decentralized lending protocol, if the current utilization rate is 80% and the interest rate model is set to: base rate 2% + utilization rate * 10%, what is the current borrowing interest rate? A) 8% B) 10% C) 12% D) 82%",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "323",
    "question": "If a yield aggregator autocompounds rewards every hour and takes a 10% performance fee, what APY would result in a doubling of investment in 6 months? A) 120% B) 146% C) 173% D) 189%",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "324",
    "question": "If a liquidity provider in a 80/20 weighted pool (Token A/Token B) deposited when Token A was worth 100 Token B, and now Token A is worth 120 Token B, what percentage of value have they gained/lost to impermanent loss (ignoring fees)? A) Lost 0.44% B) Gained 0.44% C) Lost 0.88% D) Gained 0.88%",
    "answer": "A",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "325",
    "question": "If a decentralized insurance protocol has a 5% chance of a valid claim in a year and charges 0.5% premium, what should be the payout multiplier for the protocol to break even (ignoring operational costs)? A) 10x B) 20x C) 50x D) 100x",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "326",
    "question": "A new DeFi lending protocol introduces the concept of 'nested collateral', where users can use their lending positions as collateral for further borrowing. If the protocol requires a 150% collateralization ratio for the first level of borrowing and a 200% ratio for the second level, what's the maximum amount of stablecoins a user could borrow against 100 ETH, assuming ETH is priced at $2000? A) 88,888 stablecoins B) 100,000 stablecoins C) 111,111 stablecoins D) 133,333 stablecoins",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "327",
    "question": "If a flash loan for 1000 ETH is taken and the current gas price is 50 Gwei, with the flash loan contract requiring 500,000 gas to execute, what is the minimum ETH value the arbitrage opportunity must provide to break even (assuming 1 ETH = $2000)? A) $25 B) $50 C) $100 D) $200",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "328",
    "question": "A new DeFi protocol introduces a concept of 'dynamic slippage tolerance' where the allowed slippage increases with the time a transaction spends in the mempool. If the base slippage tolerance is 0.1% and it increases by 0.05% every 10 seconds, what would be the maximum slippage for a transaction that remains in the mempool for 5 minutes, assuming a cap of 1% slippage? A) 0.6% B) 0.85% C) 1% D) 1.6%",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "329",
    "question": "A DeFi lending protocol implements a new interest rate model where the interest rate r is given by r = a * log(1 + e^((u-b)/c)), where u is the utilization rate, and a, b, c are constants. If a = 0.2, b = 0.8, and c = 0.1, at what utilization rate is the interest rate 15%? A) 75% B) 80% C) 85% D) 90%",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "330",
    "question": "In a DeFi dApp using Chainlink price feeds, if each price update costs 0.1 LINK and the dApp requires hourly updates for 10 different asset pairs, what would be the monthly cost in LINK tokens? A) 72 LINK B) 720 LINK C) 1,440 LINK D) 7,200 LINK",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "331",
    "question": "In an options protocol using Black-Scholes model, if implied volatility increases from 80% to 100%, how does this affect at-the-money option prices, all else being equal? A) Decrease by ~10% B) Increase by ~10% C) Decrease by ~25% D) Increase by ~25%",
    "answer": "D",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "332",
    "question": "A DeFi lending protocol implements a new interest rate model where the interest rate r is given by r = a * u^2 + b * u + c, where u is the utilization rate, and a, b, c are constants. If a = 0.1, b = 0.2, and c = 0.05, at what utilization rate is the interest rate 15%? A) 50% B) 60% C) 70% D) 80%",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "333",
    "question": "In a prediction market using an automated market maker, the cost function is C(q) = b * log(1 + e^(q/b)), where q is the number of shares and b is a liquidity parameter. If b = 1000 and the current price is 0.7, approximately how many shares need to be bought to move the price to 0.75? A) 115 shares B) 252 shares C) 345 shares D) 460 shares",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "334",
    "question": "A decentralized prediction market uses an automated market maker with a liquidity pool of 1,000,000 tokens. If the current probability of an event occurring is priced at 60%, how many tokens would a trader need to buy to move the probability to 75%, ignoring fees? A) 150,000 tokens B) 200,000 tokens C) 250,000 tokens D) 300,000 tokens",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "335",
    "question": "In a liquidity pool with 1000 TokenA and 5000 TokenB, if a trader wants to swap TokenA for TokenB with 1% slippage tolerance, what's the maximum amount of TokenA they can trade without exceeding the slippage tolerance? A) 10 TokenA B) 49.5 TokenA C) 90 TokenA D) 100 TokenA",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "336",
    "question": "A decentralized prediction market uses a new 'Layered Belief Aggregation' mechanism. Participants are divided into n layers, and the prediction results from each layer influence the belief update of the previous layer. The influence is proportional to the historical accuracy of that layer. If there are 5 layers of participants with historical accuracies of 50%, 60%, 70%, 80%, and 90% from the bottom to the top, and each layer has an equal number of participants, what is the approximate influence weight of the bottom layer participants on the final outcome? A) About 7% B) About 10% C) About 14% D) About 16%",
    "answer": "C",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "337",
    "question": "In a synthetic asset protocol, if the collateralization ratio is 400% and the liquidation threshold is 150%, at what price decrease of the collateral would a position with 1000 DAI of debt be liquidated? A) 25% B) 37.5% C) 50% D) 62.5%",
    "answer": "D",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "338",
    "question": "A DeFi protocol implements a new AMM model where the product of the reserves raised to different powers is constant: x^a * y^b = k. How does this affect the slippage compared to the constant product formula (x * y = k) when a = 2 and b = 1? A) Lower slippage for all trade sizes B) Higher slippage for all trade sizes C) Lower slippage for small trades, higher for large trades D) Higher slippage for small trades, lower for large trades",
    "answer": "C",
    "categories": [
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "339",
    "question": "In a prediction market using an automated market maker, the probability of an event is represented by the price p of a token (0 ≤ p ≤ 1). The AMM uses the loss function L(p) = -k(p*ln(p) + (1-p)*ln(1-p)) where k is a liquidity parameter. What is the optimal trade size Δp to minimize price impact when the current price is 0.5? A) Δp = √(k/2) B) Δp = k/4 C) Δp = √k D) Δp = k/2",
    "answer": "A",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "340",
    "question": "If a DEX aggregator splits a 1000 DAI trade across three AMMs with 50% on AMM1 (0.3% fee), 30% on AMM2 (0.5% fee), and 20% on AMM3 (0.1% fee), what's the total fee paid? A) 3 DAI B) 3.4 DAI C) 3.7 DAI D) 4 DAI",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "341",
    "question": "In a prediction market using an automated market maker, the cost function is C(q) = b * tanh(q/b), where q is the number of shares and b is a liquidity parameter. If b = 20,000 and the current price is 0.85, approximately how many shares need to be sold to move the price to 0.75? A) 4,605 shares B) 9,210 shares C) 13,815 shares D) 18,420 shares",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "342",
    "question": "A DeFi protocol implements a novel liquidation mechanism where liquidators must solve a computational puzzle before claiming collateral. The difficulty of the puzzle increases with the size of the liquidation. How might this affect the protocol's risk profile? A) Reduce the risk of flash loan attacks B) Increase the chance of bad debt in large liquidations C) Lead to more efficient price discovery during liquidations D) Encourage smaller, more frequent liquidations",
    "answer": "B",
    "categories": [
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "343",
    "question": "A DeFi protocol uses a constant product automated market maker (AMM) with 1000 ETH and 1,000,000 USDC in its liquidity pool. If a user wants to swap ETH for USDC, how much USDC will they receive for 10 ETH, ignoring fees? A) 9,900 USDC B) 90,909 USDC C) 99,009 USDC D) 100,000 USDC",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "344",
    "question": "In a prediction market with two outcomes, if the current probability for Outcome A is 70% and a user wants to stake 100 tokens on Outcome B, what would be their potential payout if correct (ignoring fees)? A) 30 tokens B) 70 tokens C) 130 tokens D) 333.33 tokens",
    "answer": "D",
    "categories": [
      "DeFi",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "345",
    "question": "In a prediction market using an automated market maker, the cost function is C(q) = b * (e^(q/b) + e^(-q/b) - 2), where q is the number of shares and b is a liquidity parameter. If b = 50,000 and the current price is 0.9, approximately how many shares need to be sold to move the price to 0.8? A) 11,552 shares B) 23,105 shares C) 34,657 shares D) 46,210 shares",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "346",
    "question": "If a liquidity provider in a 50/50 ETH/DAI pool deposited when ETH was worth 2000 DAI and now ETH is worth 2500 DAI, what percentage of value have they lost to impermanent loss (ignoring fees)? A) 0.62% B) 1.25% C) 2.5% D) 3.8%",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "347",
    "question": "In a decentralized exchange using an automated market maker (AMM) model, if the current price of ETH is $2000 and the pool contains 100 ETH and 200,000 USDC, what is the price impact of a trade selling 10 ETH? A) 9.09% B) 10% C) 11.11% D) 20%",
    "answer": "A",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "348",
    "question": "In a prediction market using an automated market maker, the cost function is C(q) = b * log(1 + e^(q/b)), where q is the number of shares and b is a liquidity parameter. If b = 100 and the current price is 0.7, approximately how many shares need to be bought to move the price to 0.8? A) 22 shares B) 53 shares C) 69 shares D) 92 shares",
    "answer": "B",
    "categories": [
      "DeFi",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "349",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following methods in the ERC-20 standard is NOT considered optional for improving usability?\n\nA) name()\nB) symbol()\nC) decimals()\nD) totalSupply()",
    "answer": "D"
  },
  {
    "id": "350",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "According to the ERC-20 standard, what should happen when a transfer() function is called with a value of 0 tokens?\n\nA) The function should throw an error\nB) The function should return false without making any changes\nC) The function should execute normally and fire the Transfer event\nD) The function should execute but not fire the Transfer event",
    "answer": "C"
  },
  {
    "id": "351",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the primary reason for the recommended two-step process when changing allowances in ERC-20 tokens?\n\nA) To reduce gas costs associated with allowance changes\nB) To prevent a potential double-spend attack\nC) To ensure compatibility with older ERC-20 implementations\nD) To allow for cancellation of pending allowance changes",
    "answer": "B"
  },
  {
    "id": "352",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the main purpose of the ERC-1155 standard?\n\nA) To manage only fungible tokens\nB) To provide an interface for managing multiple token types in a single contract\nC) To replace ERC-20 and ERC-721 standards\nD) To create non-fungible tokens exclusively",
    "answer": "B"
  },
  {
    "id": "353",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "In ERC-1155, what should happen when a transfer() function is called with a value of 0 tokens?\n\nA) The function should throw an error\nB) The function should return false without making any changes\nC) The function should execute normally and fire the Transfer event\nD) The function should execute but not fire the Transfer event",
    "answer": "C"
  },
  {
    "id": "354",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How does the ERC-1155 standard handle metadata for a large number of tokens?\n\nA) It requires separate metadata for each token\nB) It doesn't support metadata for multiple tokens\nC) It uses a centralized database for metadata\nD) It uses a URI with ID substitution, allowing many tokens to share the same on-chain string",
    "answer": "D"
  },
  {
    "id": "355",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Beginner"
    ],
    "question": "What is the main purpose of the ERC-721 standard?\n\nA) To provide a standard for fungible tokens\nB) To provide a standard interface for non-fungible tokens (NFTs)\nC) To replace the ERC-20 standard\nD) To create a new cryptocurrency",
    "answer": "B"
  },
  {
    "id": "356",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following is NOT a way to initiate a transfer in ERC-721?\n\nA) By the owner of an NFT\nB) By an approved address for a specific NFT\nC) By an authorized operator\nD) By any address holding ERC-20 tokens",
    "answer": "D"
  },
  {
    "id": "357",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Beginner"
    ],
    "question": "According to the ERC-721 metadata recommendations, what is the suggested width range for images in the metadata?\n\nA) Between 100 and 500 pixels\nB) Between 200 and 800 pixels\nC) Between 320 and 1080 pixels\nD) Between 500 and 2000 pixels",
    "answer": "C"
  },
  {
    "id": "358",
    "categories": [
      "Ethereum",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the main purpose of EIP-1559?\n\nA) To increase transaction speed\nB) To introduce a new cryptocurrency\nC) To implement a new transaction pricing mechanism with burned fees and dynamic block sizes\nD) To reduce the total supply of Ethereum",
    "answer": "C"
  },
  {
    "id": "359",
    "categories": [
      "Ethereum",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What happens to the base fee per gas in EIP-1559?\n\nA) It is paid to miners\nB) It is returned to users\nC) It is burned\nD) It is stored in a smart contract",
    "answer": "C"
  },
  {
    "id": "360",
    "categories": [
      "Ethereum",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "In EIP-1559, what are the two fee parameters that users specify in their transactions?\n\nA) Min fee and max fee\nB) Base fee and total fee\nC) Gas price and gas limit\nD) Max priority fee per gas and max fee per gas",
    "answer": "D"
  },
  {
    "id": "361",
    "categories": [
      "Ethereum",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How does EIP-1559 improve fee estimation for users?\n\nA) By introducing a new algorithm for miners\nB) By allowing wallets to auto-set gas fees reliably due to predictable base fee changes\nC) By removing gas fees entirely\nD) By introducing a fixed fee for all transactions",
    "answer": "B"
  },
  {
    "id": "362",
    "categories": [
      "Ethereum",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is recommended for transaction ordering when transactions have the same priority fee in EIP-1559?\n\nA) Sort by gas limit\nB) Sort by transaction value\nC) Sort by time the transaction was received\nD) Sort randomly",
    "answer": "C"
  },
  {
    "id": "363",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the new maximum size limit for initcode introduced by EIP-3860?\n\nA) 24576 bytes\nB) 32768 bytes\nC) 49152 bytes\nD) 65536 bytes",
    "answer": "C"
  },
  {
    "id": "364",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What happens if the length of initcode to CREATE or CREATE2 instructions exceeds the new limit?\n\nA) The transaction is rejected\nB) The instruction execution exceptionally aborts\nC) The excess initcode is truncated\nD) An error is logged but execution continues",
    "answer": "B"
  },
  {
    "id": "365",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the main purpose of ERC-4337?\n\nA) To introduce a new cryptocurrency\nB) To implement account abstraction without consensus-layer changes\nC) To replace existing smart contract wallets\nD) To modify the Ethereum mining algorithm",
    "answer": "B"
  },
  {
    "id": "366",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is a UserOperation in ERC-4337?\n\nA) A new type of Ethereum account\nB) A structure describing a transaction to be sent on behalf of a user\nC) A smart contract for managing user permissions\nD) A consensus mechanism for validating transactions",
    "answer": "B"
  },
  {
    "id": "367",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "Who is responsible for bundling UserOperations in ERC-4337?\n\nA) Miners\nB) Validators\nC) Bundlers\nD) Users",
    "answer": "C"
  },
  {
    "id": "368",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the role of the EntryPoint contract in ERC-4337?\n\nA) To create new user accounts\nB) To execute bundles of UserOperations\nC) To store user funds\nD) To validate Ethereum blocks",
    "answer": "B"
  },
  {
    "id": "369",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is a paymaster in the context of ERC-4337?\n\nA) A contract that pays miners for block creation\nB) A user who pays for gas fees\nC) A helper contract that agrees to pay for the transaction instead of the sender\nD) A system for distributing rewards to stakers",
    "answer": "C"
  },
  {
    "id": "370",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "How are new accounts created in ERC-4337?\n\nA) Through a standard Ethereum transaction\nB) Using a factory contract with CREATE2\nC) By the EntryPoint contract\nD) Automatically when a user sends their first transaction",
    "answer": "B"
  },
  {
    "id": "371",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the purpose of the reputation system in ERC-4337?\n\nA) To rank users based on their transaction volume\nB) To prevent denial-of-service attacks by requiring stakes from certain entities\nC) To determine the order of UserOperations in a bundle\nD) To calculate gas fees for complex transactions",
    "answer": "B"
  },
  {
    "id": "372",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is a key security consideration for implementing ERC-4337?\n\nA) Ensuring compatibility with all existing Ethereum wallets\nB) Implementing a new consensus algorithm\nC) Heavy auditing and formal verification of the EntryPoint contract\nD) Modifying the Ethereum Virtual Machine",
    "answer": "C"
  },
  {
    "id": "373",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the main purpose of EIP-712?\n\nA) To introduce a new cryptocurrency\nB) To improve the security of Ethereum nodes\nC) To standardize hashing and signing of typed structured data\nD) To replace existing signature schemes",
    "answer": "C"
  },
  {
    "id": "374",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How does EIP-712 handle domain separation?\n\nA) By using a separate blockchain for each domain\nB) By introducing a domain separator in the signing process\nC) By requiring different private keys for each domain\nD) By encrypting data differently for each domain",
    "answer": "B"
  },
  {
    "id": "375",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the main goal of EIP-191?\n\nA) To create a new type of smart contract\nB) To standardize the format of signed data in Ethereum contracts\nC) To improve the speed of Ethereum transactions\nD) To introduce a new consensus mechanism",
    "answer": "B"
  },
  {
    "id": "376",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the first byte in the proposed signed_data format of EIP-191?\n\nA) 0x00\nB) 0x01\nC) 0x19\nD) 0xFF",
    "answer": "C"
  },
  {
    "id": "377",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What problem does EIP-155 aim to solve?\n\nA) Slow transaction speeds\nB) High gas costs\nC) Replay attacks\nD) Smart contract vulnerabilities",
    "answer": "C"
  },
  {
    "id": "378",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How many elements are hashed when computing the transaction hash according to EIP-155?\n\nA) 3\nB) 6\nC) 9\nD) 12",
    "answer": "C"
  },
  {
    "id": "379",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What does EIP-2930 introduce?\n\nA) A new consensus algorithm\nB) A new transaction type with an access list\nC) A new smart contract language\nD) A new token standard",
    "answer": "B"
  },
  {
    "id": "380",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "How much gas does EIP-2930 charge for each address in the access list?\n\nA) 1900\nB) 2100\nC) 2400\nD) 2600",
    "answer": "C"
  },
  {
    "id": "381",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the new gas cost for SLOAD operations on a cold (previously unaccessed) storage slot according to EIP-2929?\n\nA) 800\nB) 1900\nC) 2100\nD) 2600",
    "answer": "C"
  },
  {
    "id": "382",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "How does EIP-2929 handle gas costs for repeatedly accessing the same storage slot in a transaction?\n\nA) It always charges the full cold access cost\nB) It reduces the cost to 100 gas after the first access\nC) It increases the cost for each subsequent access\nD) It makes all subsequent accesses free",
    "answer": "B"
  },
  {
    "id": "383",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ],
    "question": "What does EIP-2565 primarily address?\n\nA) The gas cost of the ModExp precompile\nB) The implementation of a new cryptographic algorithm\nC) The block size limit\nD) The consensus mechanism",
    "answer": "A"
  },
  {
    "id": "384",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the minimum gas cost for the ModExp precompile according to EIP-2565?\n\nA) 100\nB) 200\nC) 500\nD) 1000",
    "answer": "B"
  },
  {
    "id": "385",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the additional role introduced by ERC-4907?\nA. Owner\nB. User\nC. Admin\nD. Manager",
    "answer": "B"
  },
  {
    "id": "386",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How does ERC-4907 improve efficiency in managing user roles?\nA. By requiring more frequent transactions\nB. By increasing gas costs\nC. By introducing an 'expires' function for automatic role revocation\nD. By eliminating the need for user roles",
    "answer": "C"
  },
  {
    "id": "387",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following is NOT a required function in an ERC-4907 compliant contract?\nA. setUser\nB. userOf\nC. userExpires\nD. transferUser",
    "answer": "D"
  },
  {
    "id": "388",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "DeFi",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What type of token does ERC-4626 standardize?\nA. Non-fungible tokens\nB. Governance tokens\nC. Tokenized Vaults representing shares of a single underlying EIP-20 token\nD. Stablecoins",
    "answer": "C"
  },
  {
    "id": "389",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "DeFi",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which functions in ERC-4626 provide more precise calculations accounting for fees and slippage?\nA. convertTo functions\nB. preview functions\nC. max functions\nD. asset functions",
    "answer": "B"
  },
  {
    "id": "390",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "DeFi",
      "Knowledge",
      "Intermediate"
    ],
    "question": "When calculating shares to issue or underlying tokens to transfer to users in ERC-4626, how should the calculation round?\nA. Down\nB. Up\nC. To the nearest whole number\nD. It doesn't matter",
    "answer": "A"
  },
  {
    "id": "391",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "What is the main purpose of Sign-In with Ethereum (SIWE)?\nA. To replace blockchain transactions\nB. To provide a centralized identity provider\nC. To offer a self-custodied alternative to centralized identity providers and improve interoperability\nD. To create a new cryptocurrency",
    "answer": "C"
  },
  {
    "id": "392",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "Which of the following is NOT a required field in a SIWE Message?\nA. domain\nB. address\nC. statement\nD. nonce",
    "answer": "C"
  },
  {
    "id": "393",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Intermediate"
    ],
    "question": "How should wallet implementers handle origin verification for SIWE requests?\nA. They should always trust the origin provided in the message\nB. They should verify the origin against the 'scheme' and 'domain' fields in the SIWE Message\nC. They should ignore origin verification entirely\nD. They should only verify the origin for certain types of requests",
    "answer": "B"
  },
  {
    "id": "394",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the main feature of ERC-3525 that distinguishes it from ERC-20 and ERC-721?\nA. It only supports fungible tokens\nB. It introduces an <ID, SLOT, VALUE> triple scalar model\nC. It is not compatible with ERC-721\nD. It doesn't support value transfers",
    "answer": "B"
  },
  {
    "id": "395",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is NOT a transfer model introduced by ERC-3525?\nA. Value transfer from ID to ID\nB. Value transfer from ID to address\nC. Value transfer from address to address\nD. ERC-721 compatible transfers",
    "answer": "C"
  },
  {
    "id": "396",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Tokenomics",
      "Knowledge",
      "Advanced"
    ],
    "question": "How does the 'Check, Notify and Response' model in ERC-3525 work?\nA. It requires separate safe transfer methods\nB. It doesn't allow contracts to reject transfers\nC. It checks for and calls onERC3525Received on the recipient contract\nD. It only works for transfers between addresses, not tokens",
    "answer": "C"
  },
  {
    "id": "397",
    "categories": [
      "Ethereum",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the main purpose of EIP-4844?\nA. To implement full sharding\nB. To reduce gas costs for normal transactions\nC. To introduce a stop-gap solution for scaling data-availability\nD. To replace the existing transaction format",
    "answer": "C"
  },
  {
    "id": "398",
    "categories": [
      "Ethereum",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "How is the base fee per blob gas calculated in EIP-4844?\nA. It's fixed and doesn't change\nB. It's based on the normal gas price\nC. It uses a linear function based on blob usage\nD. It uses a fake exponential function based on excess blob gas",
    "answer": "D"
  },
  {
    "id": "399",
    "categories": [
      "Ethereum",
      "Layer 2 Solutions",
      "Knowledge",
      "Advanced"
    ],
    "question": "What mechanism does EIP-4844 use to ensure forward compatibility?\nA. It uses fixed commitments for all blobs\nB. It uses versioned hashes as references to blobs\nC. It requires all contracts to be upgradeable\nD. It doesn't consider forward compatibility",
    "answer": "B"
  },
  {
    "id": "400",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "According to EIP-6780, what is the main change in functionality of the SELFDESTRUCT opcode?\nA. It will always delete the contract's code and storage\nB. It will only send Ether to the target without deleting the account\nC. It will have no effect on the contract\nD. It will create a new contract at the same address",
    "answer": "B"
  },
  {
    "id": "401",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following applications will NOT be broken by the implementation of EIP-6780?\nA. Contracts using CREATE2 for upgradability\nB. Contracts burning Ether via SELFDESTRUCT\nC. Contracts using SELFDESTRUCT in the same transaction they were created\nD. Contracts using SELFDESTRUCT to send Ether to other addresses",
    "answer": "C"
  },
  {
    "id": "402",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the main purpose of the MCOPY instruction introduced in EIP-5656?\nA. To provide a new way to create contracts\nB. To efficiently copy memory areas in the EVM\nC. To reduce the cost of storage operations\nD. To implement a new type of smart contract",
    "answer": "B"
  },
  {
    "id": "403",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "How much gas does it cost to copy 256 bytes using MCOPY according to EIP-5656?\nA. 96 gas\nB. 157 gas\nC. 27 gas\nD. 757 gas",
    "answer": "C"
  },
  {
    "id": "404",
    "categories": [
      "Ethereum",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ],
    "question": "What is the main purpose of EIP-4788?\nA. To improve the performance of smart contracts\nB. To reduce gas costs for transactions\nC. To expose beacon chain roots in the EVM\nD. To implement a new consensus algorithm",
    "answer": "C"
  },
  {
    "id": "405",
    "categories": [
      "Ethereum",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ],
    "question": "How many beacon block roots can be stored in the ring buffers introduced by EIP-4788?\nA. 1024\nB. 4096\nC. 8191\nD. 16384",
    "answer": "C"
  },
  {
    "id": "406",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "What are the two new opcodes introduced by EIP-1153?\nA. MLOAD and MSTORE\nB. SLOAD and SSTORE\nC. TLOAD and TSTORE\nD. CREATE and DESTROY",
    "answer": "C"
  },
  {
    "id": "407",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is NOT a potential use case for transient storage as introduced by EIP-1153?\nA. Reentrancy locks\nB. Single transaction ERC-20 approvals\nC. Permanent storage of large data sets\nD. Fee-on-transfer contracts",
    "answer": "C"
  },
  {
    "id": "408",
    "question": "What is the primary reason Ethereum uses Keccak-256 instead of the standardized SHA-3?\nA. Keccak-256 is faster\nB. Distrust in the NIST standardization process\nC. To maintain consistency with Bitcoin\nD. To reduce the likelihood of hash collisions",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "409",
    "question": "To generate an Ethereum address starting with 10 consecutive zeros, approximately how many private keys would need to be tried on average?\nA. 2^40\nB. 2^80\nC. 2^160\nD. 2^256",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "410",
    "question": "If the elliptic curve discrete logarithm problem is solved, which of the following would NOT be directly compromised?\nA. Ethereum address generation\nB. Transaction signature verification\nC. Blockchain data storage integrity\nD. Public key derivation from private keys",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "411",
    "question": "What is the primary advantage of the EIP-55 address format over ICAP?\nA. Better compatibility with existing systems\nB. Shorter address length\nC. Error detection capability for all addresses\nD. Support for multiple blockchain networks",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "412",
    "question": "Why does Ethereum use the last 20 bytes of the public key hash for addresses instead of the full 32 bytes?\nA. To reduce storage and transmission costs\nB. To increase the address space\nC. To improve collision resistance\nD. To enhance privacy",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "413",
    "question": "What is the approximate probability of finding two different Ethereum public keys that generate the same address?\nA. 2^-160\nB. 2^-256\nC. 1/2^160\nD. 1/2^256",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "414",
    "question": "What is the main advantage of using zero-knowledge proofs for proving ownership of an Ethereum address?\nA. Reduced gas costs\nB. Increased privacy\nC. Faster transaction speed\nD. Simplified wallet management",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Privacy",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "415",
    "question": "Which aspect of ECDSA is most critical for the security of Ethereum transactions?\nA. Signature size\nB. Random number generation\nC. Public key recovery\nD. Hash function choice",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "416",
    "question": "What is likely to be Ethereum's first step in addressing the threat of quantum computing?\nA. Immediate switch to post-quantum cryptography\nB. Increasing address length\nC. Implementing multi-signature schemes\nD. Encouraging frequent key rotation",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "417",
    "question": "In designing a smart contract wallet system with enhanced security, what is the most critical trade-off to consider?\nA. Security vs. transaction speed\nB. Compatibility vs. innovation\nC. Decentralization vs. recoverability\nD. Complexity vs. gas costs",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "418",
    "question": "Which of the following is NOT an advantage of deterministic wallets over non-deterministic wallets?\nA. Easier backup process\nB. Support for generating multiple addresses\nC. Improved privacy through address reuse\nD. Simplified recovery across different devices",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "419",
    "question": "In the BIP-39 mnemonic generation process, what is the purpose of the checksum?\nA. To increase the number of words in the mnemonic\nB. To verify the integrity of the generated mnemonic\nC. To make the mnemonic easier to memorize\nD. To encrypt the underlying private key",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "420",
    "question": "What is a potential security risk of using extended public keys in an HD wallet?\nA. They can be used to derive private keys\nB. They reduce the total number of possible addresses\nC. They can lead to address reuse\nD. If a child private key is compromised, other child keys might be at risk",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "421",
    "question": "In the BIP-44 HD wallet structure, what does the 'purpose' level signify?\nA. The type of cryptocurrency\nB. The specific account number\nC. The structural standard being used (set to 44' for BIP-44)\nD. Whether the wallet is for personal or business use",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "422",
    "question": "Which of the following would be the LEAST important consideration when designing an HD wallet system for a large corporation?\nA. Implementing multi-signature requirements\nB. Using hardened derivation for department-level keys\nC. Maximizing the use of non-deterministic wallets\nD. Creating an auditing system for key usage",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "423",
    "question": "What is the primary purpose of hardened derivation in HD wallets?\nA. To increase the number of possible child keys\nB. To allow public key-only derivation of child keys\nC. To prevent compromised child keys from exposing the entire branch\nD. To make key derivation faster and more efficient",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "424",
    "question": "Which of the following is NOT a benefit of using a passphrase with a BIP-39 mnemonic?\nA. Enhanced protection against mnemonic theft\nB. Ability to create plausible deniability wallets\nC. Simplified recovery process\nD. Additional layer of security",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Security",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "425",
    "question": "In the context of deriving Ethereum addresses from an extended public key, which of the following is true?\nA. It allows generation of private keys without the master private key\nB. It enables creation of new addresses without exposing private keys\nC. It guarantees the security of the entire HD wallet branch\nD. It eliminates the need for hardened derivation",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "426",
    "question": "How does key management in Ethereum wallets primarily differ from traditional banking systems?\nA. Ethereum wallets use simpler passwords\nB. Traditional banks offer better security\nC. Ethereum users have direct control over their funds through key management\nD. Traditional banks use blockchain technology for account management",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "427",
    "question": "When designing a user education program for an Ethereum wallet, which approach is likely to be LEAST effective?\nA. Providing interactive tutorials on wallet operations\nB. Using highly technical language to explain all concepts\nC. Offering a sandbox environment for practice transactions\nD. Implementing progressive disclosure of complex features",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Problem Solving",
      "Intermediate"
    ]
  },
  {
    "id": "428",
    "question": "Which of the following is NOT a viable strategy for managing nonces in a high-concurrency environment?\nA. Using a distributed cache with eventual consistency\nB. Implementing a centralized nonce allocation service\nC. Employing optimistic nonce allocation with local conflict resolution\nD. Relying solely on the latest nonce value from the blockchain for each transaction",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "429",
    "question": "In a dynamic gas price adjustment algorithm, which factor would be LEAST relevant for optimizing network efficiency?\nA. Current block utilization rate\nB. Historical gas price volatility\nC. Number of active unique addresses\nD. Time since last difficulty adjustment",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "430",
    "question": "Which feature of the proposed new transaction type would be most challenging to implement within Ethereum's current architecture?\nA. Dependency specification for related transactions\nB. Fallback actions for failed interactions\nC. Validity period for transaction execution\nD. Pre-flight simulation for gas estimation",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "431",
    "question": "Which of the following is NOT a viable approach for creating a post-quantum secure transaction signing scheme for Ethereum?\nA. Implementing lattice-based cryptography\nB. Using hash-based signatures\nC. Increasing the key size of the current ECDSA system\nD. Employing zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs)",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Cryptography",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "432",
    "question": "In a distributed system for offline signing and online broadcasting, which component is MOST critical for maintaining security while ensuring transaction timeliness?\nA. Load balancers for distributing signing tasks\nB. Hardware Security Modules (HSMs) for signing operations\nC. One-way data transfer mechanism between offline and online systems\nD. Redundant data storage for transaction queue management",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Security",
      "System Design",
      "Advanced"
    ]
  },
  {
    "id": "433",
    "question": "Which of the following would be the MOST effective addition to EIP-155 for preventing replay attacks in a sharded Ethereum environment?\nA. Including the full node IP address in the transaction signature\nB. Extending the chain ID to include shard identifiers\nC. Requiring all transactions to be signed by multiple parties\nD. Implementing mandatory time-locks on all cross-shard transactions",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "434",
    "question": "In a machine learning-based anomaly detection system for Ethereum's transaction propagation, which feature would be LEAST useful for identifying a transaction flooding attack?\nA. Transaction propagation speed and reach\nB. Node reputation scores based on historical behavior\nC. Gas price anomaly detection\nD. Total number of unique addresses in the network",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "435",
    "question": "Which of the following would be the MOST challenging aspect of implementing a unified cross-chain multi-signature standard?\nA. Creating a chain-agnostic signature format\nB. Supporting various signature algorithms\nC. Standardizing key management procedures\nD. Handling varying transaction models across chains",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "436",
    "question": "In designing a complex multi-signature smart contract system, which feature would likely consume the MOST gas during execution?\nA. Hierarchical permission checks\nB. Time lock implementations\nC. Social recovery processes\nD. Daily transaction limit enforcement",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "437",
    "question": "Which aspect of the proposed new Ethereum transaction model would be MOST challenging to implement while maintaining backwards compatibility?\nA. Layered transaction structure\nB. Native state channels support\nC. Sharding-aware transaction format\nD. Signature aggregation with BLS",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "438",
    "question": "In a predictive model for Ethereum transaction confirmation times, which feature would likely be the LEAST significant?\nA. Current mempool size\nB. Historical gas price trends\nC. Network hash rate\nD. Total number of unique addresses in the network",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "439",
    "question": "Which of the following would be the BIGGEST challenge in implementing a zero-knowledge proof system for tax compliance on Ethereum?\nA. Generating proofs efficiently\nB. Verifying proofs on-chain\nC. Encoding complex tax rules into circuits\nD. Maintaining user privacy",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Privacy",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "440",
    "question": "Which of the following is NOT a potential problem in a complex multi-level inheritance contract system?\nA. Function name clashes\nB. Ambiguity in execution order\nC. Increased gas costs\nD. Automatic resolution of inheritance conflicts",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "441",
    "question": "When implementing an advanced event system in Solidity, which of the following approaches is MOST effective for handling complex structured data?\nA. Using multiple simple events instead of one complex event\nB. Storing complex data off-chain and emitting only a reference\nC. Encoding complex data into bytes and decoding it in the frontend\nD. Using nested structs within the event parameters",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "442",
    "question": "In an upgradeable contract system using delegatecall, which of the following is the BIGGEST risk?\nA. Increased gas costs for function calls\nB. Potential storage layout collisions between versions\nC. Limitation on the number of possible upgrades\nD. Incompatibility with older Ethereum clients",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "443",
    "question": "In the complex function modifier system, which of the following is NOT a valid use of function modifiers?\nA. Implementing access control based on user roles\nB. Enforcing cooldown periods between actions\nC. Automatically refunding excess ether sent to a function\nD. Validating input parameters before function execution",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "444",
    "question": "When implementing a cross-contract communication system using ABI encoding, which of the following is the MOST significant security concern?\nA. Increased gas costs for function calls\nB. Potential for calling unintended functions on target contracts\nC. Limitation on the types of data that can be passed\nD. Incompatibility with older Solidity versions",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "445",
    "question": "In the optimized system for loop and array processing, which approach is likely to be the MOST gas-efficient for very large arrays?\nA. Naive approach with direct storage writes\nB. Pre-allocated memory array approach\nC. Batched updates approach\nD. Assembly-based tight loop approach",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "446",
    "question": "Which of the following is NOT typically part of a comprehensive error handling and recovery mechanism in Solidity?\nA. Use of custom error types\nB. Implementation of a circuit breaker pattern\nC. Automatic rollback of all state changes on any error\nD. Logging system for capturing error details",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "447",
    "question": "In a smart contract factory system, which feature is MOST crucial for ensuring predictable deployment of child contracts?\nA. Use of create2 for address generation\nB. Event emission for contract creation\nC. Proxy pattern for upgradeable contracts\nD. Batch operations for multiple deployments",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "448",
    "question": "Which of the following techniques is likely to be LEAST effective in optimizing storage costs in Solidity?\nA. Using tightly packed structs\nB. Employing nested mappings for complex relationships\nC. Storing all data as strings for flexibility\nD. Utilizing bit manipulation for boolean flags",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "449",
    "question": "In designing a gas-efficient voting system for a DAO, which of the following techniques would likely be LEAST effective in reducing gas costs?\nA. Using Merkle trees for voter verification\nB. Implementing a commit-reveal scheme\nC. Storing full voting history on-chain for each voter\nD. Batch processing of votes",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "450",
    "question": "In a complex token staking system, which feature is MOST important for ensuring long-term sustainability and adaptability?\nA. Time-locked staking periods\nB. Slashing mechanisms\nC. Dynamic reward rates\nD. Governance integration for parameter adjustments",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "451",
    "question": "When implementing a decentralized exchange with an AMM model, which of the following is MOST critical for preventing exploitation?\nA. Supporting multiple token pairs\nB. Implementing flash loan capability\nC. Using reentrancy guards\nD. Integrating a price oracle",
    "answer": "C",
    "categories": [
      "Ethereum",
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "452",
    "question": "Which of the following is NOT a recommended fix for the reentrancy vulnerability in the given smart contract?\nA. Implementing the checks-effects-interactions pattern\nB. Using transfer() instead of call()\nC. Implementing a reentrancy guard\nD. Increasing the gas limit for the function",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "453",
    "question": "In the Roulette contract, what is the primary security vulnerability?\nA. Integer overflow\nB. Reentrancy attack\nC. Miner-manipulatable randomness\nD. Unchecked return value",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "454",
    "question": "What is the main issue with the Ownable contract's constructor?\nA. It's not payable\nB. It doesn't use the 'constructor' keyword\nC. It doesn't initialize the owner variable\nD. It's not marked as external",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "455",
    "question": "Which of the following is NOT a vulnerability in the given Token contract?\nA. Integer underflow in the transfer function\nB. Lack of protection against integer overflow\nC. Missing events for transfers\nD. Absence of access control for the transfer function",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "456",
    "question": "What is the primary risk of using tx.origin for authentication in a smart contract?\nA. It can lead to out-of-gas errors\nB. It allows for reentrancy attacks\nC. It makes the contract vulnerable to phishing-like attacks\nD. It can cause integer overflow",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "457",
    "question": "Which of the following is NOT a vulnerability in the original TimeLock contract?\nA. Integer overflow in the increaseLockTime function\nB. Reentrancy vulnerability in the withdraw function\nC. Use of block.timestamp (now) for time measurements\nD. Lack of access control for the deposit function",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "458",
    "question": "What is the primary issue with using send() in the original Auction contract?\nA. It can cause an integer overflow\nB. It doesn't check the return value, potentially leading to lost funds\nC. It uses too much gas\nD. It allows anyone to withdraw funds",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "459",
    "question": "What is the main security concern with the GuessTheNumber contract?\nA. Reentrancy vulnerability\nB. Integer overflow in the guess function\nC. Lack of true randomness and predictability of the secret number\nD. Use of transfer() instead of send()",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "460",
    "question": "When designing a token contract that simultaneously complies with both ERC20 and ERC777 standards, which approach would most effectively resolve potential conflicts between the two standards?\nA. Completely ignore the hooks mechanism of ERC777\nB. Use proxy contracts to implement each standard separately\nC. Implement ERC777 behavior within ERC20 functions using version control\nD. Create a new hybrid standard to replace both ERC20 and ERC777",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "461",
    "question": "In implementing an ERC20 token with a dynamic supply mechanism based on external factors, which of the following would be the most critical challenge to address?\nA. Ensuring the oracle providing external data is sufficiently decentralized\nB. Preventing front-running attacks on supply adjustments\nC. Maintaining compliance with securities regulations\nD. Optimizing gas costs for frequent supply updates",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "462",
    "question": "When creating a hybrid token system with both fungible (ERC20) and non-fungible (ERC721) tokens, which feature would be most crucial for ensuring seamless interaction between the two token types?\nA. Implementing a shared liquidity pool for both token types\nB. Creating a wrapper contract that can convert between ERC20 and ERC721\nC. Developing a new standard that inherits from both ERC20 and ERC721\nD. Using a factory contract to manage the creation and destruction of both token types",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "463",
    "question": "In designing a decentralized domain name system based on ERC721, which feature would provide the strongest protection against domain squatting?\nA. Implementing a commit-reveal scheme for domain registration\nB. Requiring a significant stake in a governance token to register domains\nC. Using a quadratic pricing model for domain purchases\nD. Enforcing a mandatory waiting period before domain activation",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "464",
    "question": "When implementing a tokenized decentralized exchange (DEX) with atomic swaps, which mechanism would be most effective in mitigating front-running attacks?\nA. Implementing a time-delay between order submission and execution\nB. Using a commit-reveal scheme for order placement\nC. Employing a frequent batch auction mechanism instead of continuous trading\nD. Implementing strict slippage controls on all trades",
    "answer": "C",
    "categories": [
      "Ethereum",
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "465",
    "question": "In designing a token distribution system with multiple mechanisms (airdrop, vesting, milestone-based), which approach would best balance immediate liquidity needs with long-term price stability?\nA. Allocating the majority of tokens to milestone-based releases\nB. Implementing a dynamic vesting schedule based on project milestones\nC. Using a combination of linear vesting and liquidity mining incentives\nD. Conducting a series of small airdrops over an extended period",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "466",
    "question": "When implementing a token lending system, which feature would be most crucial for maintaining system solvency during extreme market conditions?\nA. Implementing dynamic interest rates based on utilization ratios\nB. Using a multi-layered liquidation mechanism with stability reserves\nC. Enforcing strict collateralization ratios with automatic deleveraging\nD. Implementing cross-asset collateralization with risk-adjusted weightings",
    "answer": "B",
    "categories": [
      "Ethereum",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "467",
    "question": "In designing a governance system for a DAO using tokens, which mechanism would be most effective in preventing governance attacks while maintaining decentralization?\nA. Implementing a quadratic voting system with identity verification\nB. Requiring a time-locked, escalating voting power accrual\nC. Using a futarchy model for key decision-making processes\nD. Implementing a delegate-call governance framework with on-chain vote tallying",
    "answer": "B",
    "categories": [
      "Ethereum",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "468",
    "question": "When designing a new token standard to improve upon ERC20 and ERC777, which feature would provide the greatest enhancement to token functionality while maintaining backward compatibility?\nA. Implementing native meta-transactions for gasless transfers\nB. Adding built-in token vesting and lock-up mechanisms\nC. Incorporating a standardized token upgrade pathway\nD. Implementing a hybrid fungible/non-fungible token model",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "469",
    "question": "In implementing a cross-chain token bridge system, which security measure would be most effective in preventing unauthorized token minting on the destination chain?\nA. Using a threshold signature scheme for validator consensus\nB. Implementing a challenge period with fraud proofs\nC. Enforcing a time lock on large transfers with governance oversight\nD. Using zero-knowledge proofs to verify the validity of cross-chain transfers",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Interoperability",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "470",
    "question": "When designing a token-based prediction market system, which approach would best address the oracle problem while maintaining decentralization?\nA. Implementing a Schelling point mechanism with staked reporters\nB. Using a futarchy model to determine the most accurate oracle\nC. Employing a decentralized oracle network with economic incentives\nD. Implementing a governance-controlled manual resolution system",
    "answer": "C",
    "categories": [
      "Ethereum",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "471",
    "question": "In implementing a privacy-preserving token system using zero-knowledge proofs, which feature would best balance transaction privacy with regulatory compliance?\nA. Implementing optional transaction viewing keys for authorized parties\nB. Using homomorphic encryption for balance updates with public aggregates\nC. Employing ring signatures with a minimum anonymity set size\nD. Implementing confidential transactions with mandatory identity verification",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Privacy",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "472",
    "question": "Which combination of features would be most effective in creating a Sybil-resistant decentralized oracle system?\nA. Stake-based participation and random oracle selection\nB. Reputation system and cryptographic commitments\nC. Decentralized identifiers and slashing conditions\nD. All of the above",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "473",
    "question": "In a high-security smart contract application requiring both data authenticity and confidential computation, which oracle solution would be most appropriate?\nA. TLSNotary proofs\nB. Intel SGX\nC. Oraclize with Amazon AWS\nD. ChainLink's decentralized oracle network",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "474",
    "question": "Which cryptographic technique would be least suitable for providing data to privacy-preserving smart contracts while maintaining data confidentiality?\nA. Zero-knowledge proofs\nB. Homomorphic encryption\nC. Secure multi-party computation\nD. Plain public key encryption",
    "answer": "D",
    "categories": [
      "Ethereum",
      "Privacy",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "475",
    "question": "Which of the following is NOT an effective method to mitigate oracle-related vulnerabilities in smart contracts?\nA. Implementing a time delay for critical actions based on oracle data\nB. Using a single, highly trusted oracle provider\nC. Employing a commit-reveal scheme for oracle updates\nD. Implementing circuit breakers for unexpected oracle behavior",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "476",
    "question": "In designing an oracle system for a large-scale IoT network, which approach would be least effective in addressing the challenge of high data throughput?\nA. Implementing a hierarchical data aggregation system\nB. Using edge computing to pre-process and filter data\nC. Employing a single centralized server for data processing\nD. Utilizing sharding to distribute data across multiple oracles",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "477",
    "question": "If Intel SGX were to be successfully attacked, which of the following would NOT be a viable mitigation strategy for systems like Town Crier?\nA. Using multiple TEE technologies alongside SGX\nB. Implementing additional layers of encryption for data\nC. Relying more heavily on SGX for critical operations\nD. Designing systems with graceful degradation capabilities",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "478",
    "question": "In which scenario would on-chain aggregation of oracle data be preferable to off-chain aggregation?\nA. When dealing with high-frequency data updates from numerous sources\nB. When full transparency of the aggregation process is crucial and gas costs are not prohibitive\nC. When complex machine learning algorithms are used for data processing\nD. When minimizing on-chain transactions is a top priority",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "479",
    "question": "For a prediction market oracle system dealing with long-term events, which feature would be LEAST important to implement?\nA. A distributed storage system for historical data\nB. A multi-stage reporting process with peer review\nC. Real-time data updates with minimal latency\nD. A governance model for handling disputes and protocol upgrades",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "480",
    "question": "Which of the following best describes the main difference between a Decentralized Application (DApp) and a traditional application?\nA. DApps use smart contracts, while traditional applications do not\nB. DApps have decentralized backend, frontend, storage, and messaging, while traditional applications are centralized\nC. DApps are built on the blockchain, while traditional applications are built on web servers\nD. DApps are more secure than traditional applications due to decentralization",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "481",
    "question": "An auction platform claims to be a DApp, but the frontend is hosted on a centralized server and the data is stored in a private database. What conclusion can be drawn about its decentralization?\nA. It is a true DApp since the smart contract is decentralized\nB. It is not a true DApp because both the frontend and data storage are centralized\nC. It is partially decentralized and qualifies as a DApp\nD. It can be considered a DApp if it uses a blockchain for the backend",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Dapps",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "482",
    "question": "Why is it preferable to store large assets, such as item descriptions and images, on Swarm instead of directly on the blockchain in a decentralized auction DApp?\nA. Blockchain storage is too slow for storing large files\nB. Swarm allows for free data storage, while blockchain storage is costly\nC. Swarm provides decentralized, cost-effective storage for large files, while blockchain storage is expensive and inefficient for this purpose\nD. Swarm is more secure than the blockchain for storing large files",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Dapps",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "483",
    "question": "What is the final step in deploying a decentralized auction platform DApp?\nA. Writing the smart contract and testing it on a local blockchain\nB. Deploying the smart contract to Ethereum using a tool like Truffle\nC. Launching the frontend on a local server using npm\nD. Configuring the Ethereum node to allow for contract deployment",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Dapps",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "484",
    "question": "What is one way to further decentralize a DApp that already uses decentralized smart contracts and asset storage?\nA. Host the frontend on a decentralized file system such as IPFS\nB. Store all user data directly on the blockchain to increase security\nC. Move the backend to a centralized server for faster processing\nD. Use a centralized messaging service for more reliable communication",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Dapps",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "485",
    "question": "In the EVM, stack depth is limited to 1024 items. What happens if this limit is exceeded during contract execution, and how can developers optimize stack usage to avoid this issue?\nA. The transaction is halted, and the remaining gas is refunded\nB. The transaction fails with a stack overflow error, and developers can reduce nested calls or offload calculations to memory or storage\nC. The transaction continues but with reduced gas efficiency\nD. The stack is cleared automatically to prevent errors",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "486",
    "question": "What happens if two functions in a smart contract have the same first 4-byte Keccak-256 hash in the EVM? How can developers avoid function selector collisions?\nA. One function is called randomly\nB. The contract will not deploy\nC. The wrong function may be called, and developers should change parameter order or function names to ensure unique selectors\nD. The functions will not be callable unless explicitly defined",
    "answer": "C",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "487",
    "question": "Why is gas consumption for storage (SSTORE) significantly higher than for memory (MLOAD/MSTORE) in the EVM? How can developers optimize gas usage related to storage operations?\nA. Storage is permanent on the blockchain, and developers can reduce gas consumption by minimizing storage writes and using memory for temporary calculations\nB. Storage requires more computational power\nC. Gas costs are arbitrarily higher for storage operations\nD. Developers should avoid storage entirely to minimize costs",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "488",
    "question": "How does the gas limit help mitigate reentrancy attacks in the EVM, and in what cases might an attacker bypass this safeguard?\nA. Gas limits prevent excessive external contract calls, but attackers can still exploit contracts if state changes are not handled properly before external calls\nB. Gas limits ensure contracts cannot be exploited\nC. Reentrancy attacks are always prevented by using gas limits\nD. Gas limits prevent contracts from calling other contracts",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "489",
    "question": "In the context of upgrading smart contracts, how does the proxy pattern protect against storage layout changes, and what might happen if developers ignore this pattern?\nA. The proxy pattern ensures that storage remains intact during upgrades, while ignoring it may lead to data loss or incorrect reads due to storage collisions\nB. It allows for faster contract upgrades\nC. It reduces gas costs during upgrades\nD. The proxy pattern eliminates the need for redeploying storage contracts",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "490",
    "question": "When performing complex loops in a smart contract, what are the most effective strategies to reduce gas costs?\nA. Break large computations into multiple on-chain transactions or offload calculations to the client-side before submitting results to the blockchain\nB. Perform all operations on-chain for maximum transparency\nC. Use larger gas limits to prevent the loop from running out of gas\nD. Avoid loops entirely in smart contract development",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "491",
    "question": "In the EVM, why is the gas cost of the SSTORE instruction significantly higher than that of the SLOAD instruction, and how can contract logic be optimized to minimize SSTORE calls?\nA. Writing to storage is costly because it is persistent, and developers can minimize SSTORE calls by caching data in memory or limiting state changes\nB. SSTORE requires more computational power\nC. The gas cost is higher due to complex cryptographic operations\nD. There is no significant difference between SSTORE and SLOAD costs",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "492",
    "question": "Before deploying a complex contract, how can developers estimate the gas cost of different operations and optimize their code for efficiency?\nA. Use testing frameworks like Remix or Truffle to simulate gas usage and optimize the code by minimizing loops, reducing storage writes, and selecting cheaper EVM instructions\nB. Estimate manually based on contract size\nC. Use a standard gas estimator without simulating contract execution\nD. Optimization is not necessary for gas efficiency",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "493",
    "question": "In proxy contracts, how can developers ensure interface compatibility between the proxy and the new logic contract during an upgrade, and what risks arise from ignoring this?\nA. By maintaining the same function signatures and storage layout, developers ensure compatibility. Ignoring this may lead to function mismatches or contract failure\nB. By changing the proxy’s storage layout\nC. By upgrading only the proxy contract and not the logic contract\nD. No compatibility checks are needed if the contracts are redeployed",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "494",
    "question": "In the EVM, what are the differences between the REVERT and INVALID instructions, and how do they impact gas consumption?\nA. REVERT rolls back the transaction without consuming all remaining gas, while INVALID consumes all gas and represents a critical error\nB. REVERT consumes more gas\nC. INVALID returns error codes, while REVERT does not\nD. Both instructions consume all gas, but REVERT returns a custom error message",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "495",
    "question": "During periods of network congestion, how can users ensure their transactions are prioritized by miners?\nA. Increase the gas price to offer higher incentives to miners, who prioritize transactions based on the gas price and total gas consumption\nB. Decrease gas price but increase gas limit\nC. Miners do not prioritize based on gas price\nD. Increase the size of the transaction",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "496",
    "question": "When contract A calls contract B, how is gas passed along the call chain, and how can developers avoid excessive gas consumption in such situations?\nA. Contract A passes remaining gas to contract B, and developers can set gas limits on external calls to prevent downstream contracts from consuming too much gas\nB. Contract B receives all gas from contract A\nC. Each contract must specify its own gas usage\nD. Gas is automatically reset for each contract in the call chain",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "497",
    "question": "In the EVM, handling fixed-length and variable-length data incurs different gas costs. What optimizations can be applied to minimize gas costs when dealing with variable-length data?\nA. Compress data structures and process variable-length data in batches to reduce memory access costs\nB. Use fixed-length data only\nC. Store variable-length data in storage to reduce costs\nD. Use loops to handle variable-length data",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "498",
    "question": "When a contract function consumes too much gas, causing transaction failure, what strategies can developers use to break down the function for successful execution?\nA. Split the function into multiple smaller functions and execute them in separate transactions or offload heavy calculations to an off-chain service\nB. Increase the gas limit for the transaction\nC. Avoid complex functions altogether\nD. Use recursion to handle complex logic",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "499",
    "question": "How can developers implement effective access control in EVM smart contracts, and what are the best practices to avoid excessive gas costs for permission checks?\nA. Use simple role-based access controls and avoid redundant permission checks on frequently executed functions to minimize gas overhead\nB. Implement all permission checks at the beginning of each function\nC. Store permissions in storage for easy access\nD. Perform access control only for critical functions",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "500",
    "question": "In a hybrid consensus mechanism using both PoW and PoS, participants can choose between mining or staking their coins for rewards. From a game theory perspective, under which conditions could this system become unbalanced or vulnerable?\nA. When mining rewards increase and staking rewards decrease, causing PoS participation to drop\nB. When staking rewards are higher than mining rewards, leading miners to abandon PoW and over-concentrating validation power in PoS\nC. When both PoW and PoS rewards are equal, making the system unstable\nD. When transaction fees are lower in PoS than PoW, creating an incentive for participants to switch",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "501",
    "question": "In cross-chain technology, malicious actors can attempt to manipulate the state of a smaller blockchain (Blockchain B) to affect transactions on a larger blockchain (Blockchain A). Which of the following trust models can best mitigate such an attack?\nA. Increasing the block size on Blockchain A to prevent manipulation from Blockchain B\nB. Introducing time-delays in state transfers between chains and using decentralized validators to verify cross-chain state changes\nC. Centralizing verification on Blockchain A to avoid risks from smaller blockchains\nD. Requiring users to manually verify transactions across both blockchains to ensure consistency",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Interoperability",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "502",
    "question": "In a sharded blockchain system, cross-shard transactions pose challenges for maintaining global consensus. How can the protocol ensure consistency across shards and prevent malicious actions from exploiting shard independence?\nA. Using a global locking mechanism to prevent conflicting transactions from being broadcast across multiple shards\nB. Implementing immediate finality for all transactions in each shard, regardless of cross-shard interactions\nC. Requiring all shards to validate every cross-shard transaction\nD. Using a proof-of-work model for cross-shard verification to increase security",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Layer 2 Solutions",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "503",
    "question": "A malicious validator in a PoS system controls 30% of the staked tokens and attempts to launch a 'double staking' or 'long-range attack'. Which consensus mechanism parameter could best prevent these attacks?\nA. Increasing the block size to limit double staking\nB. Harsh slashing penalties for validators detected double-signing on multiple forks\nC. Reducing the number of active validators to limit validator influence\nD. Allowing validators to withdraw their stakes immediately to prevent long-range attacks",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Consensus Mechanisms",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "504",
    "question": "In selfish mining, a mining pool secretly mines a private chain and only releases it when it surpasses the public chain. What factor helps mitigate the profitability of selfish mining for a mining pool with 35% of the network’s hash rate?\nA. Increasing the number of mining nodes in the network\nB. Bitcoin’s difficulty adjustment mechanism that increases mining difficulty when block times decrease\nC. Limiting the block reward for private chains\nD. Penalizing mining pools with high hash rates through transaction fees",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Consensus Mechanisms",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "505",
    "question": "Consensus algorithms like PBFT and Tendermint have high communication complexity to maintain consistency across nodes. Which of the following approaches can reduce communication overhead while maintaining security in large-scale networks?\nA. Using a layered consensus model with committees to achieve local consensus before propagating results to the entire network\nB. Requiring fewer nodes to validate transactions in larger networks\nC. Allowing nodes to communicate directly only with trusted peers\nD. Switching from a BFT-based algorithm to PoW for scalability",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Consensus Mechanisms",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "506",
    "question": "In a sharded blockchain network with cross-chain interactions, how can double-spend attacks be prevented when a malicious actor controls shards in two different blockchain networks?\nA. Requiring all transactions to be manually verified by users on both networks\nB. Implementing lock mechanisms that delay asset release until both networks confirm the transaction\nC. Increasing the difficulty of mining on both networks to prevent manipulation\nD. Disallowing cross-chain interactions altogether to prevent double-spend attempts",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Interoperability",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "507",
    "question": "What is 'Gas' in the Ethereum network? A) A type of cryptocurrency B) A measure of computational effort C) A consensus algorithm D) A method of token distribution",
    "answer": "B",
    "categories": [
      "Ethereum",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "508",
    "question": "If a smart contract on Ethereum requires 100,000 gas to execute and the current gas price is 20 Gwei, how much ETH will this transaction cost (assuming 1 ETH = 10^18 Wei)? A) 0.002 ETH B) 0.02 ETH C) 0.2 ETH D) 2 ETH",
    "answer": "A",
    "categories": [
      "Ethereum",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "509",
    "categories": [
      "Interoperability",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A developer is designing a cross-chain bridge for transferring assets between two different blockchain networks. The bridge needs to handle lock-and-mint operations securely. Part of the lock function on the source chain is implemented. Which combination of additional security measures and design choices would best protect this cross-chain bridge against potential attacks and vulnerabilities?\n\na) Implement a multi-signature scheme for validators, use a threshold signature scheme for cross-chain communication, add a time lock for large transfers, and implement a challenge period for disputed transfers\nb) Use a centralized relayer for cross-chain communication, implement instant finality for all transfers, store all bridge logic off-chain, and use a trusted third party for dispute resolution\nc) Implement a light client verification on both chains, use zero-knowledge proofs for transfer validation, add a liquidity pool for instant transfers, and implement a slashing mechanism for malicious validators\nd) Use a federated peg system, implement a centralized KYC process for all users, store all transfer data off-chain, and require manual approval for all cross-chain transfers",
    "answer": "a"
  },
  {
    "id": "510",
    "categories": [
      "Interoperability",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is designing a cross-chain interoperability protocol that allows for atomic swaps and cross-chain contract calls. The protocol needs to ensure transaction finality, handle differences in consensus mechanisms, and prevent cross-chain replay attacks. Which combination of techniques would best address these challenges?\n\na) Use a centralized relayer for all cross-chain communications, implement instant finality for all transactions, store all cross-chain state in a single contract, and use the same nonce structure across all chains\nb) Implement a Byzantine fault-tolerant witness network, use a two-phase commit protocol for atomic swaps, implement chain-specific nonce structures, and use threshold signatures for cross-chain validations\nc) Use a trusted bridge for all cross-chain transfers, implement a single shared state for all connected chains, use synchronized clocks for timing, and rely on a central authority for dispute resolution\nd) Implement a mesh network of peer-to-peer connections between chains, use probabilistic finality for all transactions, store all cross-chain data on each connected chain, and use the same address format across all chains",
    "answer": "b"
  },
  {
    "id": "511",
    "categories": [
      "Interoperability",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a cross-chain bridge for transferring assets between multiple blockchain networks with different consensus mechanisms and finality times. The bridge needs to handle lock-and-mint operations securely and efficiently. Consider the following challenges:\n\n1. Ensuring transaction finality across chains\n2. Preventing double-spending attacks\n3. Handling different block confirmation times\n4. Mitigating potential validator collusion\n5. Optimizing for gas efficiency\n6. Ensuring proper handling of failed or stuck transactions\n\nWhich combination of techniques and design choices would best address these challenges while maintaining security and efficiency?\n\na) Use a federated peg system with trusted validators, implement instant finality for all transfers, and use a centralized relayer for cross-chain communication\nb) Implement a light client verification on both chains, use zk-SNARKs for transfer validation, and add a liquidity pool for instant transfers\nc) Use a threshold signature scheme for validators, implement a two-way peg with timelocks, use optimistic validation with fraud proofs, and implement a challenge period for large transfers\nd) Implement a hash-locking mechanism for atomic swaps, use a burn-and-mint protocol for native assets, and rely on a trusted oracle network for exchange rate data",
    "answer": "c"
  },
  {
    "id": "512",
    "categories": [
      "Interoperability",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A cross-chain bridge enables users to transfer tokens between different blockchain networks. Recently, several large transactions failed due to improper validation of cross-chain messages, resulting in losses for users. In addition, the bridge lacked rate-limiting measures, leading to congestion during peak usage times. What is the best approach to secure the cross-chain bridge and prevent future failures?\nA) Implement proper validation of cross-chain messages and introduce rate limiting for large transfers\nB) Allow users to validate their own transactions manually\nC) Disable cross-chain functionality to prevent future losses\nD) Remove all restrictions on bridge operations to improve performance",
    "answer": "A"
  },
  {
    "id": "513",
    "question": "A new interoperability protocol proposes to use zk-SNARKs to prove the validity of transactions across chains. If generating a proof takes 2 minutes and verifying it takes 0.5 seconds, and proofs need to be generated and verified for both the source and destination chains, what's the minimum time needed for a cross-chain transaction to be fully confirmed, assuming block times of 15 seconds on both chains? A) 4 minutes 31 seconds B) 4 minutes 46 seconds C) 5 minutes 1 second D) 5 minutes 16 seconds",
    "answer": "A",
    "categories": [
      "Interoperability",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "514",
    "question": "A new interoperability protocol proposes to use a combination of zk-STARKs, Verifiable Random Functions (VRFs), and multi-party computation (MPC) for cross-chain transactions. If generating a zk-STARK proof takes 10 minutes, verifying it takes 1 second, generating a VRF output takes 0.2 seconds, verifying a VRF output takes 0.1 seconds, running the MPC protocol takes 30 seconds, and verifying the MPC result takes 0.5 seconds, what's the minimum time needed for a cross-chain transaction to be fully confirmed, assuming block times of 1 minute on both chains? A) 11 minutes 30 seconds B) 12 minutes C) 12 minutes 30 seconds D) 13 minutes",
    "answer": "C",
    "categories": [
      "Interoperability",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "515",
    "question": "A new interoperability protocol proposes to use a system of 'bridge validators' that need to stake tokens on all connected chains. These validators are slashed on all chains if they misbehave on any chain. How does this affect the security of cross-chain transactions compared to traditional bridging solutions? A) It provides uniform security across all bridges B) It increases the cost of attacks but may lead to centralization C) It reduces the risk of bridge hacks but increases systemic risk D) It makes the system more resilient to validator collusion",
    "answer": "B",
    "categories": [
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "516",
    "question": "In a particular Atomic Swap protocol, Alice wants to swap 10 BTC for 150 ETH with Bob. The protocol uses Hashed Timelock Contracts (HTLCs) with a timelock of 48 hours for BTC and 24 hours for ETH. What is a potential risk in this setup? A) Alice can steal both BTC and ETH B) Bob can delay the swap indefinitely C) The swap may fail if BTC transaction times are slow D) The timelock difference allows Bob to potentially steal funds",
    "answer": "D",
    "categories": [
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "517",
    "question": "A new interoperability protocol proposes to use a combination of zk-SNARKs and threshold signatures for cross-chain transactions. If generating a zk-SNARK proof takes 1 minute, verifying it takes 0.1 seconds, and collecting threshold signatures takes 30 seconds on average, what's the minimum time needed for a cross-chain transaction to be fully confirmed, assuming block times of 15 seconds on both chains and a 2/3 threshold for signatures? A) 2 minutes 15 seconds B) 2 minutes 30 seconds C) 2 minutes 45 seconds D) 3 minutes",
    "answer": "C",
    "categories": [
      "Interoperability",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "518",
    "question": "In a cross-chain bridge using a 5-of-8 multisig for validations, if each validator has a 1% chance of being compromised, what's the probability of a successful attack on the bridge? A) 0.0000001% B) 0.000001% C) 0.0001% D) 0.001%",
    "answer": "C",
    "categories": [
      "Interoperability",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "519",
    "question": "A new interoperability protocol proposes to use a combination of zk-SNARKs, Verifiable Delay Functions (VDFs), and threshold signatures for cross-chain transactions. If generating a zk-SNARK proof takes 3 minutes, verifying it takes 0.2 seconds, computing a VDF takes 1 minute, verifying a VDF takes 0.1 seconds, generating threshold signatures takes 15 seconds, and verifying threshold signatures takes 0.5 seconds, what's the minimum time needed for a cross-chain transaction to be fully confirmed, assuming block times of 30 seconds on both chains? A) 4 minutes 45 seconds B) 5 minutes C) 5 minutes 15 seconds D) 5 minutes 30 seconds",
    "answer": "C",
    "categories": [
      "Interoperability",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "520",
    "question": "A new interoperability protocol uses a threshold signature scheme with 100 validators, requiring 67 signatures. If each validator has a 99% uptime, what's the probability that a cross-chain transaction will be delayed due to insufficient online validators? A) Less than 0.1% B) Approximately 1% C) Approximately 5% D) More than 10%",
    "answer": "A",
    "categories": [
      "Interoperability",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "521",
    "question": "A new interoperability protocol proposes to use zk-SNARKs to prove the validity of transactions across chains. If generating a proof takes 1 minute and verifying it takes 1 second, and proofs need to be generated and verified for both the source and destination chains, what's the minimum time needed for a cross-chain transaction, assuming instant block times? A) 1 minute 1 second B) 2 minutes 1 second C) 2 minutes 2 seconds D) 4 minutes 2 seconds",
    "answer": "C",
    "categories": [
      "Interoperability",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "522",
    "question": "A cross-chain DeFi protocol uses a new 'Adaptive Bridging' technology. This technology dynamically adjusts the number of validators, required confirmations, and fees based on real-time network conditions, security threat levels, and cross-chain asset liquidity. If the mainnet transaction volume suddenly increases by 300%, the security threat level rises from 'low' to 'medium,' and cross-chain liquidity drops by 50%, what action is the system most likely to take? A) Increase the number of validators by 50%, double the confirmations, and increase fees by 20% B) Increase the number of validators by 100%, increase confirmations by 50%, and increase fees by 50% C) Keep the number of validators unchanged, double the confirmations, and increase fees by 100% D) Increase the number of validators by 200%, keep confirmations unchanged, and increase fees by 80%",
    "answer": "B",
    "categories": [
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "523",
    "categories": [
      "Layer 2 Solutions",
      "Consensus Mechanisms",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A developer is implementing a new consensus mechanism for a layer-2 scaling solution. The mechanism involves a committee of validators who are responsible for proposing and validating state transitions. The following code snippet shows part of the validation process:\n\n```solidity\nfunction validateStateTransition(bytes32 oldRoot, bytes32 newRoot, bytes memory proof) public {\n    require(validators[msg.sender].stake > minStake, \"Insufficient stake\");\n    require(verifyMerkleProof(oldRoot, newRoot, proof), \"Invalid state transition\");\n    \n    emit StateTransitionValidated(msg.sender, oldRoot, newRoot);\n    \n    if (validations[newRoot].count + 1 >= requiredValidations) {\n        finalizeStateTransition(newRoot);\n    } else {\n        validations[newRoot].count += 1;\n        validations[newRoot].validators.push(msg.sender);\n    }\n}\n```\n\nWhich combination of additional security measures and modifications would best enhance the robustness and attack-resistance of this consensus mechanism?\n\na) Implement a random validator selection process, add a slashing mechanism for malicious behavior, use a threshold signature scheme for finalization, and implement a challenge period for state transitions\nb) Increase the minimum stake requirement, use a fixed set of trusted validators, implement instant finality, and store all state data on the main chain\nc) Implement a fisherman's challenge for fraud proofs, use a reputation system for validators, implement a timelock for large state transitions, and use zero-knowledge proofs for state updates\nd) Use a Proof-of-Authority consensus, implement a centralized validator approval process, store all validation logic off-chain, and use hardware security modules for signing",
    "answer": "a"
  },
  {
    "id": "524",
    "categories": [
      "Layer 2 Solutions",
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a privacy-focused layer-2 scaling solution using zk-rollups. The system needs to handle transaction batching, proof generation, and on-chain verification. Consider challenges like ensuring transaction privacy, minimizing on-chain verification costs, handling large transaction volumes, and preventing front-running and malicious operator behavior. Which combination of techniques and design choices would best address these challenges while maintaining the security and efficiency of the zk-rollup system?\n\na) Use homomorphic encryption for all transactions, implement a trusted setup ceremony, use recursive SNARKs for proof aggregation, and implement a commit-reveal scheme for transaction ordering\nb) Store all transaction data on-chain in encrypted form, use a centralized prover for efficiency, implement instant finality for all state transitions, and require KYC for all users\nc) Use stealth addresses for enhanced privacy, implement a distributed prover network, use zero-knowledge STARKs for scalability, and implement an economic incentive system for proper operator behavior\nd) Implement full nodes for all users, use ring signatures for transaction privacy, store all proof data off-chain, and use a trusted hardware enclave for proof generation",
    "answer": "c"
  },
  {
    "id": "525",
    "categories": [
      "Layer 2 Solutions",
      "Consensus Mechanisms",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a novel layer-1 blockchain with a focus on scalability and security. They are considering implementing a sharding mechanism with a unique cross-shard communication protocol. The following challenges need to be addressed:\n\n1. Ensuring data availability across shards\n2. Preventing single-shard takeover attacks\n3. Maintaining consistent state across shards\n4. Optimizing cross-shard transaction throughput\n\nWhich combination of techniques and design choices would best address these challenges while maximizing scalability and security?\n\na) Use erasure coding for data availability, implement frequent random validator rotation, use a Byzantine agreement protocol for cross-shard consensus, and implement optimistic execution for cross-shard transactions\nb) Implement full replication of all shard data, use a fixed set of validators per shard, rely on the beacon chain for cross-shard communication, and use synchronous cross-shard transactions\nc) Use fraud proofs for data availability, implement a VRF-based validator selection, use a two-phase commit protocol for cross-shard transactions, and implement state channels for frequent cross-shard interactions\nd) Implement a data availability sampling technique, use a hybrid PoS/PoW consensus mechanism, rely on zero-knowledge proofs for cross-shard state verification, and use a leaderless consensus protocol within shards",
    "answer": "a"
  },
  {
    "id": "526",
    "categories": [
      "Layer 2 Solutions",
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a privacy-focused layer-2 scaling solution using zk-rollups. They want to implement a system that ensures transaction privacy, minimizes on-chain verification costs, handles large transaction volumes, and prevents front-running. Consider the following design choices:\n\n1. Use of recursive SNARKs for proof aggregation\n2. Implementation of a decentralized sequencer network\n3. Use of homomorphic encryption for transaction data\n4. Implementation of a commit-reveal scheme for transaction ordering\n5. Use of zero-knowledge STARKs for scalability\n6. Implementation of an economic incentive system for proper operator behavior\n\nWhich combination of these design choices would create the most robust and secure layer-2 solution, and why?\n\na) 1, 3, 4 - This combination provides efficient proof aggregation, transaction privacy, and protection against front-running\nb) 2, 5, 6 - This setup offers decentralization, scalability, and economic incentives for security\nc) 1, 2, 5, 6 - This model combines efficient proof aggregation, decentralization, scalability, and economic security\nd) 3, 4, 5, 6 - This combination focuses on privacy, front-running protection, scalability, and economic incentives",
    "answer": "c"
  },
  {
    "id": "527",
    "categories": [
      "Layer 2 Solutions",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a layer-2 scaling solution that combines optimistic rollups with a novel fraud proof system for faster withdrawals. The system needs to handle complex smart contract executions, ensure data availability, and provide strong security guarantees. Consider the following challenges:\n\n1. Minimizing the fraud proof verification time on the main chain\n2. Ensuring data availability for fraud proof generation\n3. Handling potential malicious behavior by validators\n4. Optimizing for gas efficiency in contract deployments and executions\n5. Maintaining synchronization between the layer-2 and the main chain\n6. Providing fast and secure withdrawal mechanisms\n\nWhich combination of techniques and design choices would best address these challenges while maximizing the scalability and security of the layer-2 solution?\n\na) Use interactive fraud proofs with bisection, implement a data availability committee, use a bonded validator set with slashing conditions, implement contract bytecode compression, use a state commitment scheme with incremental updates, and implement an optimistic withdrawal mechanism with liquidity providers\nb) Use non-interactive fraud proofs, store all data on-chain, rely on a single trusted operator, use standard contract deployment mechanisms, synchronize state roots on every block, and require a 7-day withdrawal period for all assets\nc) Use zk-SNARKs for all state transitions, implement full data sharding, use a randomly selected validator set, implement a new smart contract language for gas optimization, use a lazy state update mechanism, and require interactive challenges for all withdrawals\nd) Use fraud proofs with state diffs, implement Merkleized data availability proofs, use a permissioned validator set, implement a new EVM-compatible bytecode format, use an optimistic state update mechanism with frequent checkpoints, and implement a bond-based fast withdrawal system",
    "answer": "a"
  },
  {
    "id": "528",
    "categories": [
      "Layer 2 Solutions",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized application (dApp) implements state channels to allow off-chain micro-transactions between participants. The dispute resolution mechanism is not well-defined, leading to unresolved disputes and blocking further on-chain updates. Additionally, malicious actors could flood the channel with invalid off-chain states, slowing down the resolution process. What should be the primary security enhancement?\nA) Use multi-signature wallets to ensure both parties sign all off-chain updates\nB) Implement cryptographic signatures for off-chain updates and a force-close mechanism to finalize disputes\nC) Rely solely on timelocks to handle unresponsive parties\nD) Allow disputes to be resolved via an external, centralized authority for faster resolution",
    "answer": "B"
  },
  {
    "id": "529",
    "question": "In a zk-rollup system, the L2 operator needs to generate a validity proof for each batch of transactions. If generating a proof takes 30 seconds, and a new block (which can include one batch) is produced on L1 every 15 seconds, what's the maximum sustainable TPS of this L2, assuming each batch can include 1000 transactions? A) 16.67 TPS B) 33.33 TPS C) 50 TPS D) 66.67 TPS",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "530",
    "question": "In a Layer 2 rollup solution, if the cost of submitting a proof to the main chain is 1 ETH and the rollup can include up to 10,000 transactions per proof, what is the minimum per-transaction fee (in ETH) needed to break even, ignoring any other operational costs? A) 0.00001 ETH B) 0.0001 ETH C) 0.001 ETH D) 0.01 ETH",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "531",
    "question": "In a state channel network, if Alice wants to send 10 tokens to Dave through Bob and Charlie (Alice -> Bob -> Charlie -> Dave), and each intermediary requires a 1 token fee, how many tokens does Alice need to have in her state channel with Bob to ensure the transaction goes through, assuming no other constraints? A) 10 tokens B) 11 tokens C) 12 tokens D) 13 tokens",
    "answer": "C",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "532",
    "question": "In a dApp using a state channel for off-chain transactions, if opening a channel costs 0.01 ETH and closing costs 0.02 ETH, what's the break-even point in number of transactions, assuming each on-chain transaction costs 0.003 ETH? A) 10 transactions B) 15 transactions C) 20 transactions D) 25 transactions",
    "answer": "A",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "533",
    "question": "In a Layer 2 payment channel network, if Alice and Bob have a channel with 10 coins total, and they've made 3 transactions back and forth, what's the maximum number of on-chain transactions needed to reflect their final balances? A) 1 B) 2 C) 3 D) 4",
    "answer": "A",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "534",
    "question": "What is the main purpose of the 'Lightning Network' in Bitcoin? A) To increase mining rewards B) To enable instant, low-cost transactions C) To improve privacy D) To create new Bitcoin addresses",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "535",
    "question": "If a Layer 2 solution can process 1000 transactions per second and it takes 15 minutes to submit a proof to the main chain, what is the maximum number of transactions that can be included in a single proof, assuming no other limitations? A) 15,000 B) 60,000 C) 900,000 D) 3,600,000",
    "answer": "C",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "536",
    "question": "A Layer 2 solution uses an optimistic rollup model with a 7-day challenge period. If a malicious operator submits an invalid state transition, what's the maximum amount of time they could delay a user's exit to L1, assuming the user immediately detects the fraud and initiates a challenge? A) 7 days B) 14 days C) 21 days D) 28 days",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "537",
    "question": "What is the primary purpose of a 'Layer 2' solution in blockchain technology? A) To increase the block size B) To improve scalability and transaction speed C) To enhance mining efficiency D) To create new cryptocurrencies",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "538",
    "question": "In a particular zk-rollup implementation, the L2 operator needs to generate and submit a validity proof to L1 every 10 minutes. Each proof can cover up to 10,000 transactions. If the L2 state size grows by 1 KB per transaction and the initial state size is 1 GB, how many transactions can be processed before the state size reaches 1 TB, assuming maximum transaction throughput? A) 1 billion transactions B) 999 million transactions C) 998 million transactions D) 997 million transactions",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "539",
    "question": "A Layer 2 solution implements a new challenge-response mechanism where challengers must stake tokens to initiate a challenge. If the challenge is successful, they receive a reward from the losing party's stake. If it fails, they lose their stake. How might this affect the security of the L2 compared to a system without challenger stakes? A) Increase security by incentivizing more challengers B) Decrease security by raising the barrier to challenge C) No significant change in security D) Improve security only for high-value transactions",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "540",
    "question": "A Layer 2 solution implements a new exit mechanism where users can 'fast exit' by paying a premium to liquidity providers on L1. These LPs then take over the exiting user's position on L2. What's a potential issue with this mechanism? A) Increased risk of exit scams B) Higher costs for users during high-demand periods C) Potential for LPs to be stuck with illiquid L2 positions D) Reduced security",
    "answer": "C",
    "categories": [
      "Layer 2 Solutions",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "541",
    "question": "In a particular Layer 2 scaling solution, users need to periodically submit 'presence claims' to the main chain to prove their continued activity. If a user fails to submit a claim within a certain period, their assets can be liquidated. What's a potential issue with this mechanism? A) Increased main chain congestion B) Risk of losing funds due to network issues C) Higher operational costs for users D) Potential for grieving attacks",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "542",
    "question": "In a zero-knowledge rollup, the cost of generating a proof is O(n log n) where n is the number of transactions, while the cost of verifying the proof on L1 is constant. If generating a proof for 1000 transactions takes 1 second and costs $0.1, what's the approximate cost of generating a proof for 1 million transactions? A) $100 B) $200 C) $300 D) $400",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "543",
    "question": "A Layer 2 solution implements an optimistic rollup with a 7-day challenge period for withdrawals. If the cost of submitting a fraudproof on the main chain is 0.1 ETH, what is the minimum value of funds (in ETH) that an attacker must withdraw to make the attack profitable, assuming they can maximize the use of the stolen funds during the challenge period and earn a 10% return? A) 0.1 ETH B) 1 ETH C) 10 ETH D) 100 ETH",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "544",
    "question": "If a blockchain uses recursive zk-SNARKs to compress historical data, and each recursive proof reduces the data size by 50% but takes 1 minute to compute, how long would it take to compress 1 year of blockchain data into a single proof, assuming the original data can be processed at 1 day per minute? A) 5.7 hours B) 8.5 hours C) 11.4 hours D) 17.1 hours",
    "answer": "C",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "545",
    "question": "In a zero-knowledge rollup system, the cost of generating a proof is proportional to the number of transactions in the batch, while the cost of verifying the proof on L1 is constant. If generating a proof for a single transaction takes 0.1 seconds and costs $0.01 in computational resources, and verifying a proof on L1 costs $10 in gas fees, what's the optimal batch size to minimize the per-transaction cost, assuming L1 gas fees are the dominant cost? A) 100 transactions B) 500 transactions C) 1000 transactions D) 5000 transactions",
    "answer": "C",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "546",
    "question": "A Layer 2 solution uses an optimistic rollup model with a 7-day challenge period. If a malicious operator submits an invalid state transition and immediately starts withdrawing funds, what's the minimum amount of time honest users have to detect the fraud and initiate a challenge, assuming the withdrawal process takes 3 days? A) 3 days B) 4 days C) 5 days D) 6 days",
    "answer": "B",
    "categories": [
      "Layer 2 Solutions",
      "Security",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "547",
    "question": "An innovative Layer 2 solution introduces the concept of 'Fractal Scaling,' allowing infinite creation of sub-layers on top of it. Each sub-layer has 50% of the throughput and 25% of the latency of its parent layer. If the base layer (Layer 2) has a throughput of 2000 TPS and a latency of 1 second, how many layers need to be created to achieve a throughput of 1 million TPS while keeping the total latency under 5 seconds? A) 4 layers B) 5 layers C) 6 layers D) 7 layers",
    "answer": "C",
    "categories": [
      "Layer 2 Solutions",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "548",
    "categories": [
      "Privacy",
      "Security",
      "Smart Contract",
      "System Design",
      "Advanced"
    ],
    "question": "When creating a smart contract wallet that combines multisig with social recovery using BIP32 HD wallets, which of the following is NOT a significant challenge?\nA. Implementing a secure upgrade mechanism for the smart contract\nB. Managing the complexity of combining multiple security features\nC. Ensuring compatibility with all existing cryptocurrencies\nD. Optimizing gas costs for complex smart contract operations",
    "answer": "C"
  },
  {
    "id": "549",
    "categories": [
      "Privacy",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A cryptocurrency exchange suspects some withdrawal recipients are attempting transaction pinning attacks. Which strategy would be MOST effective in mitigating this risk while maintaining efficient operations?\nA. Discontinuing all batched transactions and sending only individual withdrawals\nB. Implementing a flat, high fee rate for all transactions to ensure quick confirmation\nC. Using smaller batches with multiple exchange-controlled outputs and CPFP carve-out\nD. Delaying all withdrawals until network congestion decreases",
    "answer": "C"
  },
  {
    "id": "550",
    "categories": [
      "Privacy",
      "Security",
      "Knowledge",
      "Advanced"
    ],
    "question": "Which of the following is NOT a recommended strategy for improving privacy when implementing a lightweight client using compact block filters?\nA) Requesting filters and blocks from multiple, randomly selected peers\nB) Adding decoy block downloads\nC) Using Tor for filter and block requests\nD) Sharing the client's address list with trusted nodes for faster filtering",
    "answer": "D"
  },
  {
    "id": "551",
    "categories": [
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A decentralized identity (DID) system is being built on a smart contract platform. The system needs to handle identity creation, attestation, and verification while ensuring privacy and security. Consider the following code snippet for identity creation:\n\n```solidity\nfunction createIdentity(bytes32 identityCommitment) public {\n    require(identities[msg.sender].created == false, \"Identity already exists\");\n    \n    Identity memory newIdentity = Identity({\n        commitment: identityCommitment,\n        created: true,\n        attestations: new bytes32[](0)\n    });\n    \n    identities[msg.sender] = newIdentity;\n    emit IdentityCreated(msg.sender, identityCommitment);\n}\n```\n\nWhich combination of additional features and modifications would best enhance the security and privacy of this DID system?\n\na) Implement zero-knowledge proofs for identity verification, use proxy re-encryption for data sharing, add a reputation system based on attestations, and implement a recovery mechanism using social recovery\nb) Store all identity data off-chain, use a centralized KYC process, implement biometric verification, and give a trusted authority the power to revoke identities\nc) Use homomorphic encryption for all identity data, implement a blockchain-based PKI system, require hardware wallet signatures for all operations, and store all attestations on-chain\nd) Implement a federated identity system, use a consortium blockchain for faster transactions, store all identity data in plain text for transparency, and require manual verification for all attestations",
    "answer": "a"
  },
  {
    "id": "552",
    "categories": [
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A developer is implementing a decentralized identity system with selective disclosure capabilities. The system needs to handle credential issuance, verification, and revocation while preserving user privacy. Which combination of techniques would provide the highest level of security and privacy for this identity system?\n\na) Use a centralized identity provider, store all credentials on-chain in plaintext, implement a single master key for all operations, and use a trusted timestamp service for revocations\nb) Use self-sovereign identities, store all credentials off-chain, implement a centralized revocation list, and use plaintext data transmission for credential verification\nc) Use decentralized identifiers (DIDs), implement verifiable credentials with zero-knowledge proofs, use a distributed hash table for credential storage, and implement a privacy-preserving revocation mechanism using accumulators\nd) Use federated identities, implement a centralized credential repository, use symmetric encryption for all data, and rely on a trusted third party for all verification processes",
    "answer": "c"
  },
  {
    "id": "553",
    "categories": [
      "Privacy",
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a privacy-focused layer-1 blockchain with native support for confidential transactions and private smart contracts. The system needs to ensure transaction privacy, support complex computations, and maintain auditability for regulatory compliance. Which combination of cryptographic techniques and blockchain design would best achieve these goals?\n\na) Use fully homomorphic encryption for all transactions, implement a centralized zero-knowledge proof generator, store all contract states off-chain, and use a trusted setup ceremony for the entire network\nb) Implement confidential transactions using Pedersen commitments, use zk-SNARKs for private contract execution, implement viewing keys for selective disclosure, and use a combination of shielded and transparent pools for flexibility\nc) Use ring signatures for transaction privacy, implement secure multi-party computation for contract execution, store all transaction data in encrypted form on-chain, and use a centralized compliance authority for audits\nd) Implement mandatory privacy for all transactions using CryptoNote protocol, use trusted execution environments for contract computations, store all data off-chain in encrypted shards, and use zero-knowledge sets for efficient proofs",
    "answer": "b"
  },
  {
    "id": "554",
    "categories": [
      "Privacy",
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a privacy-focused layer-1 blockchain with native support for confidential transactions and private smart contracts. The system needs to ensure transaction privacy, support complex computations, and maintain auditability for regulatory compliance. Consider the following design choices:\n\n1. Use of ring signatures for transaction privacy\n2. Implementation of zero-knowledge proofs for smart contract execution\n3. Use of homomorphic encryption for data processing\n4. Implementation of secure multi-party computation for cross-contract interactions\n5. Use of trusted execution environments for validator nodes\n6. Implementation of a mixing service for additional anonymity\n\nWhich combination of these techniques would provide the highest level of privacy and security while still allowing for complex computations and regulatory compliance?\n\na) 1, 2, 6 - This combination provides strong transaction privacy, secure contract execution, and additional anonymity layers\nb) 2, 3, 4 - This setup offers privacy-preserving smart contracts, secure data processing, and private cross-contract interactions\nc) 1, 3, 5 - This model combines transaction privacy, secure data processing, and trusted execution for validators\nd) 2, 4, 5 - This combination focuses on private smart contracts, secure multi-party interactions, and trusted execution environments",
    "answer": "b"
  },
  {
    "id": "555",
    "categories": [
      "Privacy",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing a decentralized identity system with selective disclosure capabilities for a consortium blockchain. The system needs to handle credential issuance, verification, and revocation while preserving user privacy and ensuring compliance with data protection regulations. Consider the following challenges:\n\n1. Ensuring the privacy of sensitive user data\n2. Providing efficient revocation mechanisms\n3. Enabling selective disclosure of credentials\n4. Ensuring interoperability with existing identity systems\n5. Preventing credential forgery and unauthorized issuance\n6. Maintaining an audit trail for regulatory compliance\n\nWhich combination of cryptographic techniques and system design choices would best address these challenges while maintaining the security and privacy of the identity system?\n\na) Use zero-knowledge proofs for credential verification, implement a revocation accumulator for efficient revocation checks, use attribute-based encryption for selective disclosure, implement W3C DID standards for interoperability, use threshold signatures for credential issuance, and maintain an encrypted audit log with access controls\nb) Use fully homomorphic encryption for all data processing, implement a centralized revocation list, use a trusted execution environment for credential handling, implement a proprietary identity protocol, use a single trusted issuer for all credentials, and store all audit logs off-chain\nc) Use ring signatures for anonymous credentials, implement a time-based automatic revocation system, use all-or-nothing disclosure for simplicity, implement SAML for interoperability, use multi-signature schemes for credential issuance, and broadcast all system activities for transparency\nd) Use blind signatures for credential issuance, implement a distributed hash table for revocation status, use plaintext credentials with access control lists, implement OpenID Connect for interoperability, use a trusted third party for all credential issuance, and store all audit logs on a public blockchain",
    "answer": "a"
  },
  {
    "id": "556",
    "categories": [
      "Privacy",
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A team is developing a privacy-focused layer-1 blockchain with native support for confidential transactions, private smart contracts, and decentralized identity management. The system needs to ensure transaction privacy, support complex zero-knowledge computations, maintain auditability for regulatory compliance, and provide scalable identity solutions. Consider the following code snippet for a confidential transfer function:\n\n```solidity\nfunction confidentialTransfer(\n    bytes32[] memory inputNullifiers,\n    bytes32[] memory outputCommitments,\n    bytes calldata proof,\n    bytes calldata encryptedData\n) external {\n    require(verifyProof(proof, inputNullifiers, outputCommitments), \"Invalid proof\");\n    \n    for (uint i = 0; i < inputNullifiers.length; i++) {\n        require(!nullifierSet.contains(inputNullifiers[i]), \"Nullifier already used\");\n        nullifierSet.add(inputNullifiers[i]);\n    }\n    \n    for (uint i = 0; i < outputCommitments.length; i++) {\n        commitmentSet.add(outputCommitments[i]);\n    }\n    \n    emit ConfidentialTransfer(msg.sender, inputNullifiers, outputCommitments, encryptedData);\n}\n\nfunction verifyProof(bytes calldata proof, bytes32[] memory publicInputs, bytes32[] memory publicOutputs) internal returns (bool) {\n    // Zero-knowledge proof verification logic\n}\n```\n\nWhich combination of additional mechanisms and cryptographic techniques would provide the highest level of privacy, security, and scalability for this blockchain system?\n\na) Use bulletproofs for range proofs, implement Pedersen commitments for balances, use ring signatures for transaction authorization, implement a zk-rollup layer for scalability, use identity-based encryption for selective disclosure, and implement a decentralized key management system\nb) Use zk-SNARKs for all proofs, implement fully homomorphic encryption for smart contract execution, use stealth addresses for enhanced privacy, implement a sharding mechanism with secure cross-shard communication, use attribute-based credentials for identity management, and implement a threshold cryptography scheme for distributed key generation\nc) Use STARKs for scalable proofs, implement Boneh-Boyen signatures for non-interactive proofs, use CoinJoin for transaction privacy, implement a layer-2 solution with optimistic rollups, use self-sovereign identity with DIDs, and implement a trusted execution environment for sensitive computations\nd) Use Groth16 for efficient zk-proofs, implement El-Gamal encryption for confidential transactions, use Lamport signatures for quantum resistance, implement a DAG-based consensus for scalability, use zero-knowledge sets for revocation, and implement a federated identity system with privacy-preserving authentication",
    "answer": "b"
  },
  {
    "id": "557",
    "question": "How can privacy-preserving techniques, such as zero-knowledge proofs or homomorphic encryption, be applied to LLM-powered agents to ensure task completion verification without exposing sensitive data?\nA. Use smart contracts that handle only encrypted data and allow agents to verify completion through third-party audits\nB. Employ zero-knowledge proofs to confirm task completion without revealing the specific steps taken\nC. Allow agents to fully trust one another and eliminate the need for privacy-preserving technologies\nD. Use decentralized oracles to monitor task progress and automatically verify completion",
    "answer": "B",
    "categories": [
      "Privacy",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "558",
    "question": "How can a decentralized system for task verification be designed to validate task completion without relying on trust?\nA. Implement a multi-signature system where multiple agents sign off on task completion\nB. Use decentralized reputation scores to verify the trustworthiness of agents\nC. Allow tasks to be verified by a centralized authority that audits all work\nD. Use zero-knowledge proofs to verify task completion without revealing sensitive data",
    "answer": "D",
    "categories": [
      "Privacy",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "559",
    "question": "How can data sources used by LLM-powered agents be verified for trustworthiness while preserving privacy?\nA. Implement zero-knowledge proofs to verify data authenticity without exposing sensitive details\nB. Allow agents to verify data manually by comparing it with multiple sources\nC. Use centralized servers to verify the accuracy of all data inputs\nD. Implement blockchain-based ledgers to track data source authenticity",
    "answer": "A",
    "categories": [
      "Privacy",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "560",
    "question": "In a confidential transaction system, if the range proof for a transaction amount requires 700 bytes, and the non-confidential part of the transaction is 250 bytes, what is the approximate size increase factor compared to a non-confidential transaction? A) 2x B) 3x C) 4x D) 5x",
    "answer": "C",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "561",
    "question": "If a decentralized exchange implements confidential transactions using bulletproofs, and the average trade requires 2.5 kB of data for the bulletproof, how many trades can be included in a 1 MB block, assuming non-confidential data accounts for 20% of the block size? A) 400 B) 320 C) 160 D) 100",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "562",
    "question": "In a CoinJoin implementation, if the minimum anonymity set size is 5 and the maximum is 20, and 100 users want to participate, what is the optimal number of CoinJoin transactions to maximize privacy while minimizing the number of transactions? A) 5 B) 7 C) 10 D) 20",
    "answer": "A",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "563",
    "question": "In a Monero-like cryptocurrency, if the ring size is increased from 11 to 15, by what factor does the transaction size approximately increase? A) 1.15x B) 1.36x C) 1.5x D) 2x",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "564",
    "question": "If a CoinJoin transaction combines inputs from 5 users, each contributing 1 BTC, and creates 15 outputs of 0.33 BTC each, what is the anonymity set size for each participant? A) 3 B) 5 C) 15 D) 75",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "565",
    "question": "If a blockchain implements Bulletproofs and the proof size for a confidential transaction is reduced from 10 kB to 1 kB, what percentage reduction in blockchain growth rate can be expected if 50% of transactions use confidential amounts? A) 25% B) 40% C) 45% D) 50%",
    "answer": "C",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "566",
    "question": "In a blockchain using the MimbleWimble protocol, if the average transaction size is reduced from 1 kB to 100 bytes due to the compact nature of the protocol, what is the potential increase in throughput, assuming block size remains constant? A) 2x B) 5x C) 10x D) 20x",
    "answer": "C",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "567",
    "question": "In a ring signature scheme with a ring size of 11, if there are 1,000,000 unspent transaction outputs (UTXOs) in the network, how many possible combinations are there for creating a single ring signature? A) 11 B) 1,000,000 C) 11,000,000 D) Approximately 2.32 x 10^63",
    "answer": "D",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "568",
    "question": "In a blockchain using threshold signatures for privacy, if a 3-of-5 scheme is used and each participant has a 90% chance of being online at any given time, what is the probability that a transaction can be signed at any moment? A) 90% B) 95.4% C) 98.2% D) 99.9%",
    "answer": "C",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "569",
    "question": "In a privacy-focused cryptocurrency using Confidential Transactions, if the average transaction size is 2 kB and the blockchain produces 1 block per minute with a 1 MB block size, what is the maximum number of transactions that can be processed per day? A) 720 B) 7,200 C) 72,000 D) 720,000",
    "answer": "C",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "570",
    "question": "In a ring signature scheme with 10 participants, how many actual signers are needed to create a valid signature that maintains anonymity within the group? A) 1 B) 5 C) 9 D) 10",
    "answer": "A",
    "categories": [
      "Privacy",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "571",
    "question": "In a blockchain using Lelantus protocol, if the anonymity set grows by 1000 coins per day and decays by 1% per day, what is the approximate steady-state size of the anonymity set? A) 50,000 coins B) 100,000 coins C) 200,000 coins D) 1,000,000 coins",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "572",
    "question": "What is the main purpose of 'zk-SNARKs' in blockchain technology? A) To increase transaction speed B) To enhance privacy and anonymity C) To improve smart contract functionality D) To optimize mining algorithms",
    "answer": "B",
    "categories": [
      "Privacy",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "573",
    "question": "If a mixer service requires a minimum of 100 participants for each mixing round, and new mixing rounds start every 10 minutes with 70% probability that a waiting transaction joins the next round, what is the expected waiting time for a transaction to be mixed? A) 10 minutes B) 14.3 minutes C) 20 minutes D) 28.6 minutes",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "574",
    "question": "If a privacy-focused blockchain implements a system where each transaction must be verified by 10 randomly selected nodes using multi-party computation (MPC), and each node has a 99% uptime, what is the probability that a transaction can be immediately verified? A) 90.4% B) 95.1% C) 99.0% D) 99.9%",
    "answer": "A",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "575",
    "question": "In a cryptocurrency using ring signatures with a default ring size of 15, if the network has 1 million UTXOs and processes 100,000 transactions daily, approximately how many UTXO references are made in ring signatures each day? A) 100,000 B) 1.5 million C) 15 million D) 100 million",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "576",
    "question": "If a privacy coin uses stealth addresses and the average user receives 5 transactions per day, approximately how many stealth addresses would be generated in a network of 100,000 active users over the course of a year? A) 18.25 million B) 182.5 million C) 1.825 billion D) 18.25 billion",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "577",
    "question": "In a privacy-focused cryptocurrency using ring signatures with a ring size of 11, if there are 1,000,000 unspent transaction outputs (UTXOs) in the network, how many possible combinations are there for creating a single ring signature? A) 11 B) 1,000,000 C) 11,000,000 D) Approximately 2.32 x 10^63",
    "answer": "D",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "578",
    "question": "In a privacy-focused blockchain using zk-STARKs, if the proof generation time increases quadratically with the number of constraints, and it takes 1 second to generate a proof for 1000 constraints, approximately how long would it take to generate a proof for 1 million constraints? A) 16 minutes B) 2.8 hours C) 11.6 days D) 31.7 years",
    "answer": "C",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "579",
    "question": "If a decentralized exchange implements a privacy feature that creates a new stealth address for each trade, and the average user makes 3 trades per day, how many stealth addresses would be generated in a year for a user base of 50,000? A) 4.5 million B) 54.75 million C) 547.5 million D) 1.095 billion",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "580",
    "question": "If a privacy-focused blockchain implements a system where each block must contain exactly one confidential transaction and one non-confidential transaction, and the average block time is 5 minutes, what is the maximum number of confidential transactions that can be processed in a day? A) 144 B) 288 C) 576 D) 1440",
    "answer": "B",
    "categories": [
      "Privacy",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "581",
    "question": "In a blockchain using zk-SNARKs for privacy, if generating a proof takes 30 seconds on average hardware, and verifying a proof takes 10 milliseconds, what is the maximum theoretical transactions per second (TPS) that can be verified by a single verifier node? A) 0.033 TPS B) 3.33 TPS C) 33.3 TPS D) 100 TPS",
    "answer": "D",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "582",
    "question": "If a privacy-enhancing protocol requires 1 MB of zero-knowledge proof data per 1000 transactions, and the blockchain produces 1 block per minute with a 5 MB block size, what is the maximum number of private transactions that can be processed per day? A) 7,200 B) 72,000 C) 720,000 D) 7,200,000",
    "answer": "D",
    "categories": [
      "Privacy",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "583",
    "question": "How can Trusted Execution Environments (TEEs) be integrated into LLM-powered agents to ensure secure task execution?\nA. Allow agents to access and run confidential tasks within a secure, isolated hardware environment\nB. Use TEEs to encrypt all communication between agents\nC. Require agents to execute tasks only in fully decentralized networks\nD. Implement a monitoring system that detects any anomalies during task execution",
    "answer": "A",
    "categories": [
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "584",
    "question": "Which of the following best describes a side-channel attack? A) An attack that exploits implementation vulnerabilities B) A brute-force attack on the encryption key C) An attack on the network protocol D) A social engineering attack",
    "answer": "A",
    "categories": [
      "Security",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "585",
    "question": "A company is implementing a secure communication system and is deciding between using TLS 1.3 with perfect forward secrecy or a custom protocol that uses long-term static keys but claims to be faster. Which option should they choose and why? A) TLS 1.3, because it's a well-established standard B) The custom protocol, because it's faster C) TLS 1.3, because it provides perfect forward secrecy D) The custom protocol, because static keys are easier to manage",
    "answer": "C",
    "categories": [
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "586",
    "categories": [
      "Smart Contract",
      "DeFi",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A DeFi protocol implements a complex lending and borrowing system with flash loans. The following code snippet is part of the flash loan function:\n\n```solidity\nfunction flashLoan(uint256 amount, address recipient, bytes calldata data) external {\n    require(amount <= availableLiquidity(), \"Insufficient liquidity\");\n    uint256 fee = calculateFee(amount);\n    token.transfer(recipient, amount);\n    IFlashLoanReceiver(recipient).executeOperation(amount, fee, data);\n    require(token.balanceOf(address(this)) >= initialBalance + fee, \"Flash loan not repaid\");\n}\n```\n\nWhich combination of vulnerabilities and potential attacks is this code most susceptible to?\n\na) Reentrancy attack and oracle manipulation\nb) Integer overflow and front-running\nc) Unchecked return values and gas griefing\nd) Reentrancy attack and unauthorized access",
    "answer": "d"
  },
  {
    "id": "587",
    "categories": [
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "You are designing an upgradeable smart contract system for a critical financial application. The system needs to be secure, flexible for future upgrades, and resistant to potential vulnerabilities introduced during upgrades. Consider the following code snippet for the proxy contract:\n\n```solidity\ncontract Proxy {\n    address public implementation;\n    address public admin;\n    mapping(bytes4 => address) public functionImplementations;\n\n    function upgradeTo(address newImplementation) external {\n        require(msg.sender == admin, \"Not authorized\");\n        implementation = newImplementation;\n    }\n\n    fallback() external payable {\n        address impl = functionImplementations[msg.sig];\n        if (impl == address(0)) {\n            impl = implementation;\n        }\n        assembly {\n            calldatacopy(0, 0, calldatasize())\n            let result := delegatecall(gas(), impl, 0, calldatasize(), 0, 0)\n            returndatacopy(0, 0, returndatasize())\n            switch result\n            case 0 { revert(0, returndatasize()) }\n            default { return(0, returndatasize()) }\n        }\n    }\n}\n```\n\nWhich combination of additional measures and modifications would best enhance the security and flexibility of this upgradeable system?\n\na) Implement a multi-signature wallet for the admin, use a timelock for upgrades, and add a function to selectively upgrade individual functions\nb) Use the diamond pattern for upgrades, implement access control in the proxy contract, and use unstructured storage for all state variables\nc) Implement a transparent proxy pattern, use a timelock for upgrades, maintain strict storage layout compatibility, and add an initializer function with a mutex\nd) Deploy a new contract for each upgrade, manually migrate state, and use a registry contract to track the latest version",
    "answer": "c"
  },
  {
    "id": "588",
    "categories": [
      "Smart Contract",
      "Security",
      "System Design",
      "Advanced"
    ],
    "question": "A smart contract system for a prediction market relies on accurate timing for market resolution. The current implementation uses block timestamps, but there are concerns about miner manipulation and network congestion affecting timestamp accuracy. Consider the following constraints:\n\n1. The system must remain fully decentralized\n2. Market resolution must be deterministic and verifiable on-chain\n3. The solution should be resistant to short-term timestamp manipulations\n4. The system should be able to handle markets with various time scales (hours to months)\n\nWhich approach would be most effective in ensuring accurate and secure time-based operations while meeting these constraints?\n\na) Use block.number instead of block.timestamp for all time-based calculations, and assume a constant block time\nb) Implement a decentralized time oracle network, use the median of multiple time sources, allow for a small margin of error in time-sensitive operations, and implement a challenge period for market resolutions\nc) Require all time-sensitive operations to be approved by a multi-sig wallet, and implement a 24-hour delay for all actions\nd) Use the timestamp from the previous block for all calculations, and implement a rolling average of block times to estimate current time",
    "answer": "b"
  },
  {
    "id": "589",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A smart contract system uses upgradeable proxies for critical components. During an upgrade process, the following error occurs:\n\n```solidity\ncontract V1 {\n    uint256 public value;\n    address public owner;\n}\n\ncontract V2 {\n    address public owner;\n    uint256 public value;\n}\n\ncontract Proxy {\n    address public implementation;\n    address public admin;\n    \n    function upgrade(address newImplementation) external {\n        require(msg.sender == admin, \"Not authorized\");\n        implementation = newImplementation;\n    }\n    \n    fallback() external payable {\n        (bool success, ) = implementation.delegatecall(msg.data);\n        require(success, \"Delegatecall failed\");\n    }\n}\n```\n\nAfter upgrading from V1 to V2, users report unexpected behavior. What is the most likely cause of this issue, and how can it be prevented in future upgrades?\n\na) Function selector clashing; Implement a diamond pattern for multi-facet upgrades\nb) Storage collision; Use unstructured storage and maintain a strict storage layout\nc) Delegatecall failure; Implement a try-catch mechanism in the fallback function\nd) Lack of initialization; Add an initializer function with a mutex in V2",
    "answer": "b"
  },
  {
    "id": "590",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A developer is implementing a decentralized betting system where users can place bets and the outcome is determined by random numbers. The current implementation uses Solidity's `blockhash()` function for randomness, which has been deemed insecure, and no logging mechanisms are in place to track critical actions. Additionally, there's a risk of privileged actors manipulating outcomes. What should the developer prioritize to most effectively secure this system?\nA) Use a deterministic pseudo-random function to ensure outcome consistency\nB) Implement verifiable random functions (VRFs) to generate secure, unpredictable randomness\nC) Allow users to verify the outcome manually to ensure fairness\nD) Use block timestamps for generating random numbers, as they are harder to manipulate",
    "answer": "B"
  },
  {
    "id": "591",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A developer has used inline assembly in a Solidity contract to bypass certain gas inefficiencies of the Solidity compiler. However, after the contract was deployed, an unexpected bug caused a critical failure during the contract’s execution, and it was difficult to audit due to the complexity of the assembly code. The code also lacked documentation. What is the most critical action the developer should take to avoid similar issues in the future?\nA) Use inline assembly more extensively to optimize every function and reduce gas costs\nB) Keep the assembly sections small and isolated, and provide thorough comments to improve auditability\nC) Avoid using any formal verification tools, as they are incompatible with inline assembly\nD) Rely solely on Solidity's built-in arithmetic functions and avoid custom assembly code altogether",
    "answer": "B"
  },
  {
    "id": "592",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A commit-reveal scheme is being used to allow users to submit hidden commitments in a decentralized lottery system, which they later reveal. However, several users have exploited the lack of proper timeouts between the commit and reveal phases, submitting their reveals after the commit phase ended, and gaining an unfair advantage. Additionally, some commits are not being revealed at all. What is the best security measure to enhance fairness?\nA) Implement a strict timelock mechanism between commit and reveal phases and a forfeit mechanism for non-reveals\nB) Allow users to reveal their commitments at any time to encourage flexibility\nC) Increase the length of the commit phase to allow more participants to join\nD) Disable commit-reveal schemes entirely to avoid timing-related issues",
    "answer": "A"
  },
  {
    "id": "593",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A smart contract implements meta-transactions to allow users to send transactions without paying gas fees themselves. However, the contract was exploited through a replay attack due to improper signature verification, leading to multiple invalid transactions being processed. Furthermore, gas price manipulation allowed attackers to profit from the transaction ordering. What should be the primary security enhancement?\nA) Implement proper nonce tracking and signature verification for each meta-transaction\nB) Allow users to set their own gas prices to avoid manipulation\nC) Remove meta-transactions from the contract to prevent future exploits\nD) Use a single signature for all transactions to simplify verification",
    "answer": "A"
  },
  {
    "id": "594",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Intermediate"
    ],
    "question": "A decentralized application (dApp) has become difficult to maintain due to inconsistent naming conventions, deeply nested logic, and large, monolithic functions. As a result, recent updates introduced several bugs that went undetected due to the lack of clear documentation and comments. What is the most critical step to improve the code's clarity and maintainability?\nA) Use proper code comments and documentation while breaking down large functions into smaller ones\nB) Allow developers to refactor the code as needed without following a specific style guide\nC) Use magic numbers instead of named constants to simplify the code\nD) Rely on external developers to audit and maintain the code",
    "answer": "A"
  },
  {
    "id": "595",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized finance (DeFi) protocol recently encountered several edge cases that led to contract failures during certain scenarios, particularly under high network congestion. The current testing strategy only covers basic functionality and does not account for complex workflows or gas optimization. What is the most important step to ensure comprehensive test coverage?\nA) Perform scenario-based testing for complex workflows and edge cases while using property-based testing for gas optimization\nB) Rely on unit tests for each function to ensure basic functionality\nC) Avoid scenario testing, as it is unnecessary for most DeFi protocols\nD) Use only static analysis tools to catch vulnerabilities and remove the need for further testing",
    "answer": "A"
  },
  {
    "id": "596",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized auction platform experienced a 'griefing' attack, where malicious bidders intentionally made small, frequent bids to drive up transaction costs for other participants and disrupt the auction process. Additionally, unbounded loops within the contract exacerbated the issue, leading to gas exhaustion. What should the developer prioritize to prevent similar attacks?\nA) Set reasonable upper bounds for loops and implement rate limiting mechanisms to prevent abuse\nB) Increase gas limits for the contract to accommodate larger loops\nC) Remove all access controls to allow users to detect griefing attacks themselves\nD) Allow only high-value bids to reduce the number of transactions",
    "answer": "A"
  },
  {
    "id": "597",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A smart contract was exploited through a 'honeypot' attack, where the contract's logic appeared straightforward but included hidden state changes that misled external auditors and users. The attack was not detected due to the contract's overly complex interactions, which lacked transparency. What should be the developer’s highest priority to prevent such attacks?\nA) Ensure clear and transparent contract logic and avoid hidden state changes\nB) Implement more complex state changes to confuse attackers\nC) Allow external auditors to review only certain parts of the contract\nD) Remove access to contract source code to prevent attackers from understanding the logic",
    "answer": "A"
  },
  {
    "id": "598",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A Solidity contract uses modifiers to check conditions before executing certain functions, but a recent audit found that the modifiers contained complex logic, including external calls, which introduced reentrancy risks and made the contract difficult to maintain. Additionally, gas costs associated with the modifiers were unnecessarily high. What is the best practice to secure and optimize the use of modifiers?\nA) Keep modifier logic simple and avoid complex external calls within modifiers\nB) Use modifiers with deeply nested logic to ensure thorough checks\nC) Rely solely on gas optimizations to reduce costs without changing the modifier logic\nD) Remove all modifiers from the contract to reduce risks",
    "answer": "A"
  },
  {
    "id": "599",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A decentralized lending platform deployed an upgradeable smart contract without properly initializing the new contract, which allowed attackers to exploit uninitialized variables and gain unauthorized access to the platform's funds. Additionally, the platform lacked an 'initializer' modifier to prevent multiple initializations. What is the most critical security measure to prevent such issues in the future?\nA) Implement the 'initializer' modifier for upgradeable contracts and ensure all state variables are properly initialized\nB) Allow users to initialize the contract manually after deployment\nC) Avoid using upgradeable contracts to prevent initialization issues\nD) Use the constructor to set initial values without further checks",
    "answer": "A"
  },
  {
    "id": "600",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A smart contract relies heavily on fallback and receive functions to handle Ether transfers, but it was recently exploited due to complex logic within the fallback function, leading to gas exhaustion and failed transfers. The contract lacked proper reentrancy protection and state changes were made in the fallback function itself. What is the best practice to secure fallback and receive functions?\nA) Keep logic in fallback and receive functions minimal and implement reentrancy protection\nB) Increase the gas limit for fallback functions to handle more complex logic\nC) Allow users to execute fallback functions manually to avoid gas issues\nD) Disable fallback and receive functions to prevent Ether transfers altogether",
    "answer": "A"
  },
  {
    "id": "601",
    "categories": [
      "Smart Contract",
      "Security",
      "Problem Solving",
      "Advanced"
    ],
    "question": "A smart contract was exploited due to integer overflow vulnerabilities, where attackers manipulated arithmetic operations to exceed the contract’s storage limits. Additionally, improper type casting led to further vulnerabilities when converting between different data types. What is the most critical security measure to prevent such vulnerabilities?\nA) Use the SafeMath library for arithmetic operations and ensure proper type casting using libraries like SafeCast\nB) Allow only trusted users to perform arithmetic operations\nC) Increase the storage limits to prevent overflow\nD) Avoid using arithmetic operations altogether to simplify the contract",
    "answer": "A"
  },
  {
    "id": "602",
    "question": "When an LLM-powered agent hires another agent or human to execute a task, how can trust be established between the two parties?\nA. Use a decentralized system of third-party auditors to verify the task completion\nB. Implement smart contracts that automatically execute payments based on predefined conditions\nC. Require agents to stake tokens as collateral before accepting tasks\nD. Allow the hiring agent to verify task completion manually and release payment",
    "answer": "B",
    "categories": [
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "603",
    "question": "When an LLM-powered agent hires a human to complete a task, what mechanisms can verify that the human has actually completed the task?\nA. Implement smart contracts that release payment only after multiple agents confirm completion\nB. Use decentralized reputation systems to track and validate human performance\nC. Allow agents to manually review the work and release payments based on trust\nD. Use biometrics to ensure the task was completed by the hired human",
    "answer": "A",
    "categories": [
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "604",
    "question": "How can LLM-powered agents and humans dynamically adjust task goals during execution while ensuring accountability?\nA. Implement a flexible smart contract that can adjust terms and conditions during task execution\nB. Use decentralized oracles to update task objectives based on external data\nC. Allow agents to renegotiate the task terms manually\nD. Use a fixed contract where task goals cannot be altered once execution begins",
    "answer": "A",
    "categories": [
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "605",
    "question": "How can a decentralized task scheduling system ensure multiple LLM-powered agents efficiently divide and complete tasks without a central coordinator?\nA. Implement a token-based bidding system where agents compete for task assignments\nB. Use decentralized reputation systems to match agents with appropriate tasks\nC. Allow agents to negotiate task assignments manually\nD. Use smart contracts that automate task distribution based on agent capabilities",
    "answer": "D",
    "categories": [
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "606",
    "question": "How can LLM-powered agents securely interface with physical systems (such as robots or IoT devices) to ensure reliable task execution?\nA. Use smart contracts that autonomously validate and trigger physical actions\nB. Allow agents to manually operate physical systems based on task requirements\nC. Implement decentralized oracles to verify the success of physical actions in real-time\nD. Use centralized servers to monitor and validate physical task execution",
    "answer": "A",
    "categories": [
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "607",
    "question": "Which of the following best explains how Solana’s Proof of History (PoH) reduces the overhead in a Byzantine Fault Tolerant (BFT) system and achieves sub-second finality?\nA) PoH uses random hashes to increase the unpredictability of node communication\nB) PoH encodes a verifiable passage of time into a cryptographic ledger, allowing for fewer message exchanges between nodes\nC) PoH ensures that nodes can predict transaction order without verifying each state update\nD) PoH relies on a global clock synchronization to improve message efficiency",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "608",
    "question": "How does Solana ensure global order without sharding when synchronizing multiple Proof of History (PoH) generators?\nA) By using a leader-based election mechanism to coordinate PoH generators\nB) By mixing the state of each generator into the sequences of other generators, ensuring inter-dependency\nC) By delegating transaction execution to a central verifier node that compiles all sequences\nD) By introducing sharding only at specific network throughput thresholds",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "609",
    "question": "Which of the following is a security mechanism used in Solana’s Proof of Stake (PoS) consensus to prevent malicious validators from manipulating the consensus?\nA) Validators are required to provide random proofs of work to prevent conflicts\nB) Validators can be slashed if they vote on conflicting chains or sign invalid state hashes\nC) Validators are selected based on their performance in the previous consensus round\nD) Validators must stake more coins to prevent conflicts",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "610",
    "question": "What is a key computational or network optimization that enables Solana’s system architecture to support up to 710,000 transactions per second (TPS)?\nA) Sharding the transaction load across multiple verifier nodes\nB) Using GPU-based transaction verification to process thousands of transactions in parallel\nC) Verifying transactions through a central node to avoid network congestion\nD) Reducing the number of validators to minimize communication overhead",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "611",
    "question": "Which of the following best describes how Solana’s Proof of History (PoH) helps prevent long-range attacks on the blockchain?\nA) PoH ties each event to a specific validator's key, making it impossible for attackers to reforge past events\nB) PoH requires all nodes to regularly broadcast their states, limiting the attacker’s ability to forge history\nC) PoH sequences are cryptographically bound to time, meaning attackers cannot re-run the sequence faster than the original network\nD) PoH relies on periodic synchronization with global clocks, ensuring attackers cannot tamper with historical records",
    "answer": "C",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "612",
    "question": "How does Solana’s Proof of Replication (PoRep) ensure that validators store the entire blockchain history?\nA) Validators are required to provide a digital signature of every block stored\nB) Validators must periodically provide cryptographic proofs tied to the Proof of History (PoH) sequence\nC) Validators must hash their local state and compare it with a central verifier’s hash\nD) Validators are randomly audited by other nodes to ensure data consistency",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "613",
    "question": "What happens if a newly elected leader in Solana’s Proof of Stake (PoS) consensus fails to achieve consensus?\nA) The leader is penalized, and a new election is held\nB) The validator with the next highest voting power is selected as the new leader\nC) The network halts until manual intervention is performed\nD) The election is voided, and the previous leader continues",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "614",
    "question": "How does Solana’s secondary leader system improve network resilience?\nA) Secondary leaders automatically resolve network partitions by reorganizing blocks\nB) Secondary leaders can take over if the primary leader fails, ensuring continuous operation\nC) Secondary leaders are responsible for synchronizing transactions across sharded networks\nD) Secondary leaders are elected only in the event of a complete network failure",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "615",
    "question": "Which of the following best explains Solana’s strategy for preventing ASIC attacks during network finality?\nA) PoH sequences rely on a cryptographic hash function that cannot be parallelized, making it difficult for ASICs to gain an advantage\nB) The network introduces random delays in block generation to prevent ASICs from accelerating finality\nC) Validators are penalized for using ASIC hardware to gain a computational advantage\nD) The network limits the number of blocks that can be generated per second, reducing the effectiveness of ASICs",
    "answer": "A",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "616",
    "question": "What mechanism does Solana employ to mitigate censorship attacks where validators refuse to validate certain transactions?\nA) The network automatically slashes validators who fail to validate transactions within a specific time frame\nB) The network can fork and continue without the Byzantine validators, dynamically adjusting the slashing of inactive bonds\nC) Validators are rotated every epoch to ensure no validator has control over specific transactions\nD) The leader election process is randomized to prevent censorship",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "617",
    "question": "Which of the following best explains how Solana mitigates the risks of long-range attacks?\nA) Validators are required to publish cryptographic proofs of stake at regular intervals to prevent attacks\nB) Solana's PoH sequences cryptographically link blocks to time, making it difficult to rewrite the blockchain\nC) Validators are regularly rotated to ensure no validator can dominate block production\nD) The protocol requires all nodes to synchronize with a global clock to prevent inconsistencies",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "618",
    "question": "How does Solana's Proof of Stake (PoS) algorithm handle cases where the elected leader is unable to produce a valid block?\nA) The leader is immediately replaced by the next validator based on the leader schedule\nB) The leader's stake is slashed, and the validator with the next highest stake is promoted\nC) A new random election is conducted to select a new leader\nD) The leader continues until manual intervention is performed",
    "answer": "A",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "619",
    "question": "What role does the Proof of History (PoH) play in Solana’s high transaction throughput?\nA) PoH allows Solana to process transactions in parallel by cryptographically verifying the order of events\nB) PoH reduces the need for validators to communicate with each other, increasing the speed of consensus\nC) PoH eliminates the need for validators to run full nodes, reducing overhead\nD) PoH prevents reorganization of blocks, allowing transactions to be finalized faster",
    "answer": "A",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "620",
    "question": "What is the primary mechanism by which Solana ensures fairness and security in leader selection?\nA) Randomized leader selection based on a committee's vote\nB) Pre-determined leader schedules based on stake and randomness\nC) Dynamic selection based on transaction load\nD) Round-robin scheduling based on validator age",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "621",
    "question": "How does Solana’s Proof of Replication (PoRep) enhance the security of data storage?\nA) Validators are required to store and replicate only a portion of the blockchain\nB) Validators must prove they are storing data by providing cryptographic proofs tied to PoH sequences\nC) Validators randomly hash data to verify storage capacity\nD) Validators store multiple copies of the same data to ensure redundancy",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "622",
    "question": "Which of the following best describes how Solana handles validators who repeatedly fail to participate in consensus?\nA) The validator's stake is gradually reduced after each failure\nB) The validator is immediately ejected from the network and replaced\nC) The network dynamically adjusts the validator’s voting power based on participation\nD) The validator’s stake becomes stale and is eventually unbonded after missing several rounds",
    "answer": "D",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "623",
    "question": "In Solana, what mechanism is used to ensure that all validators agree on the same block and order of transactions?\nA) Validators communicate directly to reach a consensus on the next block\nB) Proof of History (PoH) establishes a verifiable sequence of events, ensuring agreement\nC) Validators are synchronized through a global clock to ensure consistency\nD) Validators rely on a central authority to verify the transaction order",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "624",
    "question": "What happens if a validator in Solana votes for two different chains?\nA) The validator’s votes are ignored and no action is taken\nB) The validator is slashed, losing a portion of their staked coins\nC) The validator is allowed to correct their vote within a grace period\nD) The validator is permanently banned from the network",
    "answer": "B",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "625",
    "question": "How does Solana’s architecture handle high transaction throughput without sharding?\nA) Transactions are processed by a single validator to maintain consistency\nB) Solana uses a horizontal scaling mechanism with multiple Proof of History (PoH) generators\nC) Shards are dynamically created based on network load\nD) Validators use a gossip protocol to distribute transactions across the network",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "626",
    "question": "In Solana, how are smart contracts executed in parallel, enhancing the network's overall performance?\nA) Smart contracts are distributed among multiple shards, each executing separately\nB) Smart contracts are batched together and executed on a GPU using eBPF bytecode\nC) Each smart contract is executed by a separate validator in parallel\nD) Smart contracts are executed sequentially to ensure consistency",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "627",
    "question": "In Solana, how does storing program state in non-executable accounts impact a program's ability to manage data?\nA) It prevents programs from sharing state across accounts\nB) It allows for the same program state to be shared and updated by multiple programs\nC) It forces all programs to use the same account for storing state\nD) It limits the size of the state stored to a single account",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "628",
    "question": "What challenge arises from Solana’s decision to make executable accounts immutable?\nA) Programs cannot update their own state\nB) Developers cannot upgrade smart contracts without migrating state to new accounts\nC) Executable accounts can modify other non-executable accounts’ data\nD) It limits the number of executable accounts a program can create",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "629",
    "question": "How do Program Derived Addresses (PDAs) enhance security in Solana?\nA) PDAs allow any program to freely access all accounts on the network\nB) PDAs ensure only the originating program can authorize transactions for derived accounts\nC) PDAs allow executable accounts to change ownership of non-executable accounts\nD) PDAs prevent non-executable accounts from storing more than 1MB of data",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "630",
    "question": "Without using a nonce field, how does Solana ensure that transactions are not processed more than once?\nA) By verifying transaction signatures and recent blockhashes\nB) By checking the number of previous transactions in the account\nC) By enforcing a fixed transaction fee for duplicate transactions\nD) By allowing validators to manually reject duplicate transactions",
    "answer": "A",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "631",
    "question": "What is the risk if a Solana program fails to enforce rent-exempt status on its storage accounts?\nA) Accounts could be permanently locked, preventing future updates\nB) Account balances could drop to zero, resulting in account deletion and potential loss of data\nC) The program may lose ownership of the account\nD) The program could be forced to pay extra rent fees indefinitely",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "632",
    "question": "How does Solana enable programs to securely create new accounts during program execution?\nA) By allowing only the System Program to create accounts\nB) By signing account creation requests with private keys and using PDAs\nC) By using validators to create accounts on behalf of the program\nD) By allocating a fixed number of accounts for each program at deployment",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "633",
    "question": "How do Solana developers handle dynamically growing data given the fixed account data size?\nA) They modify existing accounts by reducing other stored data\nB) They split data across multiple accounts and manage the linkage between them\nC) They store data off-chain to avoid Solana’s data size limitations\nD) They delete old data to make room for new data in the same account",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "634",
    "question": "What is the advantage of Solana’s multi-signature verification approach compared to Ethereum?\nA) Solana’s transactions only require one signature, simplifying validation\nB) Solana verifies multiple signatures natively within a transaction, enhancing scalability\nC) Solana stores signatures off-chain, reducing storage requirements\nD) Solana uses the same signature verification process as Ethereum, ensuring compatibility",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "635",
    "question": "What happens if a transaction includes multiple instructions but one of them fails?\nA) Only the failed instruction is skipped\nB) The failed instruction is retried until success\nC) The entire transaction fails, and no instruction is processed\nD) All succeeding instructions are executed, but the failed instruction is skipped",
    "answer": "C",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "636",
    "question": "In Solana, which of the following describes the role of the AccountMeta struct in a transaction?\nA) It specifies the size of the transaction and the number of instructions\nB) It lists accounts required by the instruction, along with their signer and writable status\nC) It defines the blockhash used to prevent transaction replay attacks\nD) It encodes the data for instruction arguments and manages account balances",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "637",
    "question": "Which part of a Solana transaction prevents duplicate processing of a transaction?\nA) AccountMeta array\nB) Transaction message header\nC) Compact-u16 instruction encoding\nD) Recent blockhash",
    "answer": "D",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "638",
    "question": "What is the maximum size of a Solana transaction?\nA) 1280 bytes\nB) 1232 bytes\nC) 1024 bytes\nD) 1400 bytes",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "639",
    "question": "In a Solana transaction message, how are account addresses and instructions stored?\nA) As a flat array of u64 integers\nB) As an array of compact-u16 encoded items\nC) As a linked list of byte arrays\nD) As an array of u256 encoded integers",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "640",
    "question": "How is the signer status of accounts determined in a Solana transaction?\nA) The program ID defines which accounts are signers\nB) Accounts marked as read-only are always signers\nC) The message header specifies the number of signers required for the transaction\nD) The blockhash determines the signing status of all accounts",
    "answer": "C",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "641",
    "question": "In the context of Solana transactions, what does the 'compact array of opaque u8 data' refer to?\nA) The array of account addresses used by the transaction\nB) The account balance of the writable accounts\nC) A byte array specifying the instruction data to be processed by the program\nD) The encoding scheme used for the message header",
    "answer": "C",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "642",
    "question": "What happens if a Solana transaction's blockhash is older than 150 blocks?\nA) The transaction is prioritized for faster execution\nB) The transaction is considered invalid and will not be processed\nC) The transaction's signatures are revalidated to ensure security\nD) The blockhash is automatically updated to the latest valid block",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "643",
    "question": "In Solana, why is 50% of transaction fees burned after every transaction?\nA) To reduce the incentive for validators to include spam transactions\nB) To create inflation and reward long-term SOL holders\nC) To discourage malicious validators from censoring transactions and increase SOL value\nD) To reduce transaction processing times during network congestion",
    "answer": "C",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "644",
    "question": "What happens if the account paying the transaction fee on Solana does not have enough balance?\nA) The transaction is partially processed until the fee payer's balance is exhausted\nB) The fee is waived, but the transaction is still processed\nC) The transaction fails immediately, but the fee is still deducted\nD) The transaction fails before execution, and no fee is collected",
    "answer": "D",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "645",
    "question": "What happens when a transaction on Solana exceeds its compute budget?\nA) The transaction is delayed until more resources are available\nB) The transaction halts and fails, but only the transaction fee is deducted\nC) The transaction is re-executed with a higher compute budget\nD) The transaction continues but with reduced priority",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "646",
    "question": "How can a user on Solana boost their transaction’s prioritization during network congestion?\nA) By increasing the number of signatures on the transaction\nB) By setting a higher compute unit price to increase the prioritization fee\nC) By using multiple accounts as fee payers for the transaction\nD) By including additional instructions to optimize resource consumption",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "647",
    "question": "What is the primary consequence of an account balance falling below the rent-exempt threshold on Solana?\nA) The account is immediately deleted from the network\nB) The account stops receiving incoming transactions\nC) The account starts paying rent fees and can be garbage collected\nD) The account is marked as inactive but retains its data",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "648",
    "question": "Which operation in a Solana transaction incurs a compute cost and consumes compute units?\nA) Logging data using the msg! macro\nB) Declaring account metadata in a transaction\nC) Signing the transaction with the fee payer account\nD) Storing the transaction blockhash in the account",
    "answer": "A",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "649",
    "question": "Why does Solana burn a portion of transaction fees rather than distribute all fees to validators?\nA) To deflate the total supply of SOL and prevent validators from censoring transactions\nB) To reduce validator power by limiting their earning potential\nC) To ensure faster transaction processing by limiting validator rewards\nD) To maintain a fixed inflation rate across the Solana network",
    "answer": "A",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "650",
    "question": "What happens if a cross-program invocation (CPI) in Solana consumes more compute units than its parent transaction's remaining budget?\nA) Only the invoked instruction fails, but the rest of the transaction continues\nB) The entire transaction, including the CPI chain, halts and fails\nC) The CPI is re-executed with more compute units allocated\nD) The CPI is skipped, and the transaction moves to the next instruction",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "651",
    "question": "A developer needs to derive a deterministic PDA for a program on Solana. What ensures that no private key can sign for this PDA?\nA) The PDA is derived using the Ed25519 curve\nB) The PDA falls off the Ed25519 curve, meaning it lacks a private key\nC) The PDA uses a randomly generated private key\nD) The PDA is created by the system program, which disables signing",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "652",
    "question": "When deriving a PDA in Solana, what role does the bump seed play?\nA) It ensures that the PDA falls off the Ed25519 curve and has no corresponding private key\nB) It allows the PDA to sign transactions without using a private key\nC) It prevents the program from being able to access the PDA's account\nD) It generates a new private key for each PDA derived",
    "answer": "A",
    "categories": [
      "Solana",
      "Smart Contract",
      "Cryptography",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "653",
    "question": "A program derived a PDA using a bump seed of 253 instead of 255. What is the risk of using non-canonical bump seeds?\nA) Non-canonical bumps could create multiple valid PDAs, leading to unauthorized access\nB) Non-canonical bumps are invalid, and the program will fail to execute\nC) Non-canonical bumps prevent the PDA from being used as an account\nD) Non-canonical bumps result in the PDA having a corresponding private key",
    "answer": "A",
    "categories": [
      "Solana",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "654",
    "question": "After deriving a PDA for an account, what must the program do to create the on-chain account at that address?\nA) Sign the PDA with the program's private key\nB) Send an instruction to the system program to create an account using the PDA address\nC) Automatically fund the PDA with lamports\nD) Register the PDA address with the Solana runtime",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "655",
    "question": "A developer used the findProgramAddressSync method to derive a PDA. What output does this method provide?\nA) A random private key associated with the PDA\nB) The public key and the bump seed used to derive the PDA\nC) A signature that proves ownership of the PDA\nD) A valid program ID that can use the PDA",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "656",
    "question": "Why is it critical for a program to validate that a PDA passed to it is derived using the canonical bump?\nA) To prevent unauthorized access via non-canonical PDAs\nB) To increase the speed of transaction processing\nC) To ensure the PDA is automatically created as an account\nD) To simplify the signing process for the PDA",
    "answer": "A",
    "categories": [
      "Solana",
      "Smart Contract",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "657",
    "question": "What happens if a program tries to reuse the same user address as a seed for a PDA more than once?\nA) The second PDA is automatically created at a new address\nB) The transaction will fail because an account already exists at that PDA\nC) The program will generate a new PDA using a different program ID\nD) The PDA will be created with a different private key",
    "answer": "B",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "658",
    "question": "In what scenario would a bump seed be decreased during PDA derivation?\nA) When the initial bump seed produces an invalid PDA on the Ed25519 curve\nB) When the PDA is derived using fewer optional seeds\nC) When the PDA is generated as an on-curve point\nD) When the program needs to reset the PDA address",
    "answer": "A",
    "categories": [
      "Solana",
      "Smart Contract",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "659",
    "question": "What information does a Mint Account store in Solana?\nA) Total token supply and decimal precision\nB) Token holder balances\nC) Transaction history\nD) Network validator information",
    "answer": "A",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "660",
    "question": "What is the main function of a Token Account?\nA) Storing network consensus information\nB) Tracking individual ownership of a specific token type\nC) Recording total supply of all tokens\nD) Managing smart contract execution",
    "answer": "B",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "661",
    "question": "What is the primary advantage of an Associated Token Account?\nA) Providing higher security\nB) Allowing simultaneous holding of multiple token types\nC) Simplifying token account address lookup for specific mints and owners\nD) Reducing transaction fees",
    "answer": "C",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "662",
    "question": "After creating a new token on Solana, what is typically the next step?\nA) Immediately start trading\nB) Mint token units\nC) Create a smart contract\nD) Register on a centralized exchange",
    "answer": "B",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Beginner"
    ]
  },
  {
    "id": "663",
    "question": "What additional functionality does the Token Extensions Program provide in Solana?\nA) Cross-chain token transfers\nB) Automatic token burning\nC) Enhanced metadata storage on Mint Accounts\nD) Direct fiat currency conversion",
    "answer": "C",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "664",
    "question": "What is the relationship between a Mint Account and Token Accounts in Solana?\nA) They are the same thing\nB) A Mint Account represents a token type, while Token Accounts track individual ownership\nC) Mint Accounts store transaction history, while Token Accounts store token supply\nD) Token Accounts create new tokens, while Mint Accounts distribute them",
    "answer": "B",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "665",
    "question": "Which of the following is NOT typically stored in a Token Account?\nA) The type of token (mint)\nB) The owner of the account\nC) The amount of tokens held\nD) The total supply of the token",
    "answer": "D",
    "categories": [
      "Solana",
      "Tokenomics",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "666",
    "question": "In Solana, what happens when a transaction’s blockhash exceeds 151 blocks?\nA) The transaction is delayed but eventually processed\nB) The transaction is rejected as expired\nC) The transaction is prioritized for faster processing\nD) The blockhash is refreshed automatically to avoid expiration",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Intermediate"
    ]
  },
  {
    "id": "667",
    "question": "How does Solana's Proof of History (PoH) ensure accurate transaction timestamps?\nA) By creating a hash chain linking transactions to previous blocks\nB) By embedding timestamps in each transaction header\nC) By using a nonce mechanism like Ethereum\nD) By verifying transactions using public keys",
    "answer": "A",
    "categories": [
      "Solana",
      "Consensus Mechanisms",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "668",
    "question": "What is the role of the BlockhashQueue in Solana's transaction lifecycle?\nA) It stores transaction signatures to prevent double-spending\nB) It queues block producers for transaction forwarding\nC) It stores the 300 most recent blockhashes for transaction validation\nD) It logs rejected transactions for later retries",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "669",
    "question": "How do durable transactions differ from regular transactions in Solana?\nA) They bypass the PoH mechanism entirely\nB) They use nonce accounts with durable blockhashes that do not expire\nC) They require double the amount of SOL fees\nD) They allow block producers to prioritize processing",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "670",
    "question": "Why might Solana's blockhash expiration mechanism be advantageous compared to Ethereum's nonce-based transaction model?\nA) Solana’s blockhashes are easier to refresh automatically\nB) Solana allows transactions to be processed out of order, reducing delays\nC) Ethereum’s nonce system is more efficient for validators\nD) Solana requires blockhashes to be manually validated by users",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "671",
    "question": "What is the key risk of reusing stale blockhashes in Solana transactions?\nA) Validators will prioritize those transactions over fresh ones\nB) Transactions will be executed twice due to replay attacks\nC) Transactions will be rejected due to expired blockhashes\nD) The transaction will be delayed until the blockhash is refreshed",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "672",
    "question": "Which commitment level should developers use to balance transaction speed and stability when fetching blockhashes in Solana?\nA) Processed\nB) Finalized\nC) Confirmed\nD) Invalidated",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "673",
    "question": "What is the potential consequence of using lagging RPC nodes when sending transactions in Solana?\nA) The transaction will automatically be re-signed\nB) The transaction might use an expired blockhash and fail\nC) The RPC node will store the transaction until the network stabilizes\nD) The block producer will correct the transaction automatically",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "674",
    "question": "What are the primary reasons why a seemingly valid Solana transaction may be dropped before it is included in a block?\nA) The leader ignores the transaction if it's not the highest fee\nB) The transaction's blockhash has expired before it was processed\nC) Network congestion or UDP packet loss prevents the transaction from reaching the leader\nD) The TPU automatically prioritizes voting transactions over other transactions",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "675",
    "question": "How does Solana handle transactions differently compared to Ethereum regarding mempools?\nA) Solana uses a direct route to leaders with no mempool, while Ethereum uses a gossip-based mempool\nB) Solana uses a mempool to store pending transactions, while Ethereum uses direct submission to leaders\nC) Both blockchains rely on RPC nodes to store pending transactions\nD) Solana uses a slower propagation mechanism for unprocessed transactions",
    "answer": "A",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "676",
    "question": "Why is it important for developers to avoid re-signing transactions before ensuring the initial blockhash has expired?\nA) The transaction will be prioritized twice, leading to wasted gas fees\nB) It could result in the same transaction being accepted twice by the network\nC) The network will reject the re-signed transaction immediately\nD) The re-signed transaction will have a higher likelihood of being dropped",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "677",
    "question": "What is a common scenario that leads to transactions being dropped when using an RPC pool?\nA) The transaction is broadcasted to too many leaders simultaneously\nB) A blockhash is queried from an advanced backend but submitted to a lagging backend\nC) The RPC pool reaches its maximum transaction forwarding capacity\nD) The network temporarily forks and drops all transactions from minority forks",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "678",
    "question": "How does Solana’s Transaction Processing Unit (TPU) handle unprocessed transactions?\nA) Unprocessed transactions are sent to a secondary queue to be retried later\nB) They are forwarded to the next leader using the tpu_forwards port\nC) They are immediately discarded to avoid network congestion\nD) They are rerouted to a validator for final consensus",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "679",
    "question": "When should developers use the maxRetries parameter in Solana’s sendTransaction method?\nA) When submitting a transaction that involves multiple CPIs\nB) During network congestion, to manually control transaction rebroadcasting\nC) When interacting with on-chain programs that require state verification\nD) When preflight checks have been disabled to increase transaction speed",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "680",
    "question": "What is the primary role of the Fetch Stage within the Transaction Processing Unit (TPU) in Solana?\nA) To distribute transactions evenly among validators\nB) To verify transaction signatures before processing\nC) To receive and categorize incoming transactions based on their type\nD) To finalize transactions and store them in the ledger",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "681",
    "question": "Why is it risky to disable preflight checks when sending transactions on Solana?\nA) It might lead to duplicate transactions being accepted by the network\nB) Skipping these checks can cause the transaction to use an expired blockhash\nC) Validators will automatically drop all transactions that skip preflight\nD) Disabling preflight checks causes significantly higher transaction fees",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Security",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "682",
    "question": "What is the key benefit of using Address Lookup Tables (ALTs) in Solana transactions?\nA) They reduce the transaction fees by compressing addresses\nB) They increase the number of addresses a transaction can interact with to 64\nC) They eliminate the need for versioned transactions\nD) They enable transactions to bypass consensus protocols",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "683",
    "question": "How does the compression mechanism of Address Lookup Tables (ALTs) in Solana work?\nA) By reducing address sizes from 32 bytes to 16 bytes\nB) By compressing each 32-byte address into a 1-byte index within the table\nC) By grouping addresses based on transaction type\nD) By automatically batching multiple transactions into one",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "684",
    "question": "Which method is used to create a new Address Lookup Table (ALT) in Solana using the @solana/web3.js library?\nA) createAddressTable\nB) createLookupTable\nC) newLookupAddress\nD) addLookupTable",
    "answer": "B",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "685",
    "question": "What limitation do developers face when extending an Address Lookup Table (ALT) in a single transaction?\nA) Only one address can be added at a time\nB) The transaction can only include addresses from one program\nC) A limited number of addresses (~20) can be added due to memory limits\nD) The transaction must be finalized before new addresses can be added",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "686",
    "question": "How do developers use an Address Lookup Table (ALT) in a versioned transaction?\nA) By compiling a v0 message that includes the ALT account\nB) By adding legacy transaction instructions to the ALT\nC) By converting the ALT into a legacy transaction format\nD) By signing the transaction after it is sent to the cluster",
    "answer": "A",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "687",
    "question": "What is the purpose of the 'canopy depth' in a concurrent Merkle tree?\nA) To limit the number of concurrent changes\nB) To store a portion of proof nodes on-chain, reducing transaction size\nC) To define the maximum size of each Merkle tree branch\nD) To allow a single tree to store multiple root hashes",
    "answer": "B",
    "categories": [
      "Solana",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "688",
    "question": "What does the 'max buffer size' parameter control in a concurrent Merkle tree?\nA) The number of concurrent updates allowed per slot\nB) The maximum number of leaves in the tree\nC) The maximum transaction size for tree updates\nD) The total number of nodes stored on-chain",
    "answer": "A",
    "categories": [
      "Solana",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "689",
    "question": "How do compressed NFTs on Solana reduce minting costs?\nA) By using state compression to store only a root hash on-chain instead of full NFT data\nB) By batching minting requests into a single transaction\nC) By using a separate blockchain for minting NFTs\nD) By bypassing standard Solana transaction fees",
    "answer": "A",
    "categories": [
      "Solana",
      "Dapps",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "690",
    "question": "What is the primary advantage of state compression in Solana?\nA) It allows for smaller transaction fees\nB) It increases block processing speed\nC) It reduces on-chain storage costs by storing only a compressed hash of off-chain data\nD) It allows transactions to bypass the consensus process",
    "answer": "C",
    "categories": [
      "Solana",
      "Blockchain Fundamental",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "691",
    "question": "How do concurrent Merkle trees in Solana handle multiple rapid changes within a block?\nA) By updating the root hash with each change\nB) By keeping a changelog of recent changes on-chain\nC) By queuing changes until the next block\nD) By storing every change directly on-chain",
    "answer": "B",
    "categories": [
      "Solana",
      "Knowledge",
      "Advanced"
    ]
  },
  {
    "id": "692",
    "question": "In an unpredictable market environment, which of the following models would best balance between incentivizing participation and preventing supply shocks in token emissions?\nA. A fixed emissions model with no adjustments\nB. An emissions model with pre-scheduled halving events\nC. A multi-phase emissions model that adjusts dynamically to market volatility and user engagement\nD. A purely deflationary emissions model that reduces supply over time",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "693",
    "question": "Which of the following best describes how a token buyback and burn mechanism can autonomously operate in response to market signals?\nA. Buybacks occur only when manually triggered by governance votes\nB. Buybacks and burns are conducted based on pre-scheduled events\nC. An algorithmic system dynamically adjusts buybacks based on market liquidity and price volatility\nD. Buybacks are executed only during market downturns to stabilize price",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "694",
    "question": "How can a decentralized treasury management framework dynamically balance risk-taking for growth and conservative reserves?\nA. By maintaining fixed asset allocations based on predefined rules\nB. Through a community-driven voting system on all investment decisions\nC. By implementing an algorithmic asset management system that adjusts based on real-time performance and market conditions\nD. By delegating all decisions to a multi-signature wallet controlled by key stakeholders",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "695",
    "question": "When migrating liquidity across platforms, which strategy would best minimize token price volatility and slippage?\nA. Migrating all liquidity at once without community consultation\nB. Phasing liquidity migration over time while providing market-making incentives\nC. Relying solely on community governance to execute the migration\nD. Moving liquidity only when token prices are stable for an extended period",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "696",
    "question": "What mechanism would best ensure seamless cross-chain token utility while preserving liquidity, security, and governance synchronization?\nA. A single-chain token model with centralized governance\nB. A decentralized bridge that facilitates token swaps between chains with synchronized governance decisions\nC. A fixed-supply token distributed equally across chains with no governance synchronization\nD. Cross-chain token swaps with separate governance systems for each chain",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "697",
    "question": "In the event of a liquidity crisis, which of the following would best stabilize the system?\nA. Immediate shutdown of liquidity pools\nB. Dynamic interest rate adjustments and time-locked liquidity pools\nC. Enforcing strict withdrawal limits\nD. Governance intervention to temporarily freeze all withdrawals",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "698",
    "question": "Which inflation control mechanism would most effectively balance long-term token growth with preventing excessive reliance on any single control mechanism?\nA. A fixed inflation rate set by governance\nB. A model using staking rewards, token burns, and capped emissions that adjust dynamically to market conditions\nC. A continuously decreasing emissions schedule without adjustments\nD. A system based purely on periodic token burns",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "699",
    "question": "How can DAO tokenomics address power imbalances between small stakeholders and large token holders?\nA. Implementing governance tokens with fixed voting power\nB. Using quadratic voting, reputation-based incentives, and dynamic delegation\nC. Allowing token holders to delegate votes without any weight limitations\nD. Encouraging larger token holders to have exclusive governance rights",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "700",
    "question": "Which of the following would best describe a token pricing strategy that ensures resilience to price manipulation while remaining responsive to real-time market demand?\nA. A fixed token price governed by smart contracts\nB. Time-weighted average pricing with on-chain oracles and anti-front-running measures\nC. A market-driven price without any intervention\nD. A system relying solely on external exchange rates for token valuation",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "701",
    "question": "How can vesting schedules be dynamically adjusted based on governance input and project milestones in a decentralized project?\nA. By using fixed schedules determined at token launch\nB. Allowing token unlocks based solely on time, with no adjustments\nC. Using flexible vesting that is modified based on governance votes and key project milestones\nD. Vesting tokens only after the project reaches final completion",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "702",
    "question": "Which of the following is the best method to ensure that a token’s utility remains the primary driver of demand, especially in a speculative market?\nA. Penalizing speculative behavior and incentivizing utility-focused actions through dynamic rewards\nB. Allowing speculative trading to drive token value without restrictions\nC. Increasing token supply during periods of high speculation\nD. Removing any restrictions on trading to enhance liquidity",
    "answer": "A",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "703",
    "question": "How can a governance token's security be enhanced to mitigate risks of hostile takeovers?\nA. Using a single-layer voting mechanism for all decisions\nB. Integrating time-locked voting power and multi-signature controls\nC. Allowing unrestricted voting access to all token holders\nD. Implementing governance based on the number of tokens held, without any security measures",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DAO & Governance",
      "Security",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "704",
    "question": "Which model best ensures that tokenomics amplify network effects in a decentralized ecosystem while avoiding centralized control?\nA. Relying solely on early adopters to grow the network\nB. Using a centralized control mechanism to reward engagement\nC. Tying network growth directly to user participation and minimizing early holder influence\nD. Delegating control of network effects to a single entity",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "705",
    "question": "Which of the following mechanisms best encourages long-term token holding based on organic utility?\nA. Offering speculative rewards for short-term trading\nB. Implementing multi-tiered staking rewards and penalties for short-term trading\nC. Relying solely on price appreciation for holding incentives\nD. Providing immediate liquidity for all token holders without lockup periods",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "706",
    "question": "How should a negative emissions model (token burn mechanism) be designed to avoid risks of liquidity crunches and deflationary spirals?\nA. By burning tokens at a fixed rate regardless of market conditions\nB. Allowing burns to occur only during market downturns\nC. Activating burns based on real-time market performance while using safeguards to prevent overburning\nD. Relying on governance votes to adjust the burn rate dynamically",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "707",
    "question": "Which strategy would best incentivize cross-chain token holders while maintaining security and governance synchronization?\nA. Rewarding users based on their activities on only one chain\nB. Using decentralized oracles to monitor cross-chain activity and adjust rewards dynamically\nC. Providing no incentives for cross-chain participation\nD. Allowing users to manually synchronize governance across chains",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Interoperability",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "708",
    "question": "How can behavioral economics principles such as loss aversion and commitment devices be integrated into tokenomics to encourage long-term participation?\nA. Penalizing long-term holders and rewarding short-term traders\nB. Offering large bonuses for speculative trading behavior\nC. Introducing commitment devices that lock rewards until engagement milestones are met\nD. Allowing users to exit the system without any penalties",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "709",
    "question": "Which model best limits economic rent extraction by early investors while maintaining incentives for long-term participation?\nA. Allowing early investors to sell all tokens immediately\nB. Using long-term vesting schedules combined with community-driven rewards\nC. Relying solely on market dynamics to regulate token distribution\nD. Permitting only early investors to participate in governance",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "710",
    "question": "How can a decentralized marketplace ensure equitable value capture among participants without distorting incentives?\nA. Allowing buyers and sellers to dictate the value capture dynamics\nB. Using dynamic fee structures and revenue-sharing models that adjust based on demand\nC. Fixing transaction fees regardless of market conditions\nD. Limiting governance participation to liquidity providers only",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "711",
    "question": "What privacy-preserving mechanism could best balance between user confidentiality and the transparency needed for decentralized governance?\nA. Using fully public transactions for all token transfers\nB. Integrating zero-knowledge proofs for transaction verification and selective disclosure in governance voting\nC. Allowing complete anonymity in all governance and transactions\nD. Relying on centralized intermediaries to ensure privacy",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Privacy",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "712",
    "question": "Which strategy would best implement adaptive supply management algorithms to respond dynamically to shifts in demand and external factors?\nA. Using a fixed token supply that never adjusts\nB. Adjusting supply based on user participation without external considerations\nC. Integrating macroeconomic indicators like inflation and interest rates to influence supply changes\nD. Increasing supply during all periods of high volatility",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "713",
    "question": "How can decentralized smart contracts dynamically adjust collateral requirements based on market volatility?\nA. Maintaining fixed collateral requirements regardless of volatility\nB. Increasing collateral requirements during high volatility periods while reducing them during stable conditions\nC. Relying on governance to manually change collateral levels during economic uncertainty\nD. Removing collateral requirements during periods of market stability",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "714",
    "question": "Which model would allow decentralized governance to continuously improve tokenomics without risking manipulation or governance fatigue?\nA. Allowing unlimited governance proposals at all times\nB. Implementing a self-amending model with multiple validation layers, expert audits, and community reviews\nC. Relying solely on the community for governance adjustments\nD. Using a static governance model that requires no future changes",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "715",
    "question": "How can algorithmic stablecoins maintain their peg during volatile markets?\nA. By using dynamic collateral ratios and real-time governance adjustments\nB. Relying solely on fixed supply models to maintain the peg\nC. Allowing supply to fluctuate based on speculative market activity\nD. Using governance-controlled emergency burns to stabilize the token",
    "answer": "A",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "716",
    "question": "What staking mechanism can best balance long-term lockups with liquidity needs in a decentralized system?\nA. Offering no liquidity options for stakers\nB. A multi-tiered staking system with varying rewards based on lockup duration and liquidity access via lending protocols\nC. Fixed rewards with no liquidity options\nD. Allowing stakers to withdraw at any time without penalties",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "717",
    "question": "In a multi-token ecosystem, which interconnected tokenomics model would best ensure value and demand across different tokens?\nA. Isolating each token with its own utilities and rewards\nB. A model where cross-utility incentives dynamically link governance, collateral, and payment tokens\nC. Allowing only the governance token to hold value while others have no utility\nD. Setting a fixed value for each token regardless of demand",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "718",
    "question": "How can governance tokenomics prioritize economic efficiency in large decentralized organizations?\nA. Using a random selection process for governance proposals\nB. Ranking governance proposals by economic impact with dynamic voting power based on past contributions\nC. Allowing all proposals to be considered equally regardless of their economic significance\nD. Giving full voting power to early investors only",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "719",
    "question": "What tokenomics model can best ensure long-term liquidity in an Autonomous Market Maker (AMM) while discouraging short-term speculative behavior?\nA. Rewarding liquidity providers based solely on short-term participation\nB. Offering dynamic rewards based on time-weighted liquidity participation to incentivize long-term stability\nC. Removing all rewards to discourage speculation\nD. Using fixed rewards with no time component",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "720",
    "question": "Which governance tokenomics structure best balances regulatory compliance with decentralization?\nA. Using purely on-chain governance without considering regulations\nB. A hybrid governance model with modular layers and off-chain signaling for regulatory compliance\nC. Allowing centralized entities to control governance decisions\nD. Implementing on-chain governance with no flexibility for regulatory changes",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "DAO & Governance",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "721",
    "question": "How can the tokenomics of algorithmic stablecoins prevent collapses during market downturns?\nA. Using dynamic supply-demand rebalancing with external collateral and governance-controlled emergency adjustments\nB. Relying on fixed supply and hoping for market stabilization\nC. Allowing full market control without any governance oversight\nD. Using a centralized system to stabilize the stablecoin",
    "answer": "A",
    "categories": [
      "Tokenomics",
      "DeFi",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "722",
    "question": "In a DAO with 1 million tokens, if a governance proposal suggests burning 20% of the total supply to increase scarcity, and the proposal passes, how many tokens would a user with 10,000 tokens have after the burn (assuming proportional burning)? A) 8,000 B) 10,000 C) 12,000 D) 12,500",
    "answer": "A",
    "categories": [
      "Tokenomics",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "723",
    "question": "If a rebase token with 1 million supply and $1 price targets a 10% supply increase, what's the new price to maintain the same market cap? A) $0.90 B) $0.91 C) $1.00 D) $1.10",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Calculation",
      "Intermediate"
    ]
  },
  {
    "id": "724",
    "question": "A blockchain implements a new fee market where transaction fees are split between validators and a 'fee smoothing contract'. This contract accumulates fees during high-demand periods and distributes them during low-demand periods. If the contract accumulates 1000 tokens per high-demand block and distributes 100 tokens per low-demand block, and there are typically 9 low-demand blocks for every high-demand block, what's the maximum number of consecutive low-demand blocks the contract can support before depleting its funds? A) 90 blocks B) 100 blocks C) 110 blocks D) 120 blocks",
    "answer": "B",
    "categories": [
      "Tokenomics",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "725",
    "question": "A blockchain implements a new fee market where transaction fees are split between validators and a 'fee smoothing contract'. This contract accumulates fees during high-demand periods and distributes them during low-demand periods. How might this affect validator behavior and network security? A) Encourage more consistent validator participation B) Lead to potential centralization of fee distribution C) Reduce the incentive for validators during peak times D) Increase the risk of long-range attacks",
    "answer": "A",
    "categories": [
      "Tokenomics",
      "Problem Solving",
      "Advanced"
    ]
  },
  {
    "id": "726",
    "question": "If a blockchain has a total supply of 21 million coins and uses a halving schedule where block rewards are halved every 210,000 blocks, starting from an initial reward of 50 coins per block, after how many halvings will more than 99% of all coins be mined? A) 32 halvings B) 16 halvings C) 8 halvings D) 4 halvings",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Calculation",
      "Advanced"
    ]
  },
  {
    "id": "727",
    "question": "A blockchain implements a new virtual machine that uses a system of 'gas futures'. Users can pre-purchase gas for future blocks at a discount, but this gas expires if not used within 1,000,000 blocks. If gas prices follow a fractional Brownian motion with Hurst parameter H = 0.7, long-term mean of 100 gwei, and volatility of 200% per year, what should be the price of gas futures for 1,000,000 blocks in the future (assuming 5-second block times) to ensure a 99.99% probability of profit for the buyer? A) Approximately 50% of current price B) Approximately 55% of current price C) Approximately 60% of current price D) Approximately 65% of current price",
    "answer": "C",
    "categories": [
      "Tokenomics",
      "Calculation",
      "Advanced"
    ]
  }
]